{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"MojPalac","title":"MojPalac"},{"location":"#mojpalac","text":"","title":"MojPalac"},{"location":"books/android_programing_big_nerd_ranch/","text":"Android Programming Big Nerd Ranch you can create default style for buttons in theme Retrofit - getX(@Url url: String) - allows to override base url for particular call (similarly as passing whole path with new base url in annotation) for images the response type has to be ResponseBody and decode to BitMap @WorkerThread allows to make sure Lint will catch and show an error when calling something on main thread LifecycleObserver can be added as implementation to any object that should be aware of lifecycle. Then you can annotate fun e.g. @OnLifecycleEvent(On_CREATE) and use instance of lifecycle like: this@fragment.lifyclcle.addObserver(myObserver) make sure to call this@fragment.lifyclcle.removeObserver()","title":"Android Programming Big Nerd Ranch"},{"location":"books/android_programing_big_nerd_ranch/#android-programming-big-nerd-ranch","text":"you can create default style for buttons in theme Retrofit - getX(@Url url: String) - allows to override base url for particular call (similarly as passing whole path with new base url in annotation) for images the response type has to be ResponseBody and decode to BitMap @WorkerThread allows to make sure Lint will catch and show an error when calling something on main thread LifecycleObserver can be added as implementation to any object that should be aware of lifecycle. Then you can annotate fun e.g. @OnLifecycleEvent(On_CREATE) and use instance of lifecycle like: this@fragment.lifyclcle.addObserver(myObserver) make sure to call this@fragment.lifyclcle.removeObserver()","title":"Android Programming Big Nerd Ranch"},{"location":"books/pragmatic_programmer/","text":"Pragmatic programmer 1 A Pragmatic Philosophy 1 It\u2019s Your Life It is your life. You own it. You run it. You create it. Many developers we talk to are frustrated. Their concerns are varied. Some feel they\u2019re stagnating in their job, others that technology has passed them by. Folks feel they are underappreciated, or underpaid, or that their teams are toxic. Maybe they want to move to Asia, or Europe, or work from home. And the answer we give is always the same. And the answer we give is always the same. Why can\u2019t you change it? Does your work environment suck? Is your job boring? Try to fix it. But don\u2019t try forever. As Martin Fowler says, \"you can change your organization or change your organization.\" 2 The Cat Ate My Source Code Team Trust - is absolutely essential for creativity and collaboration according to the research literature [e.g. ( research) [https://psycnet.apa.org/doiLanding?doi=10.1037%2Fapl0000110]. In a healthy environment based in trust, you can safely speak your mind, present your ideas, and rely on your team members who can in turn rely on you. Take Responsibility - When you do accept the responsibility for an outcome, you should expect to be held accountable for it. When you make a mistake (as we all do) or an error in judgment, admit it honestly and try to offer options. It is up to you to provide solutions, not excuses. Before you approach anyone to tell them why something can\u2019t be done, is late, or is broken, stop and listen to yourself. Talk to the rubber duck on your monitor, or the cat. Does your excuse sound reasonable, or stupid? How\u2019s it going to sound to your boss? Run through the conversation in your mind. What is the other person likely to say? Will they ask, \"Have you tried this\u2026\" or \"Didn\u2019t you consider that?\" How will you respond? Before you go and tell them the bad news, is there anything else you can try? Sometimes, you just know what they are going to say, so save them the trouble. explain what can be done to salvage the situation refactoring prototyping better testing automation additional resources more time with user maybe time for learning some technique or technology in greater depth? 3 Software Entropy Entropy is a term from physics that refers to the amount of \"disorder\" in a system. it might be called, by the more optimistic term, \"technical debt,\" with the implied notion that they\u2019ll pay it back someday. They probably won\u2019t. In inner cities, some buildings are beautiful and clean, while others are rotting hulks. Why? Researchers in the field of crime and urban decay discovered a fascinating trigger mechanism, one that very quickly turns a clean, intact, inhabited building into a smashed and abandoned derelict.[5] A broken window. One broken window, left unrepaired for any substantial length of time, instills in the inhabitants of the building a sense of abandonment\u2014a sense that the powers that be don\u2019t care about the building. So another window gets broken. People start littering. Graffiti appears. Serious structural damage begins. In a relatively short span of time, the building becomes damaged beyond the owner\u2019s desire to fix it, and the sense of abandonment becomes reality. Why would that make a difference? Psychologists have done studies[6] that show hopelessness can be contagious. Think of the flu virus in close quarters. Ignoring a clearly broken situation reinforces the ideas that perhaps nothing can be fixed, that no one cares, all is doomed; all negative thoughts which can spread among team members, creating a vicious spiral. Tip 5 Don\u2019t Live with Broken Windows Don\u2019t leave \"broken windows\" (bad designs, wrong decisions, or poor code) unrepaired. Fix each one as soon as it is discovered. If there is insufficient time to fix it properly, then board it up. Perhaps you can comment out the offending code, or display a \"Not Implemented\" message, or substitute dummy data instead. Take some action to prevent further damage and to show that you\u2019re on top of the situation. We\u2019ve seen clean, functional systems deteriorate pretty quickly. You may be thinking that no one has the time to go around cleaning up all the broken glass of a project. If so, then you\u2019d better plan on getting a dumpster, or moving to another neighborhood. Don\u2019t let entropy win. 4 Stone Soup and Boiled Frogs Stone soup - allegory to the soldiers coming back from war stopping at village hoping for some food. Villagers didn't want to share the food. The soldiers boiled a pot of water and carefully placed three stones into it. The amazed villagers came out to watch. Once villagers started to seeing what's happening one by one get more interested and ask about it, in return they hear from soldiers. \"The stone soup is good as it is, but some say it tests better when we add X\" which cause villagers to start to share their supply with soldiers. Eventually they had produced a large pot of steaming soup. The soldiers removed the stones, and they sat down with the entire village to enjoy the first square meal any of them had eaten in months. The soldiers act as a catalyst, bringing the village together, so they can jointly produce something that they couldn\u2019t have done by themselves\u2014a synergistic result. Eventually everyone wins. Tip 6 Be a Catalyst for Change Work out what you can reasonably ask for. Develop it well. Once you\u2019ve got it, show people, and let them marvel. Then say \"of course, it would be better if we added\u2026\" Pretend it\u2019s not important. Sit back and wait for them to start asking you to add the functionality you originally wanted. People find it easier to join an ongoing success. Show them a glimpse of the future, and you\u2019ll get them to rally around. boiled frog - that if you take a frog and drop it into boiling water, it will jump straight back out again. However, if you place the frog in a pan of cold water, then gradually heat it, the frog won\u2019t notice the slow increase in temperature and will stay put until cooked. The frog just doesn't notice the change. Don\u2019t be like the fabled frog. Keep an eye on the big picture. Constantly review what\u2019s happening around you, not just what you personally are doing. 5 Good-Enough Software The scope and quality of the system you produce should be discussed as part of that system\u2019s requirements. Great software today is often preferable to the fantasy of perfect software tomorrow. If you give your users something to play with early, their feedback will often lead you to a better eventual solution (Tracer Bullet). 6 Your Knowledge Portfolio Managing a knowledge portfolio is very similar to managing a financial portfolio: Serious investors invest regularly\u2014as a habit . Diversification is the key to long-term success. Smart investors balance their portfolios between conservative and high-risk , high-reward investments. Investors try to buy low and sell high for maximum return. Portfolios should be reviewed and rebalanced periodically. Goals: Learn at least one new language every year Read a technical book each month Read nontechnical books, too Take classes Participate in local user groups and meetups Experiment with different environments Stay current Tip 10 Critically Analyze What You Read and Hear A favorite consulting trick: ask \"why?\" at least five times. Ask a question, and get an answer. Dig deeper by asking \"why?\" Repeat as if you were a petulant four-year old (but a polite one). You might be able to get closer to a root cause this way. Who does this benefit? It may sound cynical, but follow the money can be a very helpful path to analyze. The benefits to someone else or another organization may be aligned with your own, or not. What\u2019s the context? Everything occurs in its own context, which is why \"one size fits all\" solutions often don\u2019t. Consider an article or book touting a \"best practice.\" Good questions to consider are best for \"who?\" What are the prerequisites, what are the consequences, short and long term? When or Where would this work? Under what circumstances? Is it too late? Too early? Don\u2019t stop with first-order thinking (what will happen next), but use second-order thinking: what will happen after that? Why is this a problem? Is there an underlying model? How does the underlying model work? 7 Communicate! Treat English (or whatever your native tongue may be) as just another programming language . Write natural language as you would write code: honor the DRY principle, ETC, automation, and so on. (We discuss the DRY and ETC design principles in the next chapter.) Know Your Audience - By making the appropriate pitch to each group, you\u2019ll get them all excited about your project. As with all forms of communication, the trick here is to gather feedback. Don\u2019t just wait for questions: ask for them. Look at body language, and facial expressions. One of the Neuro Linguistic Programming presuppositions is \"The meaning of your communication is the response you get.\" Continuously improve your knowledge of your audience as you communicate. Know What You Want to Say Fiction writers often plot out their books in detail before they start, but people writing technical documents are often happy to sit down at a keyboard, enter: 1. Introduction Plan what you want to say. Write an outline. Then ask yourself, \"Does this communicate what I want to express to my audience in a way that works for them?\" Refine it until it does. Choose Your Moment Catch a manager who\u2019s just been given a hard time by her boss because some source code got lost, and you\u2019ll have a more receptive listener to your ideas on source code repositories. Make what you\u2019re saying relevant in time, as well as in content. Sometimes all it takes is the simple question, \"Is this a good time to talk about\u2026?\" Make It Look Good Too many developers (and their managers) concentrate solely on content when producing written documents. We think this is a mistake. Any chef (or watcher of the Food Network) will tell you that you can slave in the kitchen for hours only to ruin your efforts with poor presentation. There is no excuse today for producing poor-looking printed documents. Involve Your Audience If possible, involve your readers with early drafts of your document. Get their feedback, and pick their brains. You\u2019ll build a good working relationship, and you\u2019ll probably produce a better document in the process. Be a Listener There\u2019s one technique that you must use if you want people to listen to you: listen to them. Even if this is a situation where you have all the information, even if this is a formal meeting with you standing in front of 20 suits\u2014if you don\u2019t listen to them, they won\u2019t listen to you. Encourage people to talk by asking questions, or ask them to restate the discussion in their own words. Turn the meeting into a dialog, and you\u2019ll make your point more effectively. Who knows, you might even learn something. Get Back to People Always respond to emails and voicemails, even if the response is simply \"I\u2019ll get back to you later\". communicate. The more effective that communication, the more influential you become. Keep code and documentation together Writing documentation can be made easier by not duplicating effort or wasting time, and by keeping documentation close at hand\u2014in the code itself. In fact, we want to apply all of our pragmatic principles to documentation as well as to code. It\u2019s easy to produce good-looking documentation from the comments in source code, and we recommend adding comments to modules and exported functions to give other developers a leg up when they come to use it. Restrict your non-API commenting to discussing why something is done, its purpose and its goal. The code already shows how it is done, so commenting on this is redundant\u2014and is a violation of the DRY principle. Online Communication tips Our tips are simple: Proofread before you hit SEND . Check your spelling and look for any accidental autocorrect mishaps. Keep the format simple and clear. Keep quoting to a minimum. No one likes to receive back their own 100-line email with \"I agree\" tacked on. If you\u2019re quoting other people\u2019s email, be sure to attribute it, and quote it inline (rather than as an attachment). Same when quoting on social media platforms. Don\u2019t flame or act like a troll unless you want it to come back and haunt you later. If you wouldn\u2019t say it to someone\u2019s face, don\u2019t say it online. Check your list of recipients before sending. It\u2019s become a clich\u00e9 to criticize the boss over departmental email without realizing that the boss is on the cc list. Better yet, don\u2019t criticize the boss over email. As countless large corporations and politicians have discovered, email and social media posts are forever. Try to give the same attention and care to email as you would to any written memo or report. 2 A Pragmatic Approach The Essence of Good Design Tip 14 Good Design Is Easier to Change Than Bad Design ETC - easier to change - principle every design principle out there is a special case of ETC. Why is decoupling good? Because by isolating concerns we make each easier to change. ETC. Why is the single responsibility principle useful? Because a change in requirements is mirrored by a change in just one module. ETC. Why is naming important? Because good names make code easier to read, and you have to read it to change it. ETC! ETC Is a Value, Not a Rule Deliberately ask yourself \"did the thing I just did make the overall system easier or harder to change?\" Do it when you save a file. Do it when you write a test. Do it when you fix a bug. It assumes that a person can tell which of many paths will be easier to change in the future. Much of the time, common sense will be correct, and you can make an educated guess. If you're still not sure which is the best solution, you can: Try to make the code you write replaceable treat this as a way to develop instincts.Note the situation in your engineering day book: the choices you have, and some guesses about change. Leave a tag in the source. Then, later, when this code has to change, you\u2019ll be able to look back and give yourself feedback. It might help the next time you reach a similar fork in the road. 9 DRY - The Devils of Duplication Most people assume that maintenance begins when an application is released, that maintenance means fixing bugs and enhancing features. We think these people are wrong. Programmers are constantly in maintenance mode. Our understanding changes day by day. New requirements arrive and existing requirements evolve as we\u2019re heads-down on the project. Perhaps the environment changes. Whatever the reason, maintenance is not a discrete activity, but a routine part of the entire development process. We feel that the only way to develop software reliably, and to make our developments easier to understand and maintain, is to follow what we call the DRY principle : DRY - Don't Repeat Yourself - Every piece of knowledge must have a single, unambiguous, authoritative representation within a system. Don\u2019t copy-and-paste lines of source is only a part of DRY. DRY is about the duplication of knowledge, of intent. It\u2019s about expressing the same thing in two different places, possibly in two totally different ways. Here\u2019s the acid test: when some single facet of the code has to change, do you find yourself making that change in multiple places, and in multiple different formats? Do you have to change code and documentation, or a database schema and a structure that holds it, or\u2026? If so, your code isn\u2019t DRY. Not All Code Duplication Is Knowledge Duplication Not All Code Duplication Is Knowledge Duplication As part of your online wine ordering application you\u2019re capturing and validating your user\u2019s age, along with the quantity they\u2019re ordering. According to the site owner, they should both be numbers, and both greater than zero. So you code up the validations: def validate_age(value): validate_type(value, :integer) validate_min_integer(value, 0) def validate_quantity(value): validate_type(value, :integer) validate_min_integer(value, 0) The code is the same, but the knowledge they represent is different. The two functions validate two separate things that just happen to have the same rules. That\u2019s a coincidence, not a duplication. 1. DRY Violation in Documentation Don't repeat the intent of the function in the comment. Try to write the function and names in a way that it's self expressing. 2. DRY Violation in Data class Line { Point start; Point end; double length; } we have duplication. The length is defined by the start and end points: change one of the points and the length changes. It\u2019s better to make the length a calculated field: class Line { Point start; Point end; double length() { return star.distanceTo(end); } } It's OK to violate the DRY principle fo performance reasons. e.g. caching the data. Where possible, always use accessor functions to read and write the attributes of objects. It will make it easier to add functionality in the future. All services offered by a module should be available through a uniform notation, which does not betray whether they are implemented through storage or through computation. 2. DRY Violation in Representation Your code needs to know how to communicate with libraries, API or the schemas (e.g. error codes). The duplication here is that two things (your code and the external entity) have to have knowledge of the representation of their interface. Change it at one end, and the other end breaks. Some strategies: Duplication across internal API - look for tools that let you specify the API in some kind of neutral format. These tools will typically generate documentation, mock APIs, functional tests, and API clients, the latter in a number of different languages. Ideally the tool will store all your APIs in a central repository, allowing them to be shared across teams. Duplication Across External APIs - Increasingly, you\u2019ll find that public APIs are documented formally using something like OpenAPI.This allows you to import the API spec into your local API tools and integrate more reliably with the service. If you can\u2019t find such a specification, consider creating one and publishing it. Not only will others find it useful; you may even get help maintaining it. Duplication with Data Sources - Many data sources allow you to introspect on their data schema. This can be used to remove much of the duplication between them and your code. Rather than manually creating the code to contain this stored data, you can generate the containers directly from the schema. Many persistence frameworks will do this heavy lifting for you. There\u2019s another option, and one we often prefer. Rather than writing code that represents external data in a fixed structure (an instance of a struct or class, for example), just stick it into a key/value data structure (your language might call it a map, hash, dictionary, or even object). On its own this is risky: you lose a lot of the security of knowing just what data you\u2019re working with. So we recommend adding a second layer to this solution: a simple table-driven validation suite that verifies that the map you\u2019ve created contains Inter-developer Duplication - at the module level, the problem is more insidious. Commonly needed functionality or data that doesn\u2019t fall into an obvious area of responsibility can get implemented many times over. We feel that the best way to deal with this is to encourage active and frequent communication between developers. Maybe run a daily scrum standup meeting. Set up forums (such as Slack channels) to discuss common problems. This provides a non-intrusive way of communicating\u2014even across multiple sites\u2014while retaining a permanent history of everything said. Appoint a team member as the project librarian, whose job is to facilitate the exchange of knowledge. Have a central place in the source tree where utility routines and scripts can be deposited. And make a point of reading other people\u2019s source code and documentation, either informally or during code reviews. You\u2019re not snooping\u2014you\u2019re learning from them. And remember, the access is reciprocal\u2014don\u2019t get twisted about other people poring (pawing?) through your code, either. 10 Orthogonality \"Orthogonality\" is a term borrowed from geometry. Two lines are orthogonal if they meet at right angles, such as the axes on a graph. It's generalization of the geometric notion of perpendicularity. In computing, the term has come to signify a kind of independence or decoupling. Two or more things are orthogonal if changes in one do not affect any of the others. We want to design components that are self-contained: independent, and with a single, well-defined purpose (what Yourdon and Constantine call cohesion in Structured Design: Fundamentals of a Discipline of Computer Program and Systems Design[YC79]). When components are isolated from one another, you know that you can change one without having to worry about the rest. As long as you don\u2019t change that component\u2019s external interfaces, you can be confident that you won\u2019t cause problems that ripple through the entire system. Two major benefits if you write orthogonal systems: increased productivity - It is easier to write relatively small, self-contained components than a single large block of code. Simple components can be designed, coded, tested, and then forgotten\u2014there is no need to keep changing existing code as you add new code. reduced risk - Diseased sections of code are isolated. If a module is sick, it is less likely to spread the symptoms around the rest of the system. It is also easier to slice it out and transplant in something new and healthy. Most developers are familiar with the need to design orthogonal systems, although they may use words such as modular, component-based, and layered to describe the process. Orthogonality is closely related to the DRY principle. With DRY, you\u2019re looking to minimize duplication within a system, whereas with orthogonality you reduce the interdependency among the system\u2019s components. It may be a clumsy word, but if you use the principle of orthogonality, combined closely with the DRY principle, you\u2019ll find that the systems you develop are more flexible, more understandable, and easier to debug, test, and maintain. 11 Reversibility What you can do is make it easy to change. Hide third-party APIs behind your own abstraction layers. Break your code into components: even if you end up deploying them on a single massive server, this approach is a lot easier than taking a monolithic application and splitting it. 12 Tracer Bullets the term tracer bullet development is used to visually illustrate the need for immediate feedback under actual conditions with a moving goal. Tracer bullets work because they operate in the same environment and under the same constraints as the real bullets. They get to the target fast, so the gunner gets immediate feedback. And from a practical standpoint they\u2019re a relatively cheap solution. Look for the important requirements, the ones that define the system. Look for the areas where you have doubts, and where you see the biggest risks. Then prioritize your development so that these are the first areas you code. Tracer code is not disposable: you write it for keeps. It contains all the error checking, structuring, documentation, and self-checking that any piece of production code has. It simply is not fully functional. However, once you have achieved an end-to-end connection among the components of your system, you can check how close to the target you are, adjusting if necessary. Once you\u2019re on target, adding functionality is easy. Tracer development is consistent with the idea that a project is never finished: there will always be changes required and functions to add. It is an incremental approach. The tracer code approach has many advantages: Users get to see something working early - your users will know they are seeing something immature. They won\u2019t be disappointed by a lack of functionality; they\u2019ll be ecstatic to see some visible progress toward their system. Developers build a structure to work in - it. If you have worked out all the end-to-end interactions of your application, and have embodied them in code, then your team won\u2019t need to pull as much out of thin air. This makes everyone more productive, and encourages consistency. You have an integration platform - have an integration platform As the system is connected end-to-end, you have an environment to which you can add new pieces of code once they have been unit-tested. You have something to demonstrate You have a better feel for progress Tracer Code versus Prototyping You might think that this tracer code concept is nothing more than prototyping under an aggressive name. There is a difference. With a prototype, you\u2019re aiming to explore specific aspects of the final system. With a true prototype, you will throw away whatever you lashed together when trying out the concept, and recode it properly using the lessons you\u2019ve learned. The tracer code approach addresses a different problem. You need to know how the application as a whole hangs together. You want to show your users how the interactions will work in practice, and you want to give your developers an architectural skeleton on which to hang code. 13 Prototypes and Post-it Notes What sorts of things might you choose to investigate with a prototype? Anything that carries risk. Anything that hasn\u2019t been tried before, Anything that is absolutely critical to the final system. Anything unproven, experimental, or doubtful. Anything you aren\u2019t comfortable with. You can prototype: Architecture New functionality in an existing system Structure or contents of external data Third-party tools or components Performance issues User interface design Prototyping is a learning experience. Its value lies not in the code produced, but in the lessons learned. That\u2019s really the point of prototyping. How to Use Prototypes When building a prototype, what details can you ignore? Correctness You may be able to use dummy data where appropriate. Completeness The prototype may function only in a very limited sense, perhaps with only one preselected piece of input data and one menu item. Robustness Error checking is likely to be incomplete or missing entirely. If you stray from the predefined path, the prototype may crash and burn in a glorious display of pyrotechnics. That\u2019s okay. Style Prototype code shouldn\u2019t have much in the way of comments or documentation (although you may produce reams of documentation as a result of your experience with the prototype). 14 Domain Languages We always try to write code using the vocabulary of the application domain (see Maintain a Glossary). In some cases, Pragmatic Programmers can go to the next level and actually program using the vocabulary, syntax, and semantics\u2014the language\u2014of the domain. E.g. Cucumber is programming-language neutral way of specifying tests. You run the tests using a version of Cucumber appropriate to the language you\u2019re using. In order to support the natural-language like syntax, you also have to write specific matchers that recognize phrases and extract parameters for the tests. 15 Estimating Duration Quote estimate in 1-15 days Days 3-6 weeks Weeks 8-20 weeks Months 20+ weeks Think hard before giving an estimate Where Do Estimates Come From? Ask someone who\u2019s already done it. Before you get too committed to model building, cast around for someone who\u2019s been in a similar situation in the past. See how their problem got solved. Understand What\u2019s Being Asked You need to have a grasp of the scope of the domain. Often this is implicit in the question, but you need to make it a habit to think about the scope before starting to guess. Often, the scope you choose will form part of the answer you give: \"Assuming there are no traffic accidents and there\u2019s gas in the car, I should be there in 20 minutes.\" Build a Model of the System From your understanding of the question being asked, build a rough-and-ready bare-bones mental model. Building the model introduces inaccuracies into the estimating process. This is inevitable, and also beneficial. You are trading off model simplicity for accuracy. Doubling the effort on the model may give you only a slight increase in accuracy. Your experience will tell you when to stop refining. Break the Model into Components Once you have a model, you can decompose it into components. You\u2019ll need to discover the mathematical rules that describe how these components interact. Sometimes a component contributes a single value that is added into the result. You\u2019ll find that each component will typically have parameters that affect how it contributes to the overall model. At this stage, simply identify each parameter. Give Each Parameter a Value Once you have the parameters broken out, you can go through and assign each one a value. You expect to introduce some errors in this step. The trick is to work out which parameters have the most impact on the result, and concentrate on getting them about right. Typically, parameters whose values are added into a result are less significant than those that are multiplied or divided. Calculate the Answers A spreadsheet can be a big help. Then couch your answer in terms of these parameters. During the calculation phase, you get answers that seem strange. Don\u2019t be too quick to dismiss them. If your arithmetic is correct, your understanding of the problem or your model is probably wrong. This is valuable information. Keep Track of Your Estimating Prowess We think it\u2019s a great idea to record your estimates, so you can see how close you were. If an overall estimate involved calculating sub-estimates, keep track of these as well. Often you\u2019ll find your estimates are pretty good\u2014in fact, after a while, you\u2019ll come to expect this. Estimating Project Schedules -Painting the Missile \"How long will it take to paint the house?\" \"Well, if everything goes right, and this paint has the coverage they claim, it might be as few as 10 hours. But that\u2019s unlikely: I\u2019d guess a more realistic figure is closer to 18 hours. And, of course, if the weather turns bad, that could push it out to 30 or more.\" That\u2019s how people estimate in the real world. Not with a single number (unless you force them to give you one) but with a range of scenarios. What to Say When Asked for an Estimate You say \u201cI\u2019ll get back to you.\u201d You almost always get better results if you slow the process down and spend some time going through the steps we describe in this section. Estimates given at the coffee machine will (like the coffee) come back to haunt you. 3 The Basic Tools As a developer you need to know the set of tools you should be using in your work to be efficient. 16 The Power of Plain Text Keep Knowledge in Plain Text Plain text doesn\u2019t mean that the text is unstructured; HTML, JSON, YAML, and so on are all plain text. So are the majority of the fundamental protocols on the net, such as HTTP, SMTP, IMAP, and so on. And that\u2019s for some good reasons: Insurance against obsolescence - human-readable (and human understandable!) forms of data and self-describing data will outlive all other forms of data and the applications that created them. Leverage existing tools - virtually every tool can work with plain text Easier testing 17 Shell Games Every programmer needs to manipulate files of text for that purpose we should learn command shell. From the shell prompt you can invoke your full repertoire of tools, using pipes, to combine them in ways never dreamt of by their original developers. From shell, you can launch applications, debuggers, browsers, editors and utilities. You can search for files, query the status of the system and filter output. If you can do everything inside your IDE with UI why would you need it? A benefit of GUI is WYSIWYG - What You See Is What You Get. The disadvantage is WYSIAYG - What You See Is All You Get. Tip 26 Use the power of Command Shells Make sure to configure and customize shell to your needs: setting color themes configuring a prompt aliases and shell functions command completion 18 Power Editing Achieve Editor Fluency Here\u2019s the challenge list (without using mouse/trackpad): When editing text, move and make selections by character, word, line, and paragraph. When editing code, move by various syntactic units (matching delimiters, functions, modules, \u2026). Reindent code following changes. Comment and uncomment blocks of code with a single command. Undo and redo changes. Split the editor window into multiple panels, and navigate between them. Navigate to a particular line number. Sort selected lines. Search for both strings and regular expressions, and repeat previous searches. Temporarily create multiple cursors based on a selection or on a pattern match, and edit the text at each in parallel. Display compilation errors in the current project. Run the current project\u2019s tests. 19 Version Control Always Use Version Control - not only for code repositories. For Everything: notes, prototype, configuration, system settings 20 Debugging Embrace the fact that debugging is just problem-solving and attack it as such. A debugging mindset don't panic, think about what could be causing the symptoms that you believe indicate a bug. Before you start to look at the bug make sure that you are working on code that built cleanly - without warnings. gather all relevant data talk/interview to reported, go together though the issue if you can't reproduce it. Debugging Strategies Failing Test Before Fixing Code Read the Damn Error Message! Make sure that you also see incorrect value in the debugger Jot down notes, when you find a clue and chase it down only to find it didn't pan out - it would be easier to come back to where you were before. If it is an input values problem recreate it on full list and start chopping it. Use the Binary Chop when going through stack trace to find the root of the issue Use logging Talk to rubber Duck Use Process of Elimination - if you changed one thing which looks not related to the problem at glance, double check it because you might be wrong. Don't assume, prove it. Make sure it won't repeat. Fix Unit Tests, mend them, analyze the data, check other places in the code where it can happen. 21 Text manipulation Learn a Text Manipulation Language. On Linux (or Mac) users often use tools such as awk and sed. Sometimes Python, Ruby, Perl. Ruby and Python were used to create a pragmatic Programmer book: Building the book - the build system for the bookshelf is written in Ruby. Authors, editors, layout people and support folk use Rake tasks to coordinate the building of PDFs and ebooks. Code inclusion and highlighting - the source codes examples in books are taken from repository to follow the DRY principle. Website update - simple script that does a partial book build, extracts the table of contents, then uploads it to the book's page on our website. Including equations - Python script that converts LaTeX math markup into formatted text. Index Generation - indexes are created as separate documents. Ruby script collates and formats the entries. 22 Engineering Daybooks We use daybooks to take notes in meetings, to jot down what we\u2019re working on, to note variable values when debugging, to leave reminders where we put things, to record wild ideas, and sometimes just to doodle. The daybook has three main benefits: It is more reliable than memory. People might ask \u201cWhat was the name of that company you called last week about the power supply problem?\u201d and you can flip back a page or so and give them the name and number. It gives you a place to store ideas that aren\u2019t immediately relevant to the task at hand. That way you can continue to concentrate on what you are doing, knowing that the great idea won\u2019t be forgotten. It acts as a kind of rubber duck (described here). When you stop to write something down, your brain may switch gears, almost as if talking to someone\u2014a great chance to reflect. You may start to make a note and then suddenly realize that what you\u2019d just done, the topic of the note, is just plain wrong. There\u2019s an added benefit, too. Occasionally you can look back at what you were doing oh-so-many-years-ago and think about the people, the projects, and the awful clothes and hairstyles. 4 Pragmatic Paranoia Tip 36 you can't write perfect software Perfect software doesn't exist, don't waste time and energy chasing an impossible dream. How to turn it into an advantage? If you think that someone code might not live up to your standards, don't trust your code either - no one writes perfect code. 23 Design by Contract DBC - Design By Contract - technique that focuses on documenting the rights and responsibilities of software modules to ensure program correctness. What is correct program? One that does no more and no less than it claims to do. Documenting and verifying that claim is the role of DBC. Every function does something - Before it starts doing something it might have expectations of the state, and also it can modify that state. These expectations and claims are: Pre-conditions - what must be true in order for the function to be called (it's the caller responsibility to pass good data) Post-conditions - what function is guaranteed to do. - the state when the function is done. Class invariants / state - class ensures that this condition is always true from the perspective of a caller. So the contract between the caller and module is: If all function\u2019s preconditions are met by the caller, the function shall guarantee that all post conditions and invariants will be true when it completes. If something is not as in contract the remedy is to raise exception. Or Even better disable the possibility to call the function with wrong values. E.g. on Android you can use @StringRes which indicates that the Int value needs to come from android resources. Be strict in what you will accept before you begin, promise as little as possible in return. Implementing DBC Simply enumerating what the input domain range is, what the boundary conditions are, and what the routine promises to deliver. Assertions you can get much greater benefit by having the compiler check your contract for you. You can partially emulate this in some languages by using assertions: runtime checks for logical conditions. Who is responsible for checking the preconditions, the caller or the method being called? When DBC is implemented by the language - neither. it's tested behind the scene after caller invokes the method but before the mother runs. If there is any explicit checking of parameters to be done, it must be performed by the caller because the method will never see parameters that violate its precondition. For non-supporting DBC languages you need to bracket the called method with preamble and/or post-amble that checks these assertions. Consider a program that reads a number from the console, calculates its square root (by calling sqrt), and prints the result. The sqrt function has a precondition\u2014its argument must not be negative. If the user enters a negative number at the console, it is up to the calling code to ensure that it never gets passed to sqrt. This calling code has many options: it could terminate, it could issue a warning and read another number, or it could make the number positive and append an i to the result returned by sqrt. Whatever its choice, this is definitely not sqrt\u2019s problem. By expressing the domain of the square root function in the precondition of the sqrt routine, you shift the burden of correctness to the caller\u2014where it belongs. You can then design the sqrt routine secure in the knowledge that its input will be in range. Crashing Early gives you possibility to report more accurate information about the problem. 24 Dead Programs Tell No Lies Catch and release is for fish avoid using try-catch to catch all possible errors. The application code isn't eclipsed by the error code. The code is less coupled. If the writer of the method adds another exception our code is subtly out of date. Without try catch it's propagated. same\u2014when your code discovers that something that was supposed to be impossible just happened, your program is no longer viable. Anything it does from this point forward becomes suspect, so terminate it as soon as possible. 25 Assertive Programming Tip 39 Use Assertions to prevent the impossible In the Java implementation, you can (and should) add a descriptive string: assert result! = null && result.size() > 0 : \"Empty result from XYZ\"; Don\u2019t use assertions in place of real error handling. Assertions check for things that should never happen. Your first line of defense is checking for any possible error, and your second is using assertions to try to detect those you\u2019ve missed. 26 Hot to Balance Resources The function that allocates a resource should be responsible for deallocating it. Deallocate resources with LIFO principle. When allocating the same set of resource in different places in your code, always allocate them in the same order to avoid deadlock. There are times when the basic resource allocation pattern just isn\u2019t appropriate. Commonly this is found in programs that use dynamic data structures. One routine will allocate an area of memory and link it into some larger structure, where it may stay for some time. The trick here is to establish a semantic invariant for memory allocation. You need to decide who is responsible for data in an aggregate data structure. What happens when you deallocate the top-level structure? You have three main options: The top-level structure is also responsible for freeing any substructures that it contains. These structures then recursively delete data they contain, and so on. The top-level structure is simply deallocated. Any structures that it pointed to (that are not referenced elsewhere) are orphaned. The top-level structure refuses to deallocate itself if it contains any substructures. 27 Don't Outrun Your Headlights Tip 42 Always take small steps Always take small, deliberate steps, checking for feedback and adjusting before proceeding. Consider that the rate of feedback is your speed limit. You never take on a step or a task that\u2019s \u201ctoo big.\u201d What do we mean exactly by feedback? Anything that independently confirms or disproves your action. For example: Results in a REPL provide feedback on your understanding of APIs and algorithms Unit tests provide feedback on your last code change User demo and conversation provide feedback on features and usability What's a task that's too big? Any task that requires \"fortune-telling\". We can only see into the future perhaps one or two steps, maybe a few hours or days at most. From that you can quickly past educated guess into wild speculation. When the fortune-telling starts? estimate completion dates months in the future Plan a design for future maintenance or extendability Guess user's future needs Guess future tech availability you should design for future maintenance but only to a point - only as far ahead as you can see. 5 Bend, or break 28 Decoupling Tip 44 Decoupled Code is easier to change symptoms of coupling: wacky dependencies between unrelated modules or libraries \"simple\" changes to one module that propagate through unrelated modules in the system or break stuff elsewhere in the system developers who are afraid to change code because they aren't sure what might be affected. meeting where everyone has to attend because no one is sure who will be affected by a change types of coupling: Train wrecks - chains of method calls Globalization - the dangers of static things Inheritance - why subclassing is dangerous Train wrecks We\u2019ve all seen (and probably written) code like this: public void applyDiscount(customer, order_id, discount) { totals = customer .orders .find(order_id) .getTotals(); totals.grandTotal = totals.grandTotal - discount; totals.discount = discount; } This chunk of code is traversing five levels of abstraction from customer to total amount. Ultimately our top-level code has to know that a customer object exposes orders, that the orders have a find method that takes an order id and returns an order, and that the order object has a totals object which has getters and setters for grand totals and discounts. That's a lof of implicit knowledge. But worse, that's a lot of things that cannot change in the future if this code is to continue to work. All the cars in a train are coupled together as are all the methods and attributes in a train wreck. How to fix? use Tell, don't ask . TDA - you shouldn't make decision based on the internal state of an object and then update that object. It destroys the benefit of encapsulation and in doing so spreads the knowledge of the implementation throughout the code. proper solution public void applyDiscount(customer, order_id, discount) { customer .findOrder(order_id) .applyDiscount(discount); } alternative you could try to create applyDiscountToOrder(order_id) , but TDA is just a pattern if you think (or it's required anyway) to expose the customer has orders, and we can find it, then it is pragmatic decision. The Law Of Demeter, LoD - set of guidelines that help developers keep their functions cleaner and decoupled. The LoD says that a method defined in a class C should only call: Other instance methods in C Its parameters Methods in objects that it creates, both on the stack and in the heap Global variables simpler recommended version is: Don't Chain Method Calls // poor style val amount = customer.orders.last().totals().amount // and so is this val orders = customer.orders val last = order.last() val totals = last.totals() val amount = totals.amount Big exception to the one-dot rule: the rule doesn't apply if the things you're chaining are really, really unlikely to change. In practice, anything in your application should be considered likely to change. Anything in a third-party library should be considered volatile, particularly if the maintainers of the library are known to change API between releases. Libraries that come with the language however are probably pretty stable, and we would be happy with the code such as. people.sortBy { it.age } .first(10) .map { it.name } The Evils of Globalization Globals couple code for many reasons. The most obvious is that a change to the implementation of the global potentially affects all the code in the system. In practice, of course, the impact is fairly limited; the problem really comes down to knowing that you\u2019ve found every place you need to change. Global data also creates coupling when it comes to teasing your code apart. You\u2019ll see this problem when you\u2019re writing unit tests for code that uses global data. You\u2019ll find yourself writing a bunch of setup code to create a global environment just to allow your test to run. If It\u2019s Important Enough to Be Global, Wrap It in an API Always use abstraction to represent global data (if you can't avoid having global one), same applies for third-party library. Inheritance adds coupling It's so important that it has separate topic [31] 29 Juggling the Real World Events are everywhere. Some are obvious: a button click, a timer expiring. Other are less so: someone logging in, a line in a file matching a pattern. But whatever their source, code that\u2019s crafted around events can be more responsive and better decoupled than its more linear counterpart. Strategies to handle the events: Finite State Machines The Observer Pattern Publish/Subscribe Reactive Programming and Streams Finite State Machines State machine is basically just a specification of how to handle events. It consists of a set of states, one of which is the current state. For each state we list the events that are significant to that state. For Each of those event we define new current state of the system. Stet machines are underused by developers. Though they don't solve all the problems associated with events. The Observer Pattern Observable - source of events Observers - clients who are interested in those events. observer registers its interest with the observable typically by passing a reference to a function to be called. It is particularly prevalent in user interface system where the callbacks are used to inform the application that some interaction has occurred. But it introduces coupling ! also it can introduce performance bottlenecks. (both solved by Publish/Subscribe pattern). Publish/Subscribe it generalizes the observer pattern, at the same time solves the problems of coupling and performance. We have publishers and subscribers, these are connected via channels . The channels are implemented in a separate body of code: sometimes a library, sometimes a process, and sometimes a distributed infrastructure. All this implementation detail is hidden from your code. Every channel has a name. Subscribers register interest in one or more of these named channels, and publishers write events to them. Unlike the observer pattern, the communication between the publisher and subscriber is handled outside your code, and is potentially asynchronous. PubSub modules are provided in language as library. Compared to the observer pattern, pubsub is a great example of reducing coupling by abstracting up through a shared interface (the channel). However, it is still basically just a message passing system. Reactive Programming, Streams and Events If you\u2019ve ever used a spreadsheet, then you\u2019ll be familiar with reactive programming. If a cell contains a formula which refers to a second cell, then updating that second cell causes the first to update as well. The values react as the values they use change. Streams allow us treat events as if they were a collection of data (list of events which gets longer when new events arrive). The beauty of that is that we can treat streams just like any other collection: we can manipulate, combine, filter, and do all the other data-ish things we know so well. We can even combine event streams and regular collections. And streams can be asynchronous , which means your code gets the opportunity to respond to events as they arrive. This is a very powerful abstraction: we no longer need to think about time as being something we have to manage. Event streams unify synchronous and asynchronous processing behind a common, convenient API. 30 Transforming Programming We should more often think about programs as being something that transforms inputs into outputs. This chapter talks about a way we can chain object transformations to get what we want word |> all_subsets_longer_than_three_characters() |> as_unique_signatures() |> find_in_dictionary() |> group_by_length() It\u2019s simply a chain of the transformations needed to meet our requirement, each taking input from the previous transformation and passing output to the next. That comes about as close to literate code as you can get. But there\u2019s something deeper, too. If your background is object-oriented programming, then your reflexes demand that you hide data, encapsulating it inside objects. These objects then chatter back and forth, changing each other\u2019s state. This introduces a lot of coupling, and it is a big reason that OO systems can be hard to change. Tip 50 Don\u2019t Hoard State; Pass It Around In the transformational model, we turn that on its head. Instead of little pools of data spread all over the system, think of data as a mighty river, a flow. Data becomes a peer to functionality: a pipeline is a sequence of code \u2192 data \u2192 code \u2192 data\u2026. The data is no longer tied to a particular group of functions, as it is in a class definition. Instead, it is free to represent the unfolding progress of our application as it transforms its inputs into its outputs. This means that we can greatly reduce coupling: a function can be used (and reused) anywhere its parameters match the output of some other function. Yes, there is still a degree of coupling, but in our experience it\u2019s more manageable than the OO-style of command and control. And, if you\u2019re using a language with type checking, you\u2019ll get compile-time warnings when you try to connect two incompatible things. In Language X Doesn\u2019t Have Pipelines we wrote: const content = File.read(file_name); const lines = find_matching_lines(content, pattern) const result = truncate_lines Many people write OO code by chaining together method calls, and might be tempted to write this as something like: const result = content_of(file_name) .find_matching_lines(pattern) .truncate_lines() What\u2019s the difference between these two pieces of code? Which do you think we prefer? Let\u2019s answer the second part first: we prefer the first piece of code. In the second chunk of code, each step returns an object that implements the next function we call: the object returned by content_of must implement find_matching_lines, and so on. This means that the object returned by content_of is coupled to our code. Imagine the requirement changed, and we have to ignore lines starting with a # character. In the transformation style, that would be easy: const content = File.read(file_name); const no_comments = remove_comments(content) const lines = find_matching_lines(no_comments, pattern) const result = truncate_lines(lines) We could even swap the order of remove_comments and find_matching_lines and it would still work. But in the chained style, this would be more difficult. Where should our remove_comments method live: in the object returned by content_of or the object returned by find_matching_lines? And what other code will we break if we change that object? This coupling is why the method chaining style is sometimes called a train wreck . 31 Inheritance Tax Stop using inheritance. Inheritance is coupling. Not only is the child class coupled to the parent, the parent's parent and so on, but the code that uses the child is also coupled to all the ancestors. using inheritance to build types (relation) tends to create complexity. Better alternatives: Interfaces and protocols - Prefer interfaces to express polymorphism instead of inheritance Delegation - instead of trying to inherit method from some class delegate the work to class that contains the code, by injecting particular object instead of inherit from it. Mixins and traits - allows to share the methods between different objects 32 Configuration Parametrize your app using external configuration. Common things you will want to put in configuration data include: credentials for external services (database, third party APIs and so on) logging levels and destinations port, ip address, machine, and cluster names the app uses Environment=specific validation parameters Externally set parameters, such as tax tares Site-specific formatting details License keys Basically, anything that you know will have to change that you can express outside your main body of code and slap it into some configuration bucket. create thin API to access configuration files and keep it behind a Service benefits: sharing configuration information Configuration changes ca be made globally Configuration data can be maintained via a specialized UI configuration data become dynamic without external configuration your code is not as adaptable or flexible as it could be. Don't overdo it, not everything should be in config files, focus on most important things. 6 Concurrency definition: Concurrency is when the execution of two or more pieces of code act as if they run at the same time. Parallelism is when they do run at the same time. concurrency is a software mechanism, and parallelism is a hardware concern. If we have multiple processors, either locally or remotely, then if we can split work out among them, we can reduce the overall time things take. 33 Breaking Temporal Coupling temporal coupling - coupling in time. Method A must always be called before method B, only one report can be run at a time, you must wait for the screen to redraw before the button click is received. Tick must happen before tock. This is not very flexible and not very realistic. Allowing concurrency and think about decoupling of any time or order dependencies. Result: systems that are easier to reason about, that potentially respond faster and more reliably. Looking for concurrency In many projects we'd like to find out what can happen at the same time and what must in a strict order. One way to do is by activity diagram . activity diagram - set of actions (drawn as rounded boxes). The arrow leads an action leads to either: another action (which can start after the first action completes) thick line called a synchronization bar once all actions leading into a synchronization bar are complete you can then proceed along any arrows leaving the bar, An action with no arrows leading into it can be started at any time. Activity diagram is used to maximize parallelism by identifying activities that could be performed in parallel but aren't. For instance, we may be writing the software for a robotic pi\u00f1a colada maker. We\u2019re told that the steps are: Open blender Open pi\u00f1a colada mix Put mix in blender Measure 1/2 cup white rum Pour in rum Add 2 cups of ice Close blender Liquefy for 1 minute Open blender Get glasses Get pink umbrellas Serve the top-level tasks (1, 2, 4, 10, and 11) can all happen concurrently, up front. Tasks 3, 5, and 6 can happen in parallel later. When we look at the activities, we realize that number 8, liquefy, will take a minute. During that time, our bartender can get the glasses and umbrellas (activities 10 and 11) and probably still have time to serve another customer. 34. Shared State is Incorrect State Customer is in restaurant asks server if there is a pie left, he looks, sees in the display that there is one left piece and confirms. Customer orders the pie. Same thing happens on the other side of the restaurant at exact time. One of the customers will be disappointed. Both waiters operate concurrently (in real life in parallel). The problem above is shared state. Both waiters when executes display_case.pie_count() they copy the value from the display into their own memory. If the value in the display case changes their memory (which is used to make decision) is now out of date. Solution? make the operation atomic. Semaphore is a thing that only one person can own at a time. (lock/unlock claim/release) In above example it can be used to decide who can access pie case. case_semaphore.lock() if display_case.pie_count > 0 promise_pie_to_customer() display_case.take_pie() give_pie_to_customer() end case_semaphore.unlock() This approach above works and solve mentioned issue, but there is another problem. This approach as long as every developer will use the semaphore, it that's not the case we are in the same place as before. Make the Resource Transactional We can centralize that control by checking and getting pie in one call: def get_pie_if_available() @case_semaphore.lock() try { if @slices.size > 0 update_sales_data(:pie) return @slices.shift else false end } ensue { @case_semaphore.unlock() } end Random Failures Are Often Concurrency Issues 35 Actors and Processes An actor is an independent virtual processor with its own local (and private) state. Each actor has a mailbox. When a message appears in the mailbox and the actor is idle, it kicks into life and processes the message. When it finishes processing, it processes another message in the mailbox, or, if the mailbox is empty, it goes back to sleep. When processing a message, an actor can create other actors, send messages to other actors that it knows about, and create a new state that will become the current state when the next message is processed. A process is typically a more general-purpose virtual processor, often implemented by the operating system to facilitate concurrency. Processes can be constrained (by convention) to behave like actors, and that\u2019s the type of process we mean here. Actors Can Only Be Concurrent There are a few things that you won\u2019t find in the definition of actors: There\u2019s no single thing that\u2019s in control. Nothing schedules what happens next, or orchestrates the transfer of information from the raw data to the final output. The only state in the system is held in messages and in the local state of each actor. Messages cannot be examined except by being read by their recipient, and local state is inaccessible outside the actor. All messages are one way\u2014there\u2019s no concept of replying. If you want an actor to return a response, you include your own mailbox address in the message you send it, and it will (eventually) send the response as just another message to that mailbox. An actor processes each message to completion, and only processes one message at a time. As a result, actors execute concurrently, asynchronously, and share nothing. If you had enough physical processors, you could run an actor on each. If you have a single processor, then some runtime can handle the switching of context between them. Either way, the code running in the actors is the same. Tip 59 Use Actors for concurrency without Shared State Topic 36 Blackboards Blackboard is a common (shared?) space where multiple independent actors/processes/agents can access the stored data in a form of laissez-faire concurrency, 7 While You Are Coding 37 Listen to Your Lizard Brain Tip 61 Listen to Your Inner Lizard First, stop what you\u2019re doing. Give yourself a little time and space to let your brain organize itself. Stop thinking about the code, do something that is fairly mindless for a while, away from a keyboard. Take a walk, have lunch, chat with someone. Maybe sleep on it. Let the ideas percolate up through the layers of your brain on their own: you can\u2019t force it. wait for a \"ha!\" moment. If that doesn't work, try to explain the code to someone (even to rubber duck). If still you have a problem, it's time for prototyping. 38 Programming by Coincidence Why should you take the risk of messing with something that\u2019s working? Well, we can think of several reasons: It may not really be working\u2014it might just look like it is. The boundary condition you rely on may be just an accident. In different circumstances (a different screen resolution, more CPU cores), it might behave differently. Undocumented behavior may change with the next release of the library. Additional and unnecessary calls make your code slower. Additional calls increase the risk of introducing new bugs of their own. For code, you write that others will call, the basic principles of good modularization and of hiding implementation behind small, well-documented interfaces can all help. tip: never store a phone number in numeric field 39 Algorithm Speed Big-O Notation - mathematical way of dealing with approximations. highest-order term will dominate the value as increases, the convention is to remove all low-order terms, and not to bother showing any constant multiplying: O(n^2/2 + 3n) == O(n^2) == O(n^2) O(1) - Constant (access element in array, simple statements) O(lg n) - Logarithmic (binary search). The base of the logarithm doesn\u2019t matter, so this is equivalent. O(n) - Linear (sequential search) O(n lg n) - Worse than linear, but not much worse. (Average runtime of quicksort, heapsort) O(n^2) - Square law (selection and insertion sorts) O(n^3) - Cubic (multiplication of two matrices) O(C^n) - Exponential (traveling salesman problem, set partitioning) 40 Refactoring Software development is like gardening -You plant many things in a garden according to an initial plan and conditions. Some thrive, others are destined to end up as compost. You may move plantings relative to each other to take advantage of the interplay of light and shadow, wind and rain. Overgrown plants get split or pruned, and colors that clash may get moved to more aesthetically pleasing locations. You pull weeds, and you fertilize plantings that are in need of some extra help. You constantly monitor the health of the garden, and make adjustments (to the soil, the plants, the layout) as needed. Refactoring [Fow19] is defined by Martin Fowler as a: disciplined technique for restructuring an existing body of code, altering its internal structure without changing its external behavior. Time pressure is often used as an excuse for not refactoring. But this excuse just doesn\u2019t hold up: fail to refactor now, and there\u2019ll be a far greater time investment to fix the problem down the road\u2014when there are more dependencies to reckon with. Will there be more time available then? Nope. When explaining think of the code that needs refactoring as \"a growth.\" Removing it requires invasive surgery. You can go in now, and take it out while it is still small. Or, you could wait while it grows and spreads\u2014but removing it then will be both more expensive and more dangerous. Wait even longer, and you may lose the patient entirely. Martin Fowler offers the following simple tips on how to refactor without doing more harm than good: Don\u2019t try to refactor and add functionality at the same time. Make sure you have good tests before you begin refactoring. Run the tests as often as possible. That way you will know quickly if your changes have broken anything. Take short, deliberate steps: move a field from one class to another, split a method, rename a variable. Refactoring often involves making many localized changes that result in a larger-scale change. If you keep your steps small, and test after each step, you will avoid prolonged debugging. 41 Test to Code We believe that the major benefits of testing happen when you think about and write the tests, not when you run them. Why? Because it allows you to understand the under the hood requirements of feature (e.g. parameters) Use TDD, but avoid: They spend inordinate amounts of time ensuring that they always have 100% test coverage. They have lots of redundant tests. For example, before writing a class for the first time, many TDD adherents will first write a failing test that simply references the class\u2019s name. It fails, then they write an empty class definition, and it passes. But now you have a test that does absolutely nothing; the next test you write will also reference the class, and so it makes the first unnecessary. There\u2019s more stuff to change if the class name changes later. And this is just a trivial example. Their designs tend to start at the bottom and work their way up. (TIP 68, Build End-to-End, Not Top-Down or Bottom Up) Build small pieces of end-to-end functionality, learning about the problem as you go. Apply this learning as you continue to flesh out the code, involve the customer at each step, and have them guide the process. The basic cycle of TDD is: Decide on a small piece of functionality you want to add. Write a test that will pass once that functionality is implemented. Run all tests. Verify that the only failure is the one you just wrote. Write the smallest amount of code needed to get the test to pass, and verify that the tests now run cleanly. Refactor your code: see if there is a way to improve on what you just wrote (the test or the function). Make sure the tests still pass when you\u2019re done. The idea is that this cycle should be very short: a matter of minutes, so that you\u2019re constantly writing tests and then getting them to work. 42 Property-Based Testing invariants, things that remain true about some piece of state when it\u2019s passed through a function. For example, if you sort a list, the result will have the same number of elements as the original\u2014the length is invariant. Tip Use property based tests to validate your assumptions There are also code invariants, things that remain true about some piece of state when it\u2019s passed through a function. For example, if you sort a list, the result will have the same number of elements as the original\u2014the length is invariant. Once we work out our contracts and invariants (which we\u2019re going to lump together and call properties) we can use them to automate our testing. What we end up doing is called property-based testing. from hypothesis import given import hypothesis.strategies as some @given(some.lists(some.integers())) def test_list_size_is_invariant_across_sorting(a_list): original_length = len(a_list) a_list.sort() assert len(a_list) == original_length @given(some.lists(some.text())) def test_sorted_result_is_ordered(a_list): a_list.sort() for i in range(len(a_list) - 1): assert a_list[i] <= a_list[i + 1] Thomas, David; Hunt, Andrew. Pragmatic Programmer, The (pp. 394-395). Pearson Education. Kindle Edition. 43 Stay Safe Out There Security Basic Principles Pragmatic Programmers have a healthy amount of paranoia. We know we have faults and limitations, and that external attackers will seize on any opening we leave to compromise our systems. Your particular development and deployment environments will have their own security-centric needs, but there are a handful of basic principles that you should always bear in mind: Minimize Attack Surface Area Principle of The Least Privilege Secure Defaults Encrypt Sensitive Data Maintain Security Updates 44 Naming Things whenever you create something, you need to pause and think \"what is my motivation to create this?\" It\u2019s important that everyone on the team knows what project jargon means, and that they use them consistently. encourage a lof of communication e.g. Pair programming, huddles Keep project glossary, listing the terms that have special meaning ot the team (e.g. on confluence) 8 Before The Project 45 The Requirements Pit Tip 76 Programmers Help People Understand What They Want we annoy people by looking for edge cases and asking about them. _- You: We were wondering about the $50 total. Does that include what we\u2019d normally charge for shipping? Client: Of course. It\u2019s the total they\u2019d pay us. You: That\u2019s nice and simple for our customers to understand: I can see the attraction. But I can see some less scrupulous customers trying to game that system. Client: How so? You: Well, let\u2019s say they buy a book for $25, and then select overnight shipping, the most expensive option. That\u2019ll likely be about $30, making the whole order $55. We\u2019d then make the shipping free, and they\u2019d get overnight shipping on a $25 book for just $25._ At this point the experienced developer stops. Deliver facts, and let the client make the decisions If it's not easy to get a feedback create a mockup and prototype to show to the client \"is this way you meant?\" this gives you quick feedback loop. walk in your cline's shoes simple way to achieve this is by becoming a client - spend time on the clients daily work routine to understand better the context. 46 Solving Impossible Puzzles Tup 81 Don\u2019t Think Outside the Box\u2014Find the Box Whenever you're solving a hard problem focus on constrains You must challenge any preconceived notions and evaluate whether or not they are real, hard-and-fast constraints. It\u2019s not whether you think inside the box or outside the box. The problem lies in finding the box\u2014identifying the real constraints. ask questions: Why are you solving this problem? What\u2019s the benefit of solving it? Are the problems you\u2019re having related to edge cases? Can you eliminate them? Is there a simpler, related problem you can solve? When you have a problem with solving the problem always take a break and focus on something different. 47 Working Together Pair Programming - one developer operates the keyboard, and the other does not. Both work on the problem together, and can switch typing duties as needed. Mob Programming - extension of pair programing but using more than 2 people (not necessarily ony developers). you swap out the typist every 5-10 minutes. Tip 82 Don\u2019t Go into the Code Alone 48 The Essence of Agility Manifesto values: Individuals and interactions over processes and tools Working software over comprehensive documentation Customer collaboration over contract negotiation Responding to change over following a plan That is, while there is value in the items on the right, we value the items on the left more. Agile is not about process but responding to change, to the unknowns after you set out. The above values don't tell what to do. They tell you what to look for. our recipe for working in an agile way: Work out where you are. Make the smallest meaningful step towards where you want to be. Evaluate where you end up, and fix anything you broke. Repeat 9 Pragmatic Projects 49 Pragmatic teams team has to support the no broken window (those small imperfections that no one fixes) mentality. Also be stayed alerted to avoid being Boiled Frogs . It\u2019s even easier for teams as a whole to get boiled. People assume that someone else is handling an issue, or that the team leader must have OK\u2019d a change that your user is requesting. Even the best-intentioned teams can be oblivious to significant changes in their projects. Communicate Team Presence - team needs to communicate with the rest of the organization. To outsiders, the worst project teams are those that appear sullen and reticent. They hold meetings with no structure, where no one wants to talk. Their emails and project documents are a mess: no two look the same, and each uses different terminology. There is a simple marketing trick that helps teams communicate as one: generate a brand. When you start a project, come up with a name for it, ideally something off-the-wall. (In the past, we\u2019ve named projects after things such as killer parrots that prey on sheep, optical illusions, gerbils, cartoon characters, and mythical cities.) Spend 30 minutes coming up with a zany logo, and use it. Use your team\u2019s name liberally when talking with people. It sounds silly, but it gives your team an identity to build on, and the world something memorable to associate with your work. Organize Fully Functional Teams - That means that you need all the skills to do that within the team: frontend, UI/UX, server, DBA, QA, etc. It allows to build end-to-end functionality in small pieces. 50 Coconut don't cut it The goal of course isn\u2019t to \"do Scrum,\" \"do agile,\" \"do Lean,\" or what-have-you. The goal is to be in a position to deliver working software that gives the users some new capability at a moment\u2019s notice. Not weeks, months, or years from now, but now. For many teams and organizations, continuous delivery feels like a lofty, unattainable goal, especially if you\u2019re saddled with a process that restricts delivery to months, or even weeks. But as with any goal, the key is to keep aiming in the right direction. 51 Pragmatic Starter Kit covering three critical and interrelated topics: Version Control - is needed Regression Testing - Use all kinds of testing to make sure that your code is working properly. (Unit test, Integration tests, QA testing, performance testing) + make sure to test the state not the coverage Full Automation - if something can be automated do it (like setting up your environment, CI) 52 Delight Your Users Understand the underlying expectations of value behind the project, you can start thinking about how you can deliver against them: Make sure everyone on the team is totally clear about these expectations. When making decisions, think about which path forward moves closer to those expectations. Critically analyze the user requirements in light of the expectations. On many projects we\u2019ve discovered that the stated \"requirement\" was in fact just a guess at what could be done by technology: it was actually an amateur implementation plan dressed up as a requirements document. Don\u2019t be afraid to make suggestions that change the requirement if you can demonstrate that they will move the project closer to the objective. Continue to think about these expectations as you progress through the project. 53 Pride and Prejudice You shouldn\u2019t jealously defend your code against interlopers; by the same token, you should treat other people\u2019s code with respect. The Golden Rule (\"Do unto others as you would have them do unto you\") and a foundation of mutual respect among the developers is critical to make this tip work. We want to see pride of ownership. \"I wrote this, and I stand behind my work.\" Your signature should come to be recognized as an indicator of quality. People should see your name on a piece of code and expect it to be solid, well written, tested, and documented. A really professional job. Written by a professional. 10 Postface Many non-embedded systems can also do both great good and great harm. Social media can promote peaceful revolution or foment ugly hate. Big data can make shopping easier, and it can destroy any vestige of privacy you might think you have. Banking systems make loan decisions that change people\u2019s lives. And just about any system can be used to snoop on its users. We\u2019ve seen hints of the possibilities of a utopian future, and examples of unintended consequences leading to nightmare dystopia. The difference between the two outcomes might be more subtle than you think. And it\u2019s all in your hands. We have a duty to ask ourselves two questions about every piece of code we deliver: Have I protected the user? Would I use this myself?","title":"Pragmatic programmer"},{"location":"books/pragmatic_programmer/#pragmatic-programmer","text":"","title":"Pragmatic programmer"},{"location":"books/pragmatic_programmer/#1-a-pragmatic-philosophy","text":"","title":"1 A Pragmatic Philosophy"},{"location":"books/pragmatic_programmer/#1-its-your-life","text":"It is your life. You own it. You run it. You create it. Many developers we talk to are frustrated. Their concerns are varied. Some feel they\u2019re stagnating in their job, others that technology has passed them by. Folks feel they are underappreciated, or underpaid, or that their teams are toxic. Maybe they want to move to Asia, or Europe, or work from home. And the answer we give is always the same. And the answer we give is always the same. Why can\u2019t you change it? Does your work environment suck? Is your job boring? Try to fix it. But don\u2019t try forever. As Martin Fowler says, \"you can change your organization or change your organization.\"","title":"1 It\u2019s Your Life"},{"location":"books/pragmatic_programmer/#2-the-cat-ate-my-source-code","text":"Team Trust - is absolutely essential for creativity and collaboration according to the research literature [e.g. ( research) [https://psycnet.apa.org/doiLanding?doi=10.1037%2Fapl0000110]. In a healthy environment based in trust, you can safely speak your mind, present your ideas, and rely on your team members who can in turn rely on you. Take Responsibility - When you do accept the responsibility for an outcome, you should expect to be held accountable for it. When you make a mistake (as we all do) or an error in judgment, admit it honestly and try to offer options. It is up to you to provide solutions, not excuses. Before you approach anyone to tell them why something can\u2019t be done, is late, or is broken, stop and listen to yourself. Talk to the rubber duck on your monitor, or the cat. Does your excuse sound reasonable, or stupid? How\u2019s it going to sound to your boss? Run through the conversation in your mind. What is the other person likely to say? Will they ask, \"Have you tried this\u2026\" or \"Didn\u2019t you consider that?\" How will you respond? Before you go and tell them the bad news, is there anything else you can try? Sometimes, you just know what they are going to say, so save them the trouble. explain what can be done to salvage the situation refactoring prototyping better testing automation additional resources more time with user maybe time for learning some technique or technology in greater depth?","title":"2 The Cat Ate My Source Code"},{"location":"books/pragmatic_programmer/#3-software-entropy","text":"Entropy is a term from physics that refers to the amount of \"disorder\" in a system. it might be called, by the more optimistic term, \"technical debt,\" with the implied notion that they\u2019ll pay it back someday. They probably won\u2019t. In inner cities, some buildings are beautiful and clean, while others are rotting hulks. Why? Researchers in the field of crime and urban decay discovered a fascinating trigger mechanism, one that very quickly turns a clean, intact, inhabited building into a smashed and abandoned derelict.[5] A broken window. One broken window, left unrepaired for any substantial length of time, instills in the inhabitants of the building a sense of abandonment\u2014a sense that the powers that be don\u2019t care about the building. So another window gets broken. People start littering. Graffiti appears. Serious structural damage begins. In a relatively short span of time, the building becomes damaged beyond the owner\u2019s desire to fix it, and the sense of abandonment becomes reality. Why would that make a difference? Psychologists have done studies[6] that show hopelessness can be contagious. Think of the flu virus in close quarters. Ignoring a clearly broken situation reinforces the ideas that perhaps nothing can be fixed, that no one cares, all is doomed; all negative thoughts which can spread among team members, creating a vicious spiral.","title":"3 Software Entropy"},{"location":"books/pragmatic_programmer/#tip-5-dont-live-with-broken-windows","text":"Don\u2019t leave \"broken windows\" (bad designs, wrong decisions, or poor code) unrepaired. Fix each one as soon as it is discovered. If there is insufficient time to fix it properly, then board it up. Perhaps you can comment out the offending code, or display a \"Not Implemented\" message, or substitute dummy data instead. Take some action to prevent further damage and to show that you\u2019re on top of the situation. We\u2019ve seen clean, functional systems deteriorate pretty quickly. You may be thinking that no one has the time to go around cleaning up all the broken glass of a project. If so, then you\u2019d better plan on getting a dumpster, or moving to another neighborhood. Don\u2019t let entropy win.","title":"Tip 5 Don\u2019t Live with Broken Windows"},{"location":"books/pragmatic_programmer/#4-stone-soup-and-boiled-frogs","text":"Stone soup - allegory to the soldiers coming back from war stopping at village hoping for some food. Villagers didn't want to share the food. The soldiers boiled a pot of water and carefully placed three stones into it. The amazed villagers came out to watch. Once villagers started to seeing what's happening one by one get more interested and ask about it, in return they hear from soldiers. \"The stone soup is good as it is, but some say it tests better when we add X\" which cause villagers to start to share their supply with soldiers. Eventually they had produced a large pot of steaming soup. The soldiers removed the stones, and they sat down with the entire village to enjoy the first square meal any of them had eaten in months. The soldiers act as a catalyst, bringing the village together, so they can jointly produce something that they couldn\u2019t have done by themselves\u2014a synergistic result. Eventually everyone wins.","title":"4 Stone Soup and Boiled Frogs"},{"location":"books/pragmatic_programmer/#tip-6-be-a-catalyst-for-change","text":"Work out what you can reasonably ask for. Develop it well. Once you\u2019ve got it, show people, and let them marvel. Then say \"of course, it would be better if we added\u2026\" Pretend it\u2019s not important. Sit back and wait for them to start asking you to add the functionality you originally wanted. People find it easier to join an ongoing success. Show them a glimpse of the future, and you\u2019ll get them to rally around. boiled frog - that if you take a frog and drop it into boiling water, it will jump straight back out again. However, if you place the frog in a pan of cold water, then gradually heat it, the frog won\u2019t notice the slow increase in temperature and will stay put until cooked. The frog just doesn't notice the change. Don\u2019t be like the fabled frog. Keep an eye on the big picture. Constantly review what\u2019s happening around you, not just what you personally are doing.","title":"Tip 6 Be a Catalyst for Change"},{"location":"books/pragmatic_programmer/#5-good-enough-software","text":"The scope and quality of the system you produce should be discussed as part of that system\u2019s requirements. Great software today is often preferable to the fantasy of perfect software tomorrow. If you give your users something to play with early, their feedback will often lead you to a better eventual solution (Tracer Bullet).","title":"5 Good-Enough Software"},{"location":"books/pragmatic_programmer/#6-your-knowledge-portfolio","text":"Managing a knowledge portfolio is very similar to managing a financial portfolio: Serious investors invest regularly\u2014as a habit . Diversification is the key to long-term success. Smart investors balance their portfolios between conservative and high-risk , high-reward investments. Investors try to buy low and sell high for maximum return. Portfolios should be reviewed and rebalanced periodically. Goals: Learn at least one new language every year Read a technical book each month Read nontechnical books, too Take classes Participate in local user groups and meetups Experiment with different environments Stay current","title":"6 Your Knowledge Portfolio"},{"location":"books/pragmatic_programmer/#tip-10-critically-analyze-what-you-read-and-hear","text":"A favorite consulting trick: ask \"why?\" at least five times. Ask a question, and get an answer. Dig deeper by asking \"why?\" Repeat as if you were a petulant four-year old (but a polite one). You might be able to get closer to a root cause this way. Who does this benefit? It may sound cynical, but follow the money can be a very helpful path to analyze. The benefits to someone else or another organization may be aligned with your own, or not. What\u2019s the context? Everything occurs in its own context, which is why \"one size fits all\" solutions often don\u2019t. Consider an article or book touting a \"best practice.\" Good questions to consider are best for \"who?\" What are the prerequisites, what are the consequences, short and long term? When or Where would this work? Under what circumstances? Is it too late? Too early? Don\u2019t stop with first-order thinking (what will happen next), but use second-order thinking: what will happen after that? Why is this a problem? Is there an underlying model? How does the underlying model work?","title":"Tip 10 Critically Analyze What You Read and Hear"},{"location":"books/pragmatic_programmer/#7-communicate","text":"Treat English (or whatever your native tongue may be) as just another programming language . Write natural language as you would write code: honor the DRY principle, ETC, automation, and so on. (We discuss the DRY and ETC design principles in the next chapter.) Know Your Audience - By making the appropriate pitch to each group, you\u2019ll get them all excited about your project. As with all forms of communication, the trick here is to gather feedback. Don\u2019t just wait for questions: ask for them. Look at body language, and facial expressions. One of the Neuro Linguistic Programming presuppositions is \"The meaning of your communication is the response you get.\" Continuously improve your knowledge of your audience as you communicate. Know What You Want to Say Fiction writers often plot out their books in detail before they start, but people writing technical documents are often happy to sit down at a keyboard, enter: 1. Introduction Plan what you want to say. Write an outline. Then ask yourself, \"Does this communicate what I want to express to my audience in a way that works for them?\" Refine it until it does. Choose Your Moment Catch a manager who\u2019s just been given a hard time by her boss because some source code got lost, and you\u2019ll have a more receptive listener to your ideas on source code repositories. Make what you\u2019re saying relevant in time, as well as in content. Sometimes all it takes is the simple question, \"Is this a good time to talk about\u2026?\" Make It Look Good Too many developers (and their managers) concentrate solely on content when producing written documents. We think this is a mistake. Any chef (or watcher of the Food Network) will tell you that you can slave in the kitchen for hours only to ruin your efforts with poor presentation. There is no excuse today for producing poor-looking printed documents. Involve Your Audience If possible, involve your readers with early drafts of your document. Get their feedback, and pick their brains. You\u2019ll build a good working relationship, and you\u2019ll probably produce a better document in the process. Be a Listener There\u2019s one technique that you must use if you want people to listen to you: listen to them. Even if this is a situation where you have all the information, even if this is a formal meeting with you standing in front of 20 suits\u2014if you don\u2019t listen to them, they won\u2019t listen to you. Encourage people to talk by asking questions, or ask them to restate the discussion in their own words. Turn the meeting into a dialog, and you\u2019ll make your point more effectively. Who knows, you might even learn something. Get Back to People Always respond to emails and voicemails, even if the response is simply \"I\u2019ll get back to you later\". communicate. The more effective that communication, the more influential you become. Keep code and documentation together Writing documentation can be made easier by not duplicating effort or wasting time, and by keeping documentation close at hand\u2014in the code itself. In fact, we want to apply all of our pragmatic principles to documentation as well as to code. It\u2019s easy to produce good-looking documentation from the comments in source code, and we recommend adding comments to modules and exported functions to give other developers a leg up when they come to use it. Restrict your non-API commenting to discussing why something is done, its purpose and its goal. The code already shows how it is done, so commenting on this is redundant\u2014and is a violation of the DRY principle. Online Communication tips Our tips are simple: Proofread before you hit SEND . Check your spelling and look for any accidental autocorrect mishaps. Keep the format simple and clear. Keep quoting to a minimum. No one likes to receive back their own 100-line email with \"I agree\" tacked on. If you\u2019re quoting other people\u2019s email, be sure to attribute it, and quote it inline (rather than as an attachment). Same when quoting on social media platforms. Don\u2019t flame or act like a troll unless you want it to come back and haunt you later. If you wouldn\u2019t say it to someone\u2019s face, don\u2019t say it online. Check your list of recipients before sending. It\u2019s become a clich\u00e9 to criticize the boss over departmental email without realizing that the boss is on the cc list. Better yet, don\u2019t criticize the boss over email. As countless large corporations and politicians have discovered, email and social media posts are forever. Try to give the same attention and care to email as you would to any written memo or report.","title":"7 Communicate!"},{"location":"books/pragmatic_programmer/#2-a-pragmatic-approach","text":"","title":"2 A Pragmatic Approach"},{"location":"books/pragmatic_programmer/#the-essence-of-good-design","text":"","title":"The Essence of Good Design"},{"location":"books/pragmatic_programmer/#tip-14-good-design-is-easier-to-change-than-bad-design","text":"ETC - easier to change - principle every design principle out there is a special case of ETC. Why is decoupling good? Because by isolating concerns we make each easier to change. ETC. Why is the single responsibility principle useful? Because a change in requirements is mirrored by a change in just one module. ETC. Why is naming important? Because good names make code easier to read, and you have to read it to change it. ETC! ETC Is a Value, Not a Rule Deliberately ask yourself \"did the thing I just did make the overall system easier or harder to change?\" Do it when you save a file. Do it when you write a test. Do it when you fix a bug. It assumes that a person can tell which of many paths will be easier to change in the future. Much of the time, common sense will be correct, and you can make an educated guess. If you're still not sure which is the best solution, you can: Try to make the code you write replaceable treat this as a way to develop instincts.Note the situation in your engineering day book: the choices you have, and some guesses about change. Leave a tag in the source. Then, later, when this code has to change, you\u2019ll be able to look back and give yourself feedback. It might help the next time you reach a similar fork in the road.","title":"Tip 14 Good Design Is Easier to Change Than Bad Design"},{"location":"books/pragmatic_programmer/#9-dry-the-devils-of-duplication","text":"Most people assume that maintenance begins when an application is released, that maintenance means fixing bugs and enhancing features. We think these people are wrong. Programmers are constantly in maintenance mode. Our understanding changes day by day. New requirements arrive and existing requirements evolve as we\u2019re heads-down on the project. Perhaps the environment changes. Whatever the reason, maintenance is not a discrete activity, but a routine part of the entire development process. We feel that the only way to develop software reliably, and to make our developments easier to understand and maintain, is to follow what we call the DRY principle : DRY - Don't Repeat Yourself - Every piece of knowledge must have a single, unambiguous, authoritative representation within a system. Don\u2019t copy-and-paste lines of source is only a part of DRY. DRY is about the duplication of knowledge, of intent. It\u2019s about expressing the same thing in two different places, possibly in two totally different ways. Here\u2019s the acid test: when some single facet of the code has to change, do you find yourself making that change in multiple places, and in multiple different formats? Do you have to change code and documentation, or a database schema and a structure that holds it, or\u2026? If so, your code isn\u2019t DRY. Not All Code Duplication Is Knowledge Duplication Not All Code Duplication Is Knowledge Duplication As part of your online wine ordering application you\u2019re capturing and validating your user\u2019s age, along with the quantity they\u2019re ordering. According to the site owner, they should both be numbers, and both greater than zero. So you code up the validations: def validate_age(value): validate_type(value, :integer) validate_min_integer(value, 0) def validate_quantity(value): validate_type(value, :integer) validate_min_integer(value, 0) The code is the same, but the knowledge they represent is different. The two functions validate two separate things that just happen to have the same rules. That\u2019s a coincidence, not a duplication.","title":"9 DRY - The Devils of Duplication"},{"location":"books/pragmatic_programmer/#1-dry-violation-in-documentation","text":"Don't repeat the intent of the function in the comment. Try to write the function and names in a way that it's self expressing.","title":"1. DRY Violation in Documentation"},{"location":"books/pragmatic_programmer/#2-dry-violation-in-data","text":"class Line { Point start; Point end; double length; } we have duplication. The length is defined by the start and end points: change one of the points and the length changes. It\u2019s better to make the length a calculated field: class Line { Point start; Point end; double length() { return star.distanceTo(end); } } It's OK to violate the DRY principle fo performance reasons. e.g. caching the data. Where possible, always use accessor functions to read and write the attributes of objects. It will make it easier to add functionality in the future. All services offered by a module should be available through a uniform notation, which does not betray whether they are implemented through storage or through computation.","title":"2. DRY Violation in Data"},{"location":"books/pragmatic_programmer/#2-dry-violation-in-representation","text":"Your code needs to know how to communicate with libraries, API or the schemas (e.g. error codes). The duplication here is that two things (your code and the external entity) have to have knowledge of the representation of their interface. Change it at one end, and the other end breaks. Some strategies: Duplication across internal API - look for tools that let you specify the API in some kind of neutral format. These tools will typically generate documentation, mock APIs, functional tests, and API clients, the latter in a number of different languages. Ideally the tool will store all your APIs in a central repository, allowing them to be shared across teams. Duplication Across External APIs - Increasingly, you\u2019ll find that public APIs are documented formally using something like OpenAPI.This allows you to import the API spec into your local API tools and integrate more reliably with the service. If you can\u2019t find such a specification, consider creating one and publishing it. Not only will others find it useful; you may even get help maintaining it. Duplication with Data Sources - Many data sources allow you to introspect on their data schema. This can be used to remove much of the duplication between them and your code. Rather than manually creating the code to contain this stored data, you can generate the containers directly from the schema. Many persistence frameworks will do this heavy lifting for you. There\u2019s another option, and one we often prefer. Rather than writing code that represents external data in a fixed structure (an instance of a struct or class, for example), just stick it into a key/value data structure (your language might call it a map, hash, dictionary, or even object). On its own this is risky: you lose a lot of the security of knowing just what data you\u2019re working with. So we recommend adding a second layer to this solution: a simple table-driven validation suite that verifies that the map you\u2019ve created contains Inter-developer Duplication - at the module level, the problem is more insidious. Commonly needed functionality or data that doesn\u2019t fall into an obvious area of responsibility can get implemented many times over. We feel that the best way to deal with this is to encourage active and frequent communication between developers. Maybe run a daily scrum standup meeting. Set up forums (such as Slack channels) to discuss common problems. This provides a non-intrusive way of communicating\u2014even across multiple sites\u2014while retaining a permanent history of everything said. Appoint a team member as the project librarian, whose job is to facilitate the exchange of knowledge. Have a central place in the source tree where utility routines and scripts can be deposited. And make a point of reading other people\u2019s source code and documentation, either informally or during code reviews. You\u2019re not snooping\u2014you\u2019re learning from them. And remember, the access is reciprocal\u2014don\u2019t get twisted about other people poring (pawing?) through your code, either.","title":"2. DRY Violation in Representation"},{"location":"books/pragmatic_programmer/#10-orthogonality","text":"\"Orthogonality\" is a term borrowed from geometry. Two lines are orthogonal if they meet at right angles, such as the axes on a graph. It's generalization of the geometric notion of perpendicularity. In computing, the term has come to signify a kind of independence or decoupling. Two or more things are orthogonal if changes in one do not affect any of the others. We want to design components that are self-contained: independent, and with a single, well-defined purpose (what Yourdon and Constantine call cohesion in Structured Design: Fundamentals of a Discipline of Computer Program and Systems Design[YC79]). When components are isolated from one another, you know that you can change one without having to worry about the rest. As long as you don\u2019t change that component\u2019s external interfaces, you can be confident that you won\u2019t cause problems that ripple through the entire system. Two major benefits if you write orthogonal systems: increased productivity - It is easier to write relatively small, self-contained components than a single large block of code. Simple components can be designed, coded, tested, and then forgotten\u2014there is no need to keep changing existing code as you add new code. reduced risk - Diseased sections of code are isolated. If a module is sick, it is less likely to spread the symptoms around the rest of the system. It is also easier to slice it out and transplant in something new and healthy. Most developers are familiar with the need to design orthogonal systems, although they may use words such as modular, component-based, and layered to describe the process. Orthogonality is closely related to the DRY principle. With DRY, you\u2019re looking to minimize duplication within a system, whereas with orthogonality you reduce the interdependency among the system\u2019s components. It may be a clumsy word, but if you use the principle of orthogonality, combined closely with the DRY principle, you\u2019ll find that the systems you develop are more flexible, more understandable, and easier to debug, test, and maintain.","title":"10 Orthogonality"},{"location":"books/pragmatic_programmer/#11-reversibility","text":"What you can do is make it easy to change. Hide third-party APIs behind your own abstraction layers. Break your code into components: even if you end up deploying them on a single massive server, this approach is a lot easier than taking a monolithic application and splitting it.","title":"11 Reversibility"},{"location":"books/pragmatic_programmer/#12-tracer-bullets","text":"the term tracer bullet development is used to visually illustrate the need for immediate feedback under actual conditions with a moving goal. Tracer bullets work because they operate in the same environment and under the same constraints as the real bullets. They get to the target fast, so the gunner gets immediate feedback. And from a practical standpoint they\u2019re a relatively cheap solution. Look for the important requirements, the ones that define the system. Look for the areas where you have doubts, and where you see the biggest risks. Then prioritize your development so that these are the first areas you code. Tracer code is not disposable: you write it for keeps. It contains all the error checking, structuring, documentation, and self-checking that any piece of production code has. It simply is not fully functional. However, once you have achieved an end-to-end connection among the components of your system, you can check how close to the target you are, adjusting if necessary. Once you\u2019re on target, adding functionality is easy. Tracer development is consistent with the idea that a project is never finished: there will always be changes required and functions to add. It is an incremental approach. The tracer code approach has many advantages: Users get to see something working early - your users will know they are seeing something immature. They won\u2019t be disappointed by a lack of functionality; they\u2019ll be ecstatic to see some visible progress toward their system. Developers build a structure to work in - it. If you have worked out all the end-to-end interactions of your application, and have embodied them in code, then your team won\u2019t need to pull as much out of thin air. This makes everyone more productive, and encourages consistency. You have an integration platform - have an integration platform As the system is connected end-to-end, you have an environment to which you can add new pieces of code once they have been unit-tested. You have something to demonstrate You have a better feel for progress Tracer Code versus Prototyping You might think that this tracer code concept is nothing more than prototyping under an aggressive name. There is a difference. With a prototype, you\u2019re aiming to explore specific aspects of the final system. With a true prototype, you will throw away whatever you lashed together when trying out the concept, and recode it properly using the lessons you\u2019ve learned. The tracer code approach addresses a different problem. You need to know how the application as a whole hangs together. You want to show your users how the interactions will work in practice, and you want to give your developers an architectural skeleton on which to hang code.","title":"12 Tracer Bullets"},{"location":"books/pragmatic_programmer/#13-prototypes-and-post-it-notes","text":"What sorts of things might you choose to investigate with a prototype? Anything that carries risk. Anything that hasn\u2019t been tried before, Anything that is absolutely critical to the final system. Anything unproven, experimental, or doubtful. Anything you aren\u2019t comfortable with. You can prototype: Architecture New functionality in an existing system Structure or contents of external data Third-party tools or components Performance issues User interface design Prototyping is a learning experience. Its value lies not in the code produced, but in the lessons learned. That\u2019s really the point of prototyping. How to Use Prototypes When building a prototype, what details can you ignore? Correctness You may be able to use dummy data where appropriate. Completeness The prototype may function only in a very limited sense, perhaps with only one preselected piece of input data and one menu item. Robustness Error checking is likely to be incomplete or missing entirely. If you stray from the predefined path, the prototype may crash and burn in a glorious display of pyrotechnics. That\u2019s okay. Style Prototype code shouldn\u2019t have much in the way of comments or documentation (although you may produce reams of documentation as a result of your experience with the prototype).","title":"13 Prototypes and Post-it Notes"},{"location":"books/pragmatic_programmer/#14-domain-languages","text":"We always try to write code using the vocabulary of the application domain (see Maintain a Glossary). In some cases, Pragmatic Programmers can go to the next level and actually program using the vocabulary, syntax, and semantics\u2014the language\u2014of the domain. E.g. Cucumber is programming-language neutral way of specifying tests. You run the tests using a version of Cucumber appropriate to the language you\u2019re using. In order to support the natural-language like syntax, you also have to write specific matchers that recognize phrases and extract parameters for the tests.","title":"14 Domain Languages"},{"location":"books/pragmatic_programmer/#15-estimating","text":"Duration Quote estimate in 1-15 days Days 3-6 weeks Weeks 8-20 weeks Months 20+ weeks Think hard before giving an estimate Where Do Estimates Come From? Ask someone who\u2019s already done it. Before you get too committed to model building, cast around for someone who\u2019s been in a similar situation in the past. See how their problem got solved. Understand What\u2019s Being Asked You need to have a grasp of the scope of the domain. Often this is implicit in the question, but you need to make it a habit to think about the scope before starting to guess. Often, the scope you choose will form part of the answer you give: \"Assuming there are no traffic accidents and there\u2019s gas in the car, I should be there in 20 minutes.\" Build a Model of the System From your understanding of the question being asked, build a rough-and-ready bare-bones mental model. Building the model introduces inaccuracies into the estimating process. This is inevitable, and also beneficial. You are trading off model simplicity for accuracy. Doubling the effort on the model may give you only a slight increase in accuracy. Your experience will tell you when to stop refining. Break the Model into Components Once you have a model, you can decompose it into components. You\u2019ll need to discover the mathematical rules that describe how these components interact. Sometimes a component contributes a single value that is added into the result. You\u2019ll find that each component will typically have parameters that affect how it contributes to the overall model. At this stage, simply identify each parameter. Give Each Parameter a Value Once you have the parameters broken out, you can go through and assign each one a value. You expect to introduce some errors in this step. The trick is to work out which parameters have the most impact on the result, and concentrate on getting them about right. Typically, parameters whose values are added into a result are less significant than those that are multiplied or divided. Calculate the Answers A spreadsheet can be a big help. Then couch your answer in terms of these parameters. During the calculation phase, you get answers that seem strange. Don\u2019t be too quick to dismiss them. If your arithmetic is correct, your understanding of the problem or your model is probably wrong. This is valuable information. Keep Track of Your Estimating Prowess We think it\u2019s a great idea to record your estimates, so you can see how close you were. If an overall estimate involved calculating sub-estimates, keep track of these as well. Often you\u2019ll find your estimates are pretty good\u2014in fact, after a while, you\u2019ll come to expect this.","title":"15 Estimating"},{"location":"books/pragmatic_programmer/#estimating-project-schedules-painting-the-missile","text":"\"How long will it take to paint the house?\" \"Well, if everything goes right, and this paint has the coverage they claim, it might be as few as 10 hours. But that\u2019s unlikely: I\u2019d guess a more realistic figure is closer to 18 hours. And, of course, if the weather turns bad, that could push it out to 30 or more.\" That\u2019s how people estimate in the real world. Not with a single number (unless you force them to give you one) but with a range of scenarios.","title":"Estimating Project Schedules -Painting the Missile"},{"location":"books/pragmatic_programmer/#what-to-say-when-asked-for-an-estimate","text":"You say \u201cI\u2019ll get back to you.\u201d You almost always get better results if you slow the process down and spend some time going through the steps we describe in this section. Estimates given at the coffee machine will (like the coffee) come back to haunt you.","title":"What to Say When Asked for an Estimate"},{"location":"books/pragmatic_programmer/#3-the-basic-tools","text":"As a developer you need to know the set of tools you should be using in your work to be efficient.","title":"3 The Basic Tools"},{"location":"books/pragmatic_programmer/#16-the-power-of-plain-text","text":"Keep Knowledge in Plain Text Plain text doesn\u2019t mean that the text is unstructured; HTML, JSON, YAML, and so on are all plain text. So are the majority of the fundamental protocols on the net, such as HTTP, SMTP, IMAP, and so on. And that\u2019s for some good reasons: Insurance against obsolescence - human-readable (and human understandable!) forms of data and self-describing data will outlive all other forms of data and the applications that created them. Leverage existing tools - virtually every tool can work with plain text Easier testing","title":"16 The Power of Plain Text"},{"location":"books/pragmatic_programmer/#17-shell-games","text":"Every programmer needs to manipulate files of text for that purpose we should learn command shell. From the shell prompt you can invoke your full repertoire of tools, using pipes, to combine them in ways never dreamt of by their original developers. From shell, you can launch applications, debuggers, browsers, editors and utilities. You can search for files, query the status of the system and filter output. If you can do everything inside your IDE with UI why would you need it? A benefit of GUI is WYSIWYG - What You See Is What You Get. The disadvantage is WYSIAYG - What You See Is All You Get.","title":"17 Shell Games"},{"location":"books/pragmatic_programmer/#tip-26-use-the-power-of-command-shells","text":"Make sure to configure and customize shell to your needs: setting color themes configuring a prompt aliases and shell functions command completion","title":"Tip 26 Use the power of Command Shells"},{"location":"books/pragmatic_programmer/#18-power-editing","text":"Achieve Editor Fluency Here\u2019s the challenge list (without using mouse/trackpad): When editing text, move and make selections by character, word, line, and paragraph. When editing code, move by various syntactic units (matching delimiters, functions, modules, \u2026). Reindent code following changes. Comment and uncomment blocks of code with a single command. Undo and redo changes. Split the editor window into multiple panels, and navigate between them. Navigate to a particular line number. Sort selected lines. Search for both strings and regular expressions, and repeat previous searches. Temporarily create multiple cursors based on a selection or on a pattern match, and edit the text at each in parallel. Display compilation errors in the current project. Run the current project\u2019s tests.","title":"18 Power Editing"},{"location":"books/pragmatic_programmer/#19-version-control","text":"Always Use Version Control - not only for code repositories. For Everything: notes, prototype, configuration, system settings","title":"19 Version Control"},{"location":"books/pragmatic_programmer/#20-debugging","text":"Embrace the fact that debugging is just problem-solving and attack it as such. A debugging mindset don't panic, think about what could be causing the symptoms that you believe indicate a bug. Before you start to look at the bug make sure that you are working on code that built cleanly - without warnings. gather all relevant data talk/interview to reported, go together though the issue if you can't reproduce it. Debugging Strategies Failing Test Before Fixing Code Read the Damn Error Message! Make sure that you also see incorrect value in the debugger Jot down notes, when you find a clue and chase it down only to find it didn't pan out - it would be easier to come back to where you were before. If it is an input values problem recreate it on full list and start chopping it. Use the Binary Chop when going through stack trace to find the root of the issue Use logging Talk to rubber Duck Use Process of Elimination - if you changed one thing which looks not related to the problem at glance, double check it because you might be wrong. Don't assume, prove it. Make sure it won't repeat. Fix Unit Tests, mend them, analyze the data, check other places in the code where it can happen.","title":"20 Debugging"},{"location":"books/pragmatic_programmer/#21-text-manipulation","text":"Learn a Text Manipulation Language. On Linux (or Mac) users often use tools such as awk and sed. Sometimes Python, Ruby, Perl. Ruby and Python were used to create a pragmatic Programmer book: Building the book - the build system for the bookshelf is written in Ruby. Authors, editors, layout people and support folk use Rake tasks to coordinate the building of PDFs and ebooks. Code inclusion and highlighting - the source codes examples in books are taken from repository to follow the DRY principle. Website update - simple script that does a partial book build, extracts the table of contents, then uploads it to the book's page on our website. Including equations - Python script that converts LaTeX math markup into formatted text. Index Generation - indexes are created as separate documents. Ruby script collates and formats the entries.","title":"21 Text manipulation"},{"location":"books/pragmatic_programmer/#22-engineering-daybooks","text":"We use daybooks to take notes in meetings, to jot down what we\u2019re working on, to note variable values when debugging, to leave reminders where we put things, to record wild ideas, and sometimes just to doodle. The daybook has three main benefits: It is more reliable than memory. People might ask \u201cWhat was the name of that company you called last week about the power supply problem?\u201d and you can flip back a page or so and give them the name and number. It gives you a place to store ideas that aren\u2019t immediately relevant to the task at hand. That way you can continue to concentrate on what you are doing, knowing that the great idea won\u2019t be forgotten. It acts as a kind of rubber duck (described here). When you stop to write something down, your brain may switch gears, almost as if talking to someone\u2014a great chance to reflect. You may start to make a note and then suddenly realize that what you\u2019d just done, the topic of the note, is just plain wrong. There\u2019s an added benefit, too. Occasionally you can look back at what you were doing oh-so-many-years-ago and think about the people, the projects, and the awful clothes and hairstyles.","title":"22 Engineering Daybooks"},{"location":"books/pragmatic_programmer/#4-pragmatic-paranoia","text":"","title":"4 Pragmatic Paranoia"},{"location":"books/pragmatic_programmer/#tip-36-you-cant-write-perfect-software","text":"Perfect software doesn't exist, don't waste time and energy chasing an impossible dream. How to turn it into an advantage? If you think that someone code might not live up to your standards, don't trust your code either - no one writes perfect code.","title":"Tip 36 you can't write perfect software"},{"location":"books/pragmatic_programmer/#23-design-by-contract","text":"DBC - Design By Contract - technique that focuses on documenting the rights and responsibilities of software modules to ensure program correctness. What is correct program? One that does no more and no less than it claims to do. Documenting and verifying that claim is the role of DBC. Every function does something - Before it starts doing something it might have expectations of the state, and also it can modify that state. These expectations and claims are: Pre-conditions - what must be true in order for the function to be called (it's the caller responsibility to pass good data) Post-conditions - what function is guaranteed to do. - the state when the function is done. Class invariants / state - class ensures that this condition is always true from the perspective of a caller. So the contract between the caller and module is: If all function\u2019s preconditions are met by the caller, the function shall guarantee that all post conditions and invariants will be true when it completes. If something is not as in contract the remedy is to raise exception. Or Even better disable the possibility to call the function with wrong values. E.g. on Android you can use @StringRes which indicates that the Int value needs to come from android resources. Be strict in what you will accept before you begin, promise as little as possible in return. Implementing DBC Simply enumerating what the input domain range is, what the boundary conditions are, and what the routine promises to deliver. Assertions you can get much greater benefit by having the compiler check your contract for you. You can partially emulate this in some languages by using assertions: runtime checks for logical conditions. Who is responsible for checking the preconditions, the caller or the method being called? When DBC is implemented by the language - neither. it's tested behind the scene after caller invokes the method but before the mother runs. If there is any explicit checking of parameters to be done, it must be performed by the caller because the method will never see parameters that violate its precondition. For non-supporting DBC languages you need to bracket the called method with preamble and/or post-amble that checks these assertions. Consider a program that reads a number from the console, calculates its square root (by calling sqrt), and prints the result. The sqrt function has a precondition\u2014its argument must not be negative. If the user enters a negative number at the console, it is up to the calling code to ensure that it never gets passed to sqrt. This calling code has many options: it could terminate, it could issue a warning and read another number, or it could make the number positive and append an i to the result returned by sqrt. Whatever its choice, this is definitely not sqrt\u2019s problem. By expressing the domain of the square root function in the precondition of the sqrt routine, you shift the burden of correctness to the caller\u2014where it belongs. You can then design the sqrt routine secure in the knowledge that its input will be in range. Crashing Early gives you possibility to report more accurate information about the problem.","title":"23 Design by Contract"},{"location":"books/pragmatic_programmer/#24-dead-programs-tell-no-lies","text":"Catch and release is for fish avoid using try-catch to catch all possible errors. The application code isn't eclipsed by the error code. The code is less coupled. If the writer of the method adds another exception our code is subtly out of date. Without try catch it's propagated. same\u2014when your code discovers that something that was supposed to be impossible just happened, your program is no longer viable. Anything it does from this point forward becomes suspect, so terminate it as soon as possible.","title":"24 Dead Programs Tell No Lies"},{"location":"books/pragmatic_programmer/#25-assertive-programming","text":"","title":"25 Assertive Programming"},{"location":"books/pragmatic_programmer/#tip-39-use-assertions-to-prevent-the-impossible","text":"In the Java implementation, you can (and should) add a descriptive string: assert result! = null && result.size() > 0 : \"Empty result from XYZ\"; Don\u2019t use assertions in place of real error handling. Assertions check for things that should never happen. Your first line of defense is checking for any possible error, and your second is using assertions to try to detect those you\u2019ve missed.","title":"Tip 39 Use Assertions to prevent the impossible"},{"location":"books/pragmatic_programmer/#26-hot-to-balance-resources","text":"The function that allocates a resource should be responsible for deallocating it. Deallocate resources with LIFO principle. When allocating the same set of resource in different places in your code, always allocate them in the same order to avoid deadlock. There are times when the basic resource allocation pattern just isn\u2019t appropriate. Commonly this is found in programs that use dynamic data structures. One routine will allocate an area of memory and link it into some larger structure, where it may stay for some time. The trick here is to establish a semantic invariant for memory allocation. You need to decide who is responsible for data in an aggregate data structure. What happens when you deallocate the top-level structure? You have three main options: The top-level structure is also responsible for freeing any substructures that it contains. These structures then recursively delete data they contain, and so on. The top-level structure is simply deallocated. Any structures that it pointed to (that are not referenced elsewhere) are orphaned. The top-level structure refuses to deallocate itself if it contains any substructures.","title":"26 Hot to Balance Resources"},{"location":"books/pragmatic_programmer/#27-dont-outrun-your-headlights","text":"","title":"27 Don't Outrun Your Headlights"},{"location":"books/pragmatic_programmer/#tip-42-always-take-small-steps","text":"Always take small, deliberate steps, checking for feedback and adjusting before proceeding. Consider that the rate of feedback is your speed limit. You never take on a step or a task that\u2019s \u201ctoo big.\u201d What do we mean exactly by feedback? Anything that independently confirms or disproves your action. For example: Results in a REPL provide feedback on your understanding of APIs and algorithms Unit tests provide feedback on your last code change User demo and conversation provide feedback on features and usability What's a task that's too big? Any task that requires \"fortune-telling\". We can only see into the future perhaps one or two steps, maybe a few hours or days at most. From that you can quickly past educated guess into wild speculation. When the fortune-telling starts? estimate completion dates months in the future Plan a design for future maintenance or extendability Guess user's future needs Guess future tech availability you should design for future maintenance but only to a point - only as far ahead as you can see.","title":"Tip 42 Always take small steps"},{"location":"books/pragmatic_programmer/#5-bend-or-break","text":"","title":"5 Bend, or break"},{"location":"books/pragmatic_programmer/#28-decoupling","text":"","title":"28 Decoupling"},{"location":"books/pragmatic_programmer/#tip-44-decoupled-code-is-easier-to-change","text":"symptoms of coupling: wacky dependencies between unrelated modules or libraries \"simple\" changes to one module that propagate through unrelated modules in the system or break stuff elsewhere in the system developers who are afraid to change code because they aren't sure what might be affected. meeting where everyone has to attend because no one is sure who will be affected by a change","title":"Tip 44 Decoupled Code is easier to change"},{"location":"books/pragmatic_programmer/#types-of-coupling","text":"Train wrecks - chains of method calls Globalization - the dangers of static things Inheritance - why subclassing is dangerous","title":"types of coupling:"},{"location":"books/pragmatic_programmer/#train-wrecks","text":"We\u2019ve all seen (and probably written) code like this: public void applyDiscount(customer, order_id, discount) { totals = customer .orders .find(order_id) .getTotals(); totals.grandTotal = totals.grandTotal - discount; totals.discount = discount; } This chunk of code is traversing five levels of abstraction from customer to total amount. Ultimately our top-level code has to know that a customer object exposes orders, that the orders have a find method that takes an order id and returns an order, and that the order object has a totals object which has getters and setters for grand totals and discounts. That's a lof of implicit knowledge. But worse, that's a lot of things that cannot change in the future if this code is to continue to work. All the cars in a train are coupled together as are all the methods and attributes in a train wreck. How to fix? use Tell, don't ask . TDA - you shouldn't make decision based on the internal state of an object and then update that object. It destroys the benefit of encapsulation and in doing so spreads the knowledge of the implementation throughout the code. proper solution public void applyDiscount(customer, order_id, discount) { customer .findOrder(order_id) .applyDiscount(discount); } alternative you could try to create applyDiscountToOrder(order_id) , but TDA is just a pattern if you think (or it's required anyway) to expose the customer has orders, and we can find it, then it is pragmatic decision. The Law Of Demeter, LoD - set of guidelines that help developers keep their functions cleaner and decoupled. The LoD says that a method defined in a class C should only call: Other instance methods in C Its parameters Methods in objects that it creates, both on the stack and in the heap Global variables simpler recommended version is: Don't Chain Method Calls // poor style val amount = customer.orders.last().totals().amount // and so is this val orders = customer.orders val last = order.last() val totals = last.totals() val amount = totals.amount Big exception to the one-dot rule: the rule doesn't apply if the things you're chaining are really, really unlikely to change. In practice, anything in your application should be considered likely to change. Anything in a third-party library should be considered volatile, particularly if the maintainers of the library are known to change API between releases. Libraries that come with the language however are probably pretty stable, and we would be happy with the code such as. people.sortBy { it.age } .first(10) .map { it.name }","title":"Train wrecks"},{"location":"books/pragmatic_programmer/#the-evils-of-globalization","text":"Globals couple code for many reasons. The most obvious is that a change to the implementation of the global potentially affects all the code in the system. In practice, of course, the impact is fairly limited; the problem really comes down to knowing that you\u2019ve found every place you need to change. Global data also creates coupling when it comes to teasing your code apart. You\u2019ll see this problem when you\u2019re writing unit tests for code that uses global data. You\u2019ll find yourself writing a bunch of setup code to create a global environment just to allow your test to run. If It\u2019s Important Enough to Be Global, Wrap It in an API Always use abstraction to represent global data (if you can't avoid having global one), same applies for third-party library.","title":"The Evils of Globalization"},{"location":"books/pragmatic_programmer/#inheritance-adds-coupling","text":"It's so important that it has separate topic [31]","title":"Inheritance adds coupling"},{"location":"books/pragmatic_programmer/#29-juggling-the-real-world","text":"Events are everywhere. Some are obvious: a button click, a timer expiring. Other are less so: someone logging in, a line in a file matching a pattern. But whatever their source, code that\u2019s crafted around events can be more responsive and better decoupled than its more linear counterpart. Strategies to handle the events: Finite State Machines The Observer Pattern Publish/Subscribe Reactive Programming and Streams","title":"29 Juggling the Real World"},{"location":"books/pragmatic_programmer/#finite-state-machines","text":"State machine is basically just a specification of how to handle events. It consists of a set of states, one of which is the current state. For each state we list the events that are significant to that state. For Each of those event we define new current state of the system. Stet machines are underused by developers. Though they don't solve all the problems associated with events.","title":"Finite State Machines"},{"location":"books/pragmatic_programmer/#the-observer-pattern","text":"Observable - source of events Observers - clients who are interested in those events. observer registers its interest with the observable typically by passing a reference to a function to be called. It is particularly prevalent in user interface system where the callbacks are used to inform the application that some interaction has occurred. But it introduces coupling ! also it can introduce performance bottlenecks. (both solved by Publish/Subscribe pattern).","title":"The Observer Pattern"},{"location":"books/pragmatic_programmer/#publishsubscribe","text":"it generalizes the observer pattern, at the same time solves the problems of coupling and performance. We have publishers and subscribers, these are connected via channels . The channels are implemented in a separate body of code: sometimes a library, sometimes a process, and sometimes a distributed infrastructure. All this implementation detail is hidden from your code. Every channel has a name. Subscribers register interest in one or more of these named channels, and publishers write events to them. Unlike the observer pattern, the communication between the publisher and subscriber is handled outside your code, and is potentially asynchronous. PubSub modules are provided in language as library. Compared to the observer pattern, pubsub is a great example of reducing coupling by abstracting up through a shared interface (the channel). However, it is still basically just a message passing system.","title":"Publish/Subscribe"},{"location":"books/pragmatic_programmer/#reactive-programming-streams-and-events","text":"If you\u2019ve ever used a spreadsheet, then you\u2019ll be familiar with reactive programming. If a cell contains a formula which refers to a second cell, then updating that second cell causes the first to update as well. The values react as the values they use change. Streams allow us treat events as if they were a collection of data (list of events which gets longer when new events arrive). The beauty of that is that we can treat streams just like any other collection: we can manipulate, combine, filter, and do all the other data-ish things we know so well. We can even combine event streams and regular collections. And streams can be asynchronous , which means your code gets the opportunity to respond to events as they arrive. This is a very powerful abstraction: we no longer need to think about time as being something we have to manage. Event streams unify synchronous and asynchronous processing behind a common, convenient API.","title":"Reactive Programming, Streams and Events"},{"location":"books/pragmatic_programmer/#30-transforming-programming","text":"We should more often think about programs as being something that transforms inputs into outputs. This chapter talks about a way we can chain object transformations to get what we want word |> all_subsets_longer_than_three_characters() |> as_unique_signatures() |> find_in_dictionary() |> group_by_length() It\u2019s simply a chain of the transformations needed to meet our requirement, each taking input from the previous transformation and passing output to the next. That comes about as close to literate code as you can get. But there\u2019s something deeper, too. If your background is object-oriented programming, then your reflexes demand that you hide data, encapsulating it inside objects. These objects then chatter back and forth, changing each other\u2019s state. This introduces a lot of coupling, and it is a big reason that OO systems can be hard to change. Tip 50 Don\u2019t Hoard State; Pass It Around In the transformational model, we turn that on its head. Instead of little pools of data spread all over the system, think of data as a mighty river, a flow. Data becomes a peer to functionality: a pipeline is a sequence of code \u2192 data \u2192 code \u2192 data\u2026. The data is no longer tied to a particular group of functions, as it is in a class definition. Instead, it is free to represent the unfolding progress of our application as it transforms its inputs into its outputs. This means that we can greatly reduce coupling: a function can be used (and reused) anywhere its parameters match the output of some other function. Yes, there is still a degree of coupling, but in our experience it\u2019s more manageable than the OO-style of command and control. And, if you\u2019re using a language with type checking, you\u2019ll get compile-time warnings when you try to connect two incompatible things. In Language X Doesn\u2019t Have Pipelines we wrote: const content = File.read(file_name); const lines = find_matching_lines(content, pattern) const result = truncate_lines Many people write OO code by chaining together method calls, and might be tempted to write this as something like: const result = content_of(file_name) .find_matching_lines(pattern) .truncate_lines() What\u2019s the difference between these two pieces of code? Which do you think we prefer? Let\u2019s answer the second part first: we prefer the first piece of code. In the second chunk of code, each step returns an object that implements the next function we call: the object returned by content_of must implement find_matching_lines, and so on. This means that the object returned by content_of is coupled to our code. Imagine the requirement changed, and we have to ignore lines starting with a # character. In the transformation style, that would be easy: const content = File.read(file_name); const no_comments = remove_comments(content) const lines = find_matching_lines(no_comments, pattern) const result = truncate_lines(lines) We could even swap the order of remove_comments and find_matching_lines and it would still work. But in the chained style, this would be more difficult. Where should our remove_comments method live: in the object returned by content_of or the object returned by find_matching_lines? And what other code will we break if we change that object? This coupling is why the method chaining style is sometimes called a train wreck .","title":"30 Transforming Programming"},{"location":"books/pragmatic_programmer/#31-inheritance-tax","text":"Stop using inheritance. Inheritance is coupling. Not only is the child class coupled to the parent, the parent's parent and so on, but the code that uses the child is also coupled to all the ancestors. using inheritance to build types (relation) tends to create complexity. Better alternatives: Interfaces and protocols - Prefer interfaces to express polymorphism instead of inheritance Delegation - instead of trying to inherit method from some class delegate the work to class that contains the code, by injecting particular object instead of inherit from it. Mixins and traits - allows to share the methods between different objects","title":"31 Inheritance Tax"},{"location":"books/pragmatic_programmer/#32-configuration","text":"Parametrize your app using external configuration. Common things you will want to put in configuration data include: credentials for external services (database, third party APIs and so on) logging levels and destinations port, ip address, machine, and cluster names the app uses Environment=specific validation parameters Externally set parameters, such as tax tares Site-specific formatting details License keys Basically, anything that you know will have to change that you can express outside your main body of code and slap it into some configuration bucket. create thin API to access configuration files and keep it behind a Service benefits: sharing configuration information Configuration changes ca be made globally Configuration data can be maintained via a specialized UI configuration data become dynamic without external configuration your code is not as adaptable or flexible as it could be. Don't overdo it, not everything should be in config files, focus on most important things.","title":"32 Configuration"},{"location":"books/pragmatic_programmer/#6-concurrency","text":"definition: Concurrency is when the execution of two or more pieces of code act as if they run at the same time. Parallelism is when they do run at the same time. concurrency is a software mechanism, and parallelism is a hardware concern. If we have multiple processors, either locally or remotely, then if we can split work out among them, we can reduce the overall time things take.","title":"6 Concurrency"},{"location":"books/pragmatic_programmer/#33-breaking-temporal-coupling","text":"temporal coupling - coupling in time. Method A must always be called before method B, only one report can be run at a time, you must wait for the screen to redraw before the button click is received. Tick must happen before tock. This is not very flexible and not very realistic. Allowing concurrency and think about decoupling of any time or order dependencies. Result: systems that are easier to reason about, that potentially respond faster and more reliably.","title":"33 Breaking Temporal Coupling"},{"location":"books/pragmatic_programmer/#looking-for-concurrency","text":"In many projects we'd like to find out what can happen at the same time and what must in a strict order. One way to do is by activity diagram . activity diagram - set of actions (drawn as rounded boxes). The arrow leads an action leads to either: another action (which can start after the first action completes) thick line called a synchronization bar once all actions leading into a synchronization bar are complete you can then proceed along any arrows leaving the bar, An action with no arrows leading into it can be started at any time. Activity diagram is used to maximize parallelism by identifying activities that could be performed in parallel but aren't. For instance, we may be writing the software for a robotic pi\u00f1a colada maker. We\u2019re told that the steps are: Open blender Open pi\u00f1a colada mix Put mix in blender Measure 1/2 cup white rum Pour in rum Add 2 cups of ice Close blender Liquefy for 1 minute Open blender Get glasses Get pink umbrellas Serve the top-level tasks (1, 2, 4, 10, and 11) can all happen concurrently, up front. Tasks 3, 5, and 6 can happen in parallel later. When we look at the activities, we realize that number 8, liquefy, will take a minute. During that time, our bartender can get the glasses and umbrellas (activities 10 and 11) and probably still have time to serve another customer.","title":"Looking for concurrency"},{"location":"books/pragmatic_programmer/#34-shared-state-is-incorrect-state","text":"Customer is in restaurant asks server if there is a pie left, he looks, sees in the display that there is one left piece and confirms. Customer orders the pie. Same thing happens on the other side of the restaurant at exact time. One of the customers will be disappointed. Both waiters operate concurrently (in real life in parallel). The problem above is shared state. Both waiters when executes display_case.pie_count() they copy the value from the display into their own memory. If the value in the display case changes their memory (which is used to make decision) is now out of date. Solution? make the operation atomic. Semaphore is a thing that only one person can own at a time. (lock/unlock claim/release) In above example it can be used to decide who can access pie case. case_semaphore.lock() if display_case.pie_count > 0 promise_pie_to_customer() display_case.take_pie() give_pie_to_customer() end case_semaphore.unlock() This approach above works and solve mentioned issue, but there is another problem. This approach as long as every developer will use the semaphore, it that's not the case we are in the same place as before. Make the Resource Transactional We can centralize that control by checking and getting pie in one call: def get_pie_if_available() @case_semaphore.lock() try { if @slices.size > 0 update_sales_data(:pie) return @slices.shift else false end } ensue { @case_semaphore.unlock() } end Random Failures Are Often Concurrency Issues","title":"34. Shared State is Incorrect State"},{"location":"books/pragmatic_programmer/#35-actors-and-processes","text":"An actor is an independent virtual processor with its own local (and private) state. Each actor has a mailbox. When a message appears in the mailbox and the actor is idle, it kicks into life and processes the message. When it finishes processing, it processes another message in the mailbox, or, if the mailbox is empty, it goes back to sleep. When processing a message, an actor can create other actors, send messages to other actors that it knows about, and create a new state that will become the current state when the next message is processed. A process is typically a more general-purpose virtual processor, often implemented by the operating system to facilitate concurrency. Processes can be constrained (by convention) to behave like actors, and that\u2019s the type of process we mean here. Actors Can Only Be Concurrent There are a few things that you won\u2019t find in the definition of actors: There\u2019s no single thing that\u2019s in control. Nothing schedules what happens next, or orchestrates the transfer of information from the raw data to the final output. The only state in the system is held in messages and in the local state of each actor. Messages cannot be examined except by being read by their recipient, and local state is inaccessible outside the actor. All messages are one way\u2014there\u2019s no concept of replying. If you want an actor to return a response, you include your own mailbox address in the message you send it, and it will (eventually) send the response as just another message to that mailbox. An actor processes each message to completion, and only processes one message at a time. As a result, actors execute concurrently, asynchronously, and share nothing. If you had enough physical processors, you could run an actor on each. If you have a single processor, then some runtime can handle the switching of context between them. Either way, the code running in the actors is the same.","title":"35 Actors and Processes"},{"location":"books/pragmatic_programmer/#tip-59-use-actors-for-concurrency-without-shared-state","text":"","title":"Tip 59 Use Actors for concurrency without Shared State"},{"location":"books/pragmatic_programmer/#topic-36-blackboards","text":"Blackboard is a common (shared?) space where multiple independent actors/processes/agents can access the stored data in a form of laissez-faire concurrency,","title":"Topic 36 Blackboards"},{"location":"books/pragmatic_programmer/#7-while-you-are-coding","text":"","title":"7 While You Are Coding"},{"location":"books/pragmatic_programmer/#37-listen-to-your-lizard-brain","text":"","title":"37 Listen to Your Lizard Brain"},{"location":"books/pragmatic_programmer/#tip-61-listen-to-your-inner-lizard","text":"First, stop what you\u2019re doing. Give yourself a little time and space to let your brain organize itself. Stop thinking about the code, do something that is fairly mindless for a while, away from a keyboard. Take a walk, have lunch, chat with someone. Maybe sleep on it. Let the ideas percolate up through the layers of your brain on their own: you can\u2019t force it. wait for a \"ha!\" moment. If that doesn't work, try to explain the code to someone (even to rubber duck). If still you have a problem, it's time for prototyping.","title":"Tip 61 Listen to Your Inner Lizard"},{"location":"books/pragmatic_programmer/#38-programming-by-coincidence","text":"Why should you take the risk of messing with something that\u2019s working? Well, we can think of several reasons: It may not really be working\u2014it might just look like it is. The boundary condition you rely on may be just an accident. In different circumstances (a different screen resolution, more CPU cores), it might behave differently. Undocumented behavior may change with the next release of the library. Additional and unnecessary calls make your code slower. Additional calls increase the risk of introducing new bugs of their own. For code, you write that others will call, the basic principles of good modularization and of hiding implementation behind small, well-documented interfaces can all help. tip: never store a phone number in numeric field","title":"38 Programming by Coincidence"},{"location":"books/pragmatic_programmer/#39-algorithm-speed","text":"","title":"39 Algorithm Speed"},{"location":"books/pragmatic_programmer/#big-o-notation-mathematical-way-of-dealing-with-approximations","text":"highest-order term will dominate the value as increases, the convention is to remove all low-order terms, and not to bother showing any constant multiplying: O(n^2/2 + 3n) == O(n^2) == O(n^2) O(1) - Constant (access element in array, simple statements) O(lg n) - Logarithmic (binary search). The base of the logarithm doesn\u2019t matter, so this is equivalent. O(n) - Linear (sequential search) O(n lg n) - Worse than linear, but not much worse. (Average runtime of quicksort, heapsort) O(n^2) - Square law (selection and insertion sorts) O(n^3) - Cubic (multiplication of two matrices) O(C^n) - Exponential (traveling salesman problem, set partitioning)","title":"Big-O Notation - mathematical way of dealing with approximations."},{"location":"books/pragmatic_programmer/#40-refactoring","text":"Software development is like gardening -You plant many things in a garden according to an initial plan and conditions. Some thrive, others are destined to end up as compost. You may move plantings relative to each other to take advantage of the interplay of light and shadow, wind and rain. Overgrown plants get split or pruned, and colors that clash may get moved to more aesthetically pleasing locations. You pull weeds, and you fertilize plantings that are in need of some extra help. You constantly monitor the health of the garden, and make adjustments (to the soil, the plants, the layout) as needed. Refactoring [Fow19] is defined by Martin Fowler as a: disciplined technique for restructuring an existing body of code, altering its internal structure without changing its external behavior. Time pressure is often used as an excuse for not refactoring. But this excuse just doesn\u2019t hold up: fail to refactor now, and there\u2019ll be a far greater time investment to fix the problem down the road\u2014when there are more dependencies to reckon with. Will there be more time available then? Nope. When explaining think of the code that needs refactoring as \"a growth.\" Removing it requires invasive surgery. You can go in now, and take it out while it is still small. Or, you could wait while it grows and spreads\u2014but removing it then will be both more expensive and more dangerous. Wait even longer, and you may lose the patient entirely. Martin Fowler offers the following simple tips on how to refactor without doing more harm than good: Don\u2019t try to refactor and add functionality at the same time. Make sure you have good tests before you begin refactoring. Run the tests as often as possible. That way you will know quickly if your changes have broken anything. Take short, deliberate steps: move a field from one class to another, split a method, rename a variable. Refactoring often involves making many localized changes that result in a larger-scale change. If you keep your steps small, and test after each step, you will avoid prolonged debugging.","title":"40 Refactoring"},{"location":"books/pragmatic_programmer/#41-test-to-code","text":"We believe that the major benefits of testing happen when you think about and write the tests, not when you run them. Why? Because it allows you to understand the under the hood requirements of feature (e.g. parameters) Use TDD, but avoid: They spend inordinate amounts of time ensuring that they always have 100% test coverage. They have lots of redundant tests. For example, before writing a class for the first time, many TDD adherents will first write a failing test that simply references the class\u2019s name. It fails, then they write an empty class definition, and it passes. But now you have a test that does absolutely nothing; the next test you write will also reference the class, and so it makes the first unnecessary. There\u2019s more stuff to change if the class name changes later. And this is just a trivial example. Their designs tend to start at the bottom and work their way up. (TIP 68, Build End-to-End, Not Top-Down or Bottom Up) Build small pieces of end-to-end functionality, learning about the problem as you go. Apply this learning as you continue to flesh out the code, involve the customer at each step, and have them guide the process. The basic cycle of TDD is: Decide on a small piece of functionality you want to add. Write a test that will pass once that functionality is implemented. Run all tests. Verify that the only failure is the one you just wrote. Write the smallest amount of code needed to get the test to pass, and verify that the tests now run cleanly. Refactor your code: see if there is a way to improve on what you just wrote (the test or the function). Make sure the tests still pass when you\u2019re done. The idea is that this cycle should be very short: a matter of minutes, so that you\u2019re constantly writing tests and then getting them to work.","title":"41 Test to Code"},{"location":"books/pragmatic_programmer/#42-property-based-testing","text":"invariants, things that remain true about some piece of state when it\u2019s passed through a function. For example, if you sort a list, the result will have the same number of elements as the original\u2014the length is invariant.","title":"42 Property-Based Testing"},{"location":"books/pragmatic_programmer/#tip-use-property-based-tests-to-validate-your-assumptions","text":"There are also code invariants, things that remain true about some piece of state when it\u2019s passed through a function. For example, if you sort a list, the result will have the same number of elements as the original\u2014the length is invariant. Once we work out our contracts and invariants (which we\u2019re going to lump together and call properties) we can use them to automate our testing. What we end up doing is called property-based testing. from hypothesis import given import hypothesis.strategies as some @given(some.lists(some.integers())) def test_list_size_is_invariant_across_sorting(a_list): original_length = len(a_list) a_list.sort() assert len(a_list) == original_length @given(some.lists(some.text())) def test_sorted_result_is_ordered(a_list): a_list.sort() for i in range(len(a_list) - 1): assert a_list[i] <= a_list[i + 1] Thomas, David; Hunt, Andrew. Pragmatic Programmer, The (pp. 394-395). Pearson Education. Kindle Edition.","title":"Tip Use property based tests to validate your assumptions"},{"location":"books/pragmatic_programmer/#43-stay-safe-out-there","text":"","title":"43 Stay Safe Out There"},{"location":"books/pragmatic_programmer/#security-basic-principles","text":"Pragmatic Programmers have a healthy amount of paranoia. We know we have faults and limitations, and that external attackers will seize on any opening we leave to compromise our systems. Your particular development and deployment environments will have their own security-centric needs, but there are a handful of basic principles that you should always bear in mind: Minimize Attack Surface Area Principle of The Least Privilege Secure Defaults Encrypt Sensitive Data Maintain Security Updates","title":"Security Basic Principles"},{"location":"books/pragmatic_programmer/#44-naming-things","text":"whenever you create something, you need to pause and think \"what is my motivation to create this?\" It\u2019s important that everyone on the team knows what project jargon means, and that they use them consistently. encourage a lof of communication e.g. Pair programming, huddles Keep project glossary, listing the terms that have special meaning ot the team (e.g. on confluence)","title":"44 Naming Things"},{"location":"books/pragmatic_programmer/#8-before-the-project","text":"","title":"8 Before The Project"},{"location":"books/pragmatic_programmer/#45-the-requirements-pit","text":"","title":"45 The Requirements Pit"},{"location":"books/pragmatic_programmer/#tip-76-programmers-help-people-understand-what-they-want","text":"we annoy people by looking for edge cases and asking about them. _- You: We were wondering about the $50 total. Does that include what we\u2019d normally charge for shipping? Client: Of course. It\u2019s the total they\u2019d pay us. You: That\u2019s nice and simple for our customers to understand: I can see the attraction. But I can see some less scrupulous customers trying to game that system. Client: How so? You: Well, let\u2019s say they buy a book for $25, and then select overnight shipping, the most expensive option. That\u2019ll likely be about $30, making the whole order $55. We\u2019d then make the shipping free, and they\u2019d get overnight shipping on a $25 book for just $25._ At this point the experienced developer stops. Deliver facts, and let the client make the decisions If it's not easy to get a feedback create a mockup and prototype to show to the client \"is this way you meant?\" this gives you quick feedback loop. walk in your cline's shoes simple way to achieve this is by becoming a client - spend time on the clients daily work routine to understand better the context.","title":"Tip 76 Programmers Help People Understand What They Want"},{"location":"books/pragmatic_programmer/#46-solving-impossible-puzzles","text":"","title":"46 Solving Impossible Puzzles"},{"location":"books/pragmatic_programmer/#tup-81-dont-think-outside-the-boxfind-the-box","text":"Whenever you're solving a hard problem focus on constrains You must challenge any preconceived notions and evaluate whether or not they are real, hard-and-fast constraints. It\u2019s not whether you think inside the box or outside the box. The problem lies in finding the box\u2014identifying the real constraints. ask questions: Why are you solving this problem? What\u2019s the benefit of solving it? Are the problems you\u2019re having related to edge cases? Can you eliminate them? Is there a simpler, related problem you can solve? When you have a problem with solving the problem always take a break and focus on something different.","title":"Tup 81 Don\u2019t Think Outside the Box\u2014Find the Box"},{"location":"books/pragmatic_programmer/#47-working-together","text":"Pair Programming - one developer operates the keyboard, and the other does not. Both work on the problem together, and can switch typing duties as needed. Mob Programming - extension of pair programing but using more than 2 people (not necessarily ony developers). you swap out the typist every 5-10 minutes.","title":"47 Working Together"},{"location":"books/pragmatic_programmer/#tip-82-dont-go-into-the-code-alone","text":"","title":"Tip 82 Don\u2019t Go into the Code Alone"},{"location":"books/pragmatic_programmer/#48-the-essence-of-agility","text":"Manifesto values: Individuals and interactions over processes and tools Working software over comprehensive documentation Customer collaboration over contract negotiation Responding to change over following a plan That is, while there is value in the items on the right, we value the items on the left more. Agile is not about process but responding to change, to the unknowns after you set out. The above values don't tell what to do. They tell you what to look for. our recipe for working in an agile way: Work out where you are. Make the smallest meaningful step towards where you want to be. Evaluate where you end up, and fix anything you broke. Repeat","title":"48 The Essence of Agility"},{"location":"books/pragmatic_programmer/#9-pragmatic-projects","text":"","title":"9 Pragmatic Projects"},{"location":"books/pragmatic_programmer/#49-pragmatic-teams","text":"team has to support the no broken window (those small imperfections that no one fixes) mentality. Also be stayed alerted to avoid being Boiled Frogs . It\u2019s even easier for teams as a whole to get boiled. People assume that someone else is handling an issue, or that the team leader must have OK\u2019d a change that your user is requesting. Even the best-intentioned teams can be oblivious to significant changes in their projects. Communicate Team Presence - team needs to communicate with the rest of the organization. To outsiders, the worst project teams are those that appear sullen and reticent. They hold meetings with no structure, where no one wants to talk. Their emails and project documents are a mess: no two look the same, and each uses different terminology. There is a simple marketing trick that helps teams communicate as one: generate a brand. When you start a project, come up with a name for it, ideally something off-the-wall. (In the past, we\u2019ve named projects after things such as killer parrots that prey on sheep, optical illusions, gerbils, cartoon characters, and mythical cities.) Spend 30 minutes coming up with a zany logo, and use it. Use your team\u2019s name liberally when talking with people. It sounds silly, but it gives your team an identity to build on, and the world something memorable to associate with your work. Organize Fully Functional Teams - That means that you need all the skills to do that within the team: frontend, UI/UX, server, DBA, QA, etc. It allows to build end-to-end functionality in small pieces.","title":"49 Pragmatic teams"},{"location":"books/pragmatic_programmer/#50-coconut-dont-cut-it","text":"The goal of course isn\u2019t to \"do Scrum,\" \"do agile,\" \"do Lean,\" or what-have-you. The goal is to be in a position to deliver working software that gives the users some new capability at a moment\u2019s notice. Not weeks, months, or years from now, but now. For many teams and organizations, continuous delivery feels like a lofty, unattainable goal, especially if you\u2019re saddled with a process that restricts delivery to months, or even weeks. But as with any goal, the key is to keep aiming in the right direction.","title":"50 Coconut don't cut it"},{"location":"books/pragmatic_programmer/#51-pragmatic-starter-kit","text":"covering three critical and interrelated topics: Version Control - is needed Regression Testing - Use all kinds of testing to make sure that your code is working properly. (Unit test, Integration tests, QA testing, performance testing) + make sure to test the state not the coverage Full Automation - if something can be automated do it (like setting up your environment, CI)","title":"51 Pragmatic Starter Kit"},{"location":"books/pragmatic_programmer/#52-delight-your-users","text":"Understand the underlying expectations of value behind the project, you can start thinking about how you can deliver against them: Make sure everyone on the team is totally clear about these expectations. When making decisions, think about which path forward moves closer to those expectations. Critically analyze the user requirements in light of the expectations. On many projects we\u2019ve discovered that the stated \"requirement\" was in fact just a guess at what could be done by technology: it was actually an amateur implementation plan dressed up as a requirements document. Don\u2019t be afraid to make suggestions that change the requirement if you can demonstrate that they will move the project closer to the objective. Continue to think about these expectations as you progress through the project.","title":"52 Delight Your Users"},{"location":"books/pragmatic_programmer/#53-pride-and-prejudice","text":"You shouldn\u2019t jealously defend your code against interlopers; by the same token, you should treat other people\u2019s code with respect. The Golden Rule (\"Do unto others as you would have them do unto you\") and a foundation of mutual respect among the developers is critical to make this tip work. We want to see pride of ownership. \"I wrote this, and I stand behind my work.\" Your signature should come to be recognized as an indicator of quality. People should see your name on a piece of code and expect it to be solid, well written, tested, and documented. A really professional job. Written by a professional.","title":"53 Pride and Prejudice"},{"location":"books/pragmatic_programmer/#10-postface","text":"Many non-embedded systems can also do both great good and great harm. Social media can promote peaceful revolution or foment ugly hate. Big data can make shopping easier, and it can destroy any vestige of privacy you might think you have. Banking systems make loan decisions that change people\u2019s lives. And just about any system can be used to snoop on its users. We\u2019ve seen hints of the possibilities of a utopian future, and examples of unintended consequences leading to nightmare dystopia. The difference between the two outcomes might be more subtle than you think. And it\u2019s all in your hands. We have a duty to ask ourselves two questions about every piece of code we deliver: Have I protected the user? Would I use this myself?","title":"10 Postface"},{"location":"books/rozwoj_w_dwoch_jezykach/","text":"Rozwoj w Dwoch jezykach bilingualism - surround by 2 languages which one of them is the language of environment and one is language of minority. language of environment - language which is spoken by the majority of people like in shool, playgroup language of minority language of minority - language spoken in minority of surrounding environment like e.g. spoken only at home.","title":"Rozwoj w Dwoch jezykach"},{"location":"books/rozwoj_w_dwoch_jezykach/#rozwoj-w-dwoch-jezykach","text":"bilingualism - surround by 2 languages which one of them is the language of environment and one is language of minority. language of environment - language which is spoken by the majority of people like in shool, playgroup language of minority language of minority - language spoken in minority of surrounding environment like e.g. spoken only at home.","title":"Rozwoj w Dwoch jezykach"},{"location":"books/kotlin_coroutines/analogy/","text":"kotlin coroutines analogy CoroutineContext, CoroutineScope, Coroutine, Jobs Imagine you are the manager(CoroutineContext) of a restaurant(CoroutineScope). As the manager, you provide a specific set of rules and resources for your employees(coroutines) to work within the restaurant. These rules and resources collectively represent the CoroutineContext. For example, the restaurant's working hours, uniforms, cooking equipment, and the specific tasks employees can perform (like cooking, serving, cleaning) are part of the CoroutineContext. Every employee (coroutine) you hire in your restaurant is given a specific job assignment (analogous to a Job). Each job has a set of responsibilities and tasks that the employee needs to perform. For instance, the chef's job is to cook meals, the server's job is to deliver food to customers, and the cleaner's job is to keep the restaurant tidy. Now, let's see how they relate to each other and what happens when we cancel one Job: Cancel all coroutines When you, as the manager, decide to close the restaurant (call cancel() on the CoroutineScope), here's what happens: All the employees (coroutines) working in the restaurant (CoroutineScope) will be notified that the restaurant is closing (cancellation is requested). Each employee (coroutine) checks their job assignment (Job) and sees the notification of restaurant closure. The employees (coroutines) will stop working on their current tasks, clean up their workstations, and leave the restaurant. Coroutine cancels itself Imagine, Each employee has a specific task (job) they are responsible for. Chef (Coroutine A) - Responsible for cooking dishes. Server (Coroutine B) - Responsible for serving food to customers. Now, let's say the Chef (Coroutine A) is cooking a dish in the kitchen when they notice a fire has broken out in the restaurant. Realizing the danger, the Chef immediately informs the manager (CoroutineContext), about the fire (cancellation propagates to the CoroutineContext). Manager in turn cancel all other employees' tasks (coroutines) within the restaurant (CoroutineScope).","title":"kotlin coroutines analogy"},{"location":"books/kotlin_coroutines/analogy/#kotlin-coroutines-analogy","text":"","title":"kotlin coroutines analogy"},{"location":"books/kotlin_coroutines/analogy/#coroutinecontext-coroutinescope-coroutine-jobs","text":"Imagine you are the manager(CoroutineContext) of a restaurant(CoroutineScope). As the manager, you provide a specific set of rules and resources for your employees(coroutines) to work within the restaurant. These rules and resources collectively represent the CoroutineContext. For example, the restaurant's working hours, uniforms, cooking equipment, and the specific tasks employees can perform (like cooking, serving, cleaning) are part of the CoroutineContext. Every employee (coroutine) you hire in your restaurant is given a specific job assignment (analogous to a Job). Each job has a set of responsibilities and tasks that the employee needs to perform. For instance, the chef's job is to cook meals, the server's job is to deliver food to customers, and the cleaner's job is to keep the restaurant tidy. Now, let's see how they relate to each other and what happens when we cancel one Job:","title":"CoroutineContext, CoroutineScope, Coroutine, Jobs"},{"location":"books/kotlin_coroutines/analogy/#cancel-all-coroutines","text":"When you, as the manager, decide to close the restaurant (call cancel() on the CoroutineScope), here's what happens: All the employees (coroutines) working in the restaurant (CoroutineScope) will be notified that the restaurant is closing (cancellation is requested). Each employee (coroutine) checks their job assignment (Job) and sees the notification of restaurant closure. The employees (coroutines) will stop working on their current tasks, clean up their workstations, and leave the restaurant.","title":"Cancel all coroutines"},{"location":"books/kotlin_coroutines/analogy/#coroutine-cancels-itself","text":"Imagine, Each employee has a specific task (job) they are responsible for. Chef (Coroutine A) - Responsible for cooking dishes. Server (Coroutine B) - Responsible for serving food to customers. Now, let's say the Chef (Coroutine A) is cooking a dish in the kitchen when they notice a fire has broken out in the restaurant. Realizing the danger, the Chef immediately informs the manager (CoroutineContext), about the fire (cancellation propagates to the CoroutineContext). Manager in turn cancel all other employees' tasks (coroutines) within the restaurant (CoroutineScope).","title":"Coroutine cancels itself"},{"location":"books/kotlin_coroutines/kotlin_coroutines/","text":"Kotlin Coroutines Deep Dive Part 1: Understanding KotlinCoroutines Why Kotlin Coroutines? Threads issues: There is no mechanism here to cancel these threads, so we often face memory leaks. Making so many threads is costly. Frequently switching threads is confusing and hard to manage. The code will unnecessarily get bigger and more complicated. Callbacks: Getting data parallelized, is not so straightforward with callbacks supporting cancellation requires a lot of additional effort. The increasing number of indentations make this code hard to read (code with multiple callbacks is often considered highly unreadable). Such a situation is called \u201ccallback hell\u201d. When we use callbacks, it is hard to control when things are triggered. Rxjava/ReactiveStreams You need to learn different functions, like subscribeOn, observeOn, map, or subscribe, Cancelling needs to be explicit. Functions need to return objects wrapped inside Observable or Single classes. In practice, when we introduce RxJava, we need to reorganize our code a lot. Using Kotlin coroutines core functionality is the ability to suspend a coroutine at some point and resume it in the future. Suspended coroutine released the thread, so thread is not blocked! suspendCoroutine<Unit> {continuation -> continuation.resume(Unit} suspendCoroutine needs to be called with resume to progress, otherwise it will always be suspended. Suspending a coroutine, not a function we suspend a coroutine, not a function. Suspending functions are not coroutines, just functions that can suspend a coroutine. Coroutines under the hood suspend fun in reality is a fun with additional parameter at the end: continuation suspend fun in reality is like state machine, with a possible state at the beginning of the function and after each suspending function call. Both the number identifying the state and the local data are kept in the continuation object. continuation of a function decorates a continuation of its caller function. As a result, all these continuations represent a call stack that is used when we resume or a resumed function completes. Part 2: Kotlin Coroutines library Coroutine builders Suspend function can't be called from normal function, it can either be started in another suspended function or from coroutine builder - bridge from the normal to the suspending world. most common used: launch runBlocking async launch The way launch works is conceptually similar to starting a new thread (thread function). launch is an extension function on the CoroutineScope interface. This is part of an important mechanism called structured concurrency , whose purpose is to build a relationship between the parent coroutine and a child coroutine. To some degree, how launch works is similar to a daemon thread but much cheaper. fun main() { thread(isDaemon = true) { Thread.sleep(1000L) println(\"World!\") } thread(isDaemon = true) { Thread.sleep(1000L) println (\"World!\") } thread(isDaemon = true) { Thread.sleep(1000L) println(\"World!\") } println(\"Hello,\") Thread.sleep(2000L) } fun main() { GlobalScope.launch { delay(1000L) println(\"World!\") } GlobalScope.launch { delay(1000L) println(\"World!\") } GlobalScope.launch { delay(1000L) println(\"World!\") } println(\"Hello,\") Thread.sleep(2000L) } runBlocking builder (currently rarely used) runBlocking is a very atypical builder. It blocks the thread it has been started on whenever its coroutine is suspended (similar to suspending main). This means that delay(1000L) inside runBlocking will behave like Thread.sleep(1000L) : fun main() { Thread.sleep(1000L) println(\"World!\") Thread.sleep(1000L) println(\"World!\") Thread.sleep(1000L) println(\"World!\") println(\"Hello,\") } fun main() { runBlocking { delay(1000L) println(\"World!\") } runBlocking { delay(1000L) println(\"World!\") } runBlocking { delay(1000L) println(\"World!\") } println(\"Hello,\") } Use cases in which runBlocking is used: main function, where we need to block the thread, because otherwise the program will end. unit tests, where we need to block the thread for the same reason. async builder Similar to launch , but produce a value. The async function returns an object of type Deferred<T> , where T is the type of the produced value. Deferred has a suspending method await, which returns this value once it is ready. Just like the launch builder, async starts a coroutine immediately when it is called. So, it is a way to start a few processes at once and then await all their results. The returned Deferred stores a value inside itself once it is produced, so once it is ready it will be immediately returned from await . However, if we call await before the value is produced, we are suspended until the value is ready. fun main() = runBlocking { val res1 = GlobalScope.async { delay(1000L) \"Text 1\" } val res2 = GlobalScope.async { delay(3000L) \"Text 2\" } val res3 = GlobalScope.async { delay(2000L) \"Text 3\" } println(res1.await()) println(res2.await()) println(res3.await()) } How the async builder works is very similar to launch , but it has additional support for returning a value. If all launch functions were replaced with async , the code would still work fine. But don\u2019t do that! async is about producing a value, so if we don\u2019t need a value, we should use launch . fun main() = runBlocking { // Don't do that! // this is misleading to use async as launch GlobalScope.async { delay(1000L) println(\"World!\") } println(\"Hello,\") delay(2000L) } The async builder is often used to parallelize two processes, such as obtaining data from two different places, to combine them together. scope.launch { val news = async { newsRepo.getNews() .sortedByDescending { it.date } } val newsSummary = newsRepo.getNewsSummary() // we could wrap it with async as well, // but it would be redundant view.showNews( newsSummary, news.await() ) } Structured Concurrency If a coroutine is started on GlobalScope , the program will not wait for it. As previously mentioned, coroutines do not block any threads, and nothing prevents the program from ending. This is why, in the below example, an additional delay at the end of runBlocking needs to be called if we want to see \u201cWorld!\u201d printed. fun main() = runBlocking { GlobalScope.launch { delay(1000L) println(\"World!\") } GlobalScope.launch { delay(2000L) println(\"World!\") } println(\"Hello,\") // delay(3000L) } // Hello, Why do we need this GlobalScope in the first place? It is because launch and async are extension functions on CoroutineScope . However, if you take a look at the definitions of these and of runBlocking , you will see that the block parameter is a function type whose receiver type is also CoroutineScope . This means we don't need GlobalScope , instead, launch can be called on the receiver provided by runBlocking . fun main() = runBlocking { this.launch { // same as just launch delay(1000L) println(\"World!\") } launch { // same as this.launch delay(2000L) println(\"World!\") } println(\"Hello,\") } parent-child relationship A parent provides a scope for its children, and they are called in this scope. This builds a relationship that is called a structured concurrency. Here are the most important effects of the parent-child relationship: children inherit context from their parent (but they can also overwrite) a parent suspends until all the children are finished when the parent is cancelled,its child coroutines are cancelled too when a child raises an error,it destroys the parent as well Notice that, unlike other coroutine builders, runBlocking is not an extension function on CoroutineScope. This means that it cannot be a child: it can only be used as a root coroutine (the parent of all the children in a hierarchy). This means that runBlocking will be used in different cases than other coroutines. As we mentioned before, this is very different from other builders. Coroutine context CoroutineContext is conceptually similar to a map or a set collection. It is an indexed set of Element instances, where each Element is also a CoroutineContext . Every element in it has a unique Key that is used to identify it. This way, CoroutineContext is just a universal way to group and pass objects to coroutines. These objects are kept by the coroutines and can determine how these coroutines should be running (what their state is, in which thread, etc). Adding contexts - What makes CoroutineContext truly useful is the ability to merge two of them together. When two elements with different keys are added, the resulting context responds to both keys. fun main() { val ctx1: CoroutineContext = CoroutineName(\"Name1\") println(ctx1[CoroutineName]?.name) // Name1 println(ctx1[Job]?.isActive) // null val ctx2: CoroutineContext = Job() println(ctx2[CoroutineName]?.name) // null println(ctx2[Job]?.isActive) // true, because \"Active\" // is the default state of a job created this way val ctx3 = ctx1 + ctx2 println(ctx3[CoroutineName]?.name) // Name1 println(ctx3[Job]?.isActive) // true } When another element with the same key is added, just like in a map , the new element replaces the previous one. fun main() { val ctx1: CoroutineContext = CoroutineName(\"Name1\") println(ctx1[CoroutineName]?.name) // Name1 val ctx2: CoroutineContext = CoroutineName(\"Name2\") println(ctx2[CoroutineName]?.name) // Name2 val ctx3 = ctx1 + ctx2 println(ctx3[CoroutineName]?.name) // Name2 } Subtracting elements - Elements can also be removed from a context by their key using the minusKey function. Folding context - If we need to do something for each element in a context, we can use the fold method, which is similar to fold for other collections. Coroutine context and builders So CoroutineContext is just a way to hold and pass data. By default, the parent passes its context to the child, which is one of the parent-child relationship effects. We say that the child inherits context from its parent. Since new elements always replace old ones with the same key, the child context always overrides elements with the same key from the parent context. The defaults are used only for keys that are not specified anywhere else. Currently, the defaults only set Dispatchers.Default when no ContinuationInterceptor is set, and they only set CoroutineId when the application is in debug mode. There is a special context called Job , which is mutable and is used to communicate between a coroutine\u2019s child and its parent. Accessing context in a suspending function Context is referenced by continuations, which are passed to each suspending function. So, it is possible to access a parent\u2019s context in a suspending function. To do this, we use the coroutineContext property, which is available in every suspending scope. suspend fun printName() { println(coroutineContext[CoroutineName]?.name) } suspend fun main() = withContext(CoroutineName(\"Outer\")) { printName() // Outer launch(CoroutineName(\"Inner\")) { printName() // Inner } delay(10) printName() // Outer } Creating our own context It is not a common need, but we can create our own coroutine context pretty easily. To do this, the easiest way is to create a class that implements the CoroutineContext.Element interface. Such a class needs a property key of type CoroutineContext.Key<*>. This key will be used as the key that identifies this context. The common practice is to use this class\u2019s companion object as a key. This is how a very simple coroutine context can be implemented: class MyCustomContext : CoroutineContext.Element { override val key: CoroutineContext.Key<*> = Key companion object Key : CoroutineContext.Key<MyCustomContext> } job Conceptually, a job represents a cancellable thing with a lifecycle. Formally, Job is an interface, but it has a concrete contract and state, so it might be treated similarly to an abstract class. A job lifecycle is represented by its state. Here is a graph of states and the transitions between them: In the \u201cActive\u201d state, a job is running and doing its job. If the job is created with a coroutine builder, this is the state where the body of this coroutine will be executed. In this state, we can start child coroutines. Most coroutines will start in the \u201cActive\u201d state. Only those that are started lazily will start with the \u201cNew\u201d state. These need to be started in order for them to move to the \u201cActive\u201d state. When a coroutine is executing its body, it is surely in the \u201cActive\u201d state. When it is done, its state changes to \u201cCompleting\u201d, where it waits for its children. Once all its children are done, the job changes its state to \u201cCompleted\u201d, which is a terminal one. Alternatively, if a job cancels or fails when running (in the \u201cActive\u201d or \u201cCompleting\u201d state), its state will change to \u201cCancelling\u201d. In this state, we have the last chance to do some clean-up, like closing connections or freeing resources (we will see how to do this in the next chapter). Once this is done, the job will move to the \u201cCancelled\u201d state. Every coroutine builder from the Kotlin Coroutines library creates its own job. Most coroutine builders return their jobs, so it can be used elsewhere. This is clearly visible for launch, where Job is an explicit result type. There is a very important rule: Job is the only coroutine context that is not inherited by a coroutine from a coroutine . Every coroutine creates its own Job, and the job from an argument or parent coroutine is used as a parent of this new job. The parent can reference all its children, and the children can refer to the parent. This parent-child relationship (Job reference storing) enables the implementation of cancellation and exception handling inside a coroutine\u2019s scope. Structured concurrency mechanisms will not work if a new Job context replaces the one from the parent. To see this, we might use the Job() function, which creates a Job context (this will be explained later). fun main(): Unit = runBlocking { launch(Job()) { // the new job replaces one from parent delay(1000) println(\"Will not be printed\") } } // (prints nothing, finishes immediately) In the above example, the parent does not wait for its children because it has no relation with them. This is because the child uses the job from the argument as a parent, so it has no relation to the runBlocking. When a coroutine has its own (independent) job, it has nearly no relation to its parent. It only inherits other contexts, but other results of the parent-child relationship will not apply. This causes us to lose structured concurrency, which is a problematic situation that should be avoided. The first important advantage of a job is that it can be used to wait until the coroutine is completed. For that, we use the join method. This is a suspending function that suspends until a concrete job reaches a final state (either Completed or Cancelled). fun main(): Unit = runBlocking { val job1 = launch { delay(1000) println(\"Test1\") } val job2 = launch { delay(2000) println(\"Test2\") } job1.join() job2.join() println(\"All tests are done\") } // (1 sec) // Test1 // (1 sec) // Test2 // All tests are done The Job interface also exposes a children property that lets us reference all its children. We might as well use it to wait until all children are in a final state. val children = coroutineContext[Job]?.children children?.forEach { it.join() } println(\"All tests are done\") Cancellation Basic cancellation The Job interface has a cancel method, which allows its cancellation. Calling it triggers the following effects: \u2022 Such a coroutine ends the job at the first suspension point ( delay in the example below). \u2022 If a job has some children, they are also cancelled (but its parent is not affected). \u2022 Once a job is cancelled, it cannot be used as a parent for any new coroutines. It is first in the Cancelling and then in the Cancelled state. We might cancel with a different exception (by passing an exception as an argument to the cancel function) to specify the cause. This cause needs to be a subtype of CancellationException, because only an exception to this type can be used to cancel a coroutine. After cancel, we often also add join to wait for the cancellation to finish before we can proceed. Without this, we would have some race conditions. The snippet below shows an example in which without join we will see \u201cPrinting 4\u201d after \u201cCancelled successfully\u201d. suspend fun main() = coroutineScope { val job = launch { repeat(1_000) { i -> delay(100) Thread.sleep(100) // We simulate long operation println(\"Printing $i\") } } delay(1000) job.cancel() println(\"Cancelled successfully\") } // Printing 0 // Printing 1 // Printing 2 // Printing 3 // Cancelled successfully // Printing 4 Adding job.join() would change this because it suspends until a coroutine has finished cancellation (I guess currently it's in cancelling state, hence it's still able to produce values). To make it easier to call cancel and join together, the kotlinx.coroutines library offers a convenient extension function with a self-descriptive name, cancelAndJoin . Keep in mind that a cancelled coroutine is not just stopped: it is cancelled internally using an exception. Therefore, we can freely clean up everything inside the finally block. For instance, we can use a finally block to close a file or a database connection. Since most resource-closing mechanisms rely on the finally block (for instance, if we read a file using useLines), we simply do not need to worry about them. Just one more call Since we can catch CancellationException and invoke more operations before the coroutine truly ends, you might be wondering where the limit is. The coroutine can run as long as it needs to clean up all the resources. However, suspension is no longer allowed. The Job is already in a \u201cCancelling\u201d state, in which suspension or starting another coroutine is not possible at all. If we try to start another coroutine, it will just be ignored. If we try to suspend, it will throw CancellationException. suspend fun main(): Unit = coroutineScope { val job = Job() launch(job) { try { delay(2000) println(\"Job is done\") } finally { println(\"Finally\") launch { // will be ignored println(\"Will not be printed\") } delay(1000) // here exception is thrown println(\"Will not be printed\") } } delay(1000) job.cancelAndJoin() println(\"Cancel done\") } // (1 sec) // Finally // Cancel done Sometimes, we truly need to use a suspending call when a coroutine is already cancelled. For instance, we might need to roll back changes in a database. In this case, the preferred way is to wrap this call with the withContext( NonCancellable) function. We will later explain in detail how withContext works. For now, all we need to know is that it changes the context of a block of code. Inside withContext, we used the NonCancellable object, which is a Job that cannot be cancelled. So, inside the block the job is in the active state, and we can call whatever suspending functions we want. Stopping the unstoppable Because cancellation happens at the suspension points, it will not happen if there is no suspension point. To simulate such a situation, we could use Thread.sleep instead of delay. This is a terrible practice, so please don\u2019t do this in any real-life projects. suspend fun main(): Unit = coroutineScope { val job = Job() launch(job) { repeat(1_000) { i -> Thread.sleep(200) // We might have some // complex operations or reading files here // without suspension println(\"Printing $i\") } } delay(1000) job.cancelAndJoin() println(\"Cancelled successfully\") delay(1000) } // Printing 0 // Printing 1 // Printing 2 // ... (up to 1000) solution to lack of suspension: using yield() - It is a good practice to use yield in suspend functions, between blocks of non-suspended CPU-intensive or time-intensive operations. launch(job) { repeat(1_000) { i -> Thread.sleep(200) yield() println(\"Printing $i\") } } check if the current job is active launch(job) { do { Thread.sleep(200) println(\"Printing\") } while (isActive) } Use ensureActive() which throws CancellationException if Job is not active launch(job) { repeat(1000) { num -> Thread.sleep(200) ensureActive() println(\"Printing $num\") } } The result of ensureActive() and yield() seem similar, but they are very different. The function ensureActive() needs to be called on a CoroutineScope (or CoroutineContext, or Job). All it does is throw an exception if the job is no longer active. It is lighter, so generally it should be preferred. The function yield is a regular top-level suspension function. It does not need any scope, so it can be used in regular suspending functions. Since it does suspension and resuming, other effects might arise, such as thread changing if we use a dispatcher with a pool of threads (more about this in the Dispatchers chapter). yield is more often used just in suspending functions that are CPU intensive or are blocking threads. suspendCancellableCoroutine Most often we use it to cancel processes in a library or to free some resources. Here, you might remind yourself of the suspendCancellableCoroutine function introduced in the How does suspension work? chapter. It behaves like suspendCoroutine, but its continuation is wrapped into CancellableContinuation , which provides some additional methods. The most important one is invokeOnCancellation, which we use to define what should happen when a coroutine is cancelled. suspend fun someTask() = suspendCancellableCoroutine { cont -> cont.invokeOnCancellation { // do cleanup } // rest of the implementation } Exception handling A very important part of how coroutines behave is their exception handling. Just as a program breaks when an uncaught exception slips by, a coroutine breaks in the case of an uncaught exception. This behavior is nothing new: for instance, threads also end in such cases. The difference is that coroutine builders also cancel their parents, and each cancelled parent cancels all its children. Let\u2019s look at the example below. Once a coroutine receives an exception, it cancels itself and propagates the exception to its parent ( launch ). The parent cancels itself and all its children, then it propagates the exception to its parent ( runBlocking ). runBlocking is a root coroutine (it has no parent), so it just ends the program ( runBlocking rethrows the exception). fun main(): Unit = runBlocking { launch { launch { delay(1000) throw Error(\"Some error\") } launch { delay(2000) println(\"Will not be printed\") } launch { delay(500) // faster than the exception println(\"Will be printed\") } } launch { delay(2000) println(\"Will not be printed\") } } // Will be printed // Exception in thread \"main\" java.lang.Error: Some error... Exception propagation is bidirectional : the exception is propagated from child to parent, and when those parents are cancelled, they cancel their children. Thus, if exception propagation is not stopped, all coroutines in the hierarchy will be cancelled. Stop breaking my coroutines Catching an exception before it breaks a coroutine is helpful, but any later is too late. Communication happens via a job, so wrapping a coroutine builder with a try-catch is not helpful at all. fun main(): Unit = runBlocking { // Don't wrap in a try-catch here. It will be ignored. try { launch { delay(1000) throw Error(\"Some error\") } } catch (e: Throwable) { // nope, does not help here println(\"Will not be printed\") } launch { delay(2000) println(\"Will not be printed\") } } // Exception in thread \"main\" java.lang.Error: Some error... SupervisorJob The most important way to stop coroutines breaking is by using a SupervisorJob. This is a special kind of job that ignores all exceptions in its children. SupervisorJob is generally used as part of a scope in which we start multiple coroutines (more about this in the Constructing coroutine scope chapter). fun main(): Unit = runBlocking { val scope = CoroutineScope(SupervisorJob()) scope.launch { delay(1000) throw Error(\"Some error\") } scope.launch { delay(2000) println(\"Will be printed\") } delay(3000) } // Exception... // Will be printed A common mistake is to use a SupervisorJob as an argument to a parent coroutine, like in the code below. It won\u2019t help us handle exceptions, because in such a case SupervisorJob has only one direct child, namely the launch defined at 1 that received this SupervisorJob as an argument. So, in such a case there is no advantage of using SupervisorJob over Job (in both cases, the exception will not prop-agate to runBlocking because we are not using its job). fun main(): Unit = runBlocking { // Don't do that, SupervisorJob with one child // and no parent works similar to just Job launch(SupervisorJob()) { // 1 launch { delay(1000) throw Error(\"Some error\") } launch { delay(2000) println(\"Will not be printed\") } } delay(3000) } // Exception... It would make more sense if we used the same job as a context for multiple coroutine builders because each of them can be cancelled, but they won\u2019t cancel each other. fun main(): Unit = runBlocking { val job = SupervisorJob() launch(job) { delay(1000) throw Error(\"Some error\") } launch(job) { delay(2000) println(\"Will be printed\") } job.join() } // (1 sec) // Exception... // (1 sec) // Will be printed supervisorScope Another way to stop exception propagation is to wrap coroutine builders with supervisorScope. This is very convenient as we still keep a connection to the parent, yet any exceptions from the coroutine will be silenced. fun main(): Unit = runBlocking { supervisorScope { launch { delay(1000) throw Error(\"Some error\") } launch { delay(2000) println(\"Will be printed\") } } delay(1000) println(\"Done\") } // Exception... // Will be printed // (1 sec) // Done The common way to use it is to start multiple independent tasks . suspend fun notifyAnalytics(actions: List<UserAction>) = supervisorScope { actions.forEach { action -> launch { notifyAnalytics(action) } } } Beware, that supervisorScope cannot be replaced with withContext(SupervisorJob())! Take a look at the below snippet. // DON'T DO THAT! suspend fun sendNotifications( notifications: List<Notification> ) = withContext(SupervisorJob()) { for (notification in notifications) { launch { client.send(notification) } } } The problem here is that Job is the only context that is not inherited. Each coroutine needs its own job, and passing a job to a coroutine makes it a parent. So here SupervisorJob is a parent of withContext coroutine. When a child has an exception, it propagates to coroutine coroutine, cancels its Job, cancels children, and throws an exception. The fact that SupervisorJob is a parent changes nothing. CancellationException does not propagate to its parent If an exception is a subclass of CancellationException, it will not be propagated to its parent. It will only cause cancellation of the current coroutine. CancellationException is an open class, so it can be extended by our own classes or objects. object MyNonPropagatingException : CancellationException() suspend fun main(): Unit = coroutineScope { launch { // 1 launch { // 2 delay(2000) println(\"Will not be printed\") } throw MyNonPropagatingException // 3 } launch { // 4 delay(2000) println(\"Will be printed\") } } // (2 sec) // Will be printed In the above snippet, we start two coroutines with builders at 1 and 4. At 3, we throw a MyNonPropagatingException exception, which is a subtype of CancellationException. This exception is caught by launch (started at 1). This builder cancels itself, then it also cancels its children, namely the builder defined at 2. The launch started at 4 is not affected, so it prints \u201cWill be printed\u201d after 2 seconds. Coroutine exception handler When dealing with exceptions, sometimes it is useful to define default behavior for all of them. This is where the CoroutineExceptionHandler context comes in handy. It does not stop the exception propagating, but it can be used to define what should happen in the case of an exception (by default, it prints the exception stack trace). fun main(): Unit = runBlocking { val handler = CoroutineExceptionHandler { ctx, exception -> println(\"Caught $exception\") } val scope = CoroutineScope(SupervisorJob() + handler) scope.launch { delay(1000) throw Error(\"Some error\") } scope.launch { delay(2000) println(\"Will be printed\") } delay(3000) } // Caught java.lang.Error: Some error // Will be printed This context is useful on many platforms to add a default way of dealing with exceptions. For Android, it often informs the user about a problem by showing a dialog or an error message. Coroutine scope functions GlobalScope is just a scope with EmptyCoroutineContext. object GlobalScope : CoroutineScope { override val coroutineContext: CoroutineContext get() = EmptyCoroutineContext } If we call async on a GlobalScope, we will have no relationship to the parent coroutine. This means that the async coroutine: cannot be cancelled(if the parent is cancelled,functions inside async still run, thus wasting resources until they are done); does not inherit a scope from any parent (it will always run on the default dispatcher and will not respect any context from the parent). The most important consequences are: potential memory leaks and redundant CPU usage; the tools for unit testing coroutines will not work here, so testing this function is very hard. coroutineScope Unlike async or launch, the body of coroutineScope is called in-place. It formally creates a new coroutine, but it suspends the previous one until the new one is finished, so it does not start any concurrent process. Take a look at the below example, in which both delay calls suspend runBlocking. fun main() = runBlocking { val a = coroutineScope { delay(1000) 10 } println(\"a is calculated\") val b = coroutineScope { delay(1000) 20 } println(a) // 10 println(b) // 20 } // (1 sec) // a is calculated // (1 sec) // 10 // 20 The provided scope inherits its coroutineContext from the outer scope, but it overrides the context\u2019s Job. Thus, the produced scope respects its parental responsibilities: inherits a context from its parent; waits for all its children before it can finish itself; cancels all its children when the parent is cancelled. In the example below, you can observe that \u201cAfter\u201d will be printed at the end because coroutineScope will not finish until all its children are finished. Also, CoroutineName is properly passed from parent to child. Coroutine builders (except for runBlocking) Coroutine scope functions launch, async, produce coroutineScope, supervisorScope, withContext, withTimeout Are extension functions on CoroutineScope. Are suspending functions. Take coroutine context from CoroutineScope receiver. Take coroutine context from suspending function continuation. Exceptions are propagated to the parent through Job. Exceptions are thrown in the same way as they are from/by regular functions. Starts an asynchronous coroutine. Starts a coroutine that is called in-place. withContext The withContext function is similar to coroutineScope, but it additionally allows some changes to be made to the scope. The context provided as an argument to this function overrides the context from the parent scope (the same way as in coroutine builders). This means that withContext(EmptyCoroutineContext) and coroutineScope() behave in exactly the same way it\u2019s better to use coroutineScope and withContext, and avoid async with immediate await. supervisorScope The supervisorScope function also behaves a lot like coroutineScope: it creates a CoroutineScope that inherits from the outer scope and calls the specified suspend block in it. The difference is that it overrides the context\u2019s Job with SupervisorJob, so it is not cancelled when a child raises an exception. supervisorScope is mainly used in functions that start multiple independent tasks. withTimeout Another function that behaves a lot like coroutineScope is withTimeout. It also creates a scope and returns a value. Actually, withTimeout with a very big timeout behaves just like coroutineScope. The difference is that withTimeout additionally sets a time limit for its body execution. If it takes too long, it cancels this body and throws TimeoutCancellationException (a subtype of CancellationException). The function withTimeout is especially useful for testing. It can be used to test if some function takes more or less than some time. If it is used inside runTest, it will operate in virtual time. We also use it inside runBlocking to just limit the execution time of some function (this is then like setting timeout on @Test). class Test { @Test fun testTime2() = runTest { withTimeout(1000) { // something that should take less than 1000 delay(900) // virtual time } } @Test(expected = TimeoutCancellationException::class) fun testTime1() = runTest { withTimeout(1000) { // something that should take more than 1000 delay(1100) // virtual time } } @Test fun testTime3() = runBlocking { withTimeout(1000) { } } } Beware that withTimeout throws TimeoutCancellationException, which is a subtype of CancellationException (the same exception that is thrown when a coroutine is cancelled). So, when this exception is thrown in a coroutine builder, it only cancels it and does not affect its parent (as explained in the previous chapter). Additional operations Imagine a case in which in the middle of some processing you need to execute an additional operation. For example, after showing a user profile you want to send a request for analytics purposes. People often do this with just a regular launch in the same scope: However, there are some problems with this approach. Firstly, this launch does nothing here because coroutineScope needs to await its completion anyway. So if you are showing a progress bar when updating the view, the user needs to wait until this notifyProfileShown is finished as well. This does not make much sense. The second problem is cancellation. Coroutines are designed (by default) to cancel other operations when there is an exception. This is great for essential operations. If getProfile has an exception, we should cancel getName and getFriends because their response would be useless anyway. However, canceling a process just because an analytics call has failed does not make much sense. So what should we do? When you have an additional (non-essential) operation that should not influence the main process, it is better to start it on a separate scope. Creating your own scope is easy. In this example, we create an analyticsScope. val analyticsScope = CoroutineScope(SupervisorJob()) For unit testing and controlling this scope, it is better to inject it via a constructor. Dispatchers In the English dictionary, a dispatcher is defined as \u201ca person who is responsible for sending people or vehicles to where they are needed, especially emergency vehicles\u201d. In Kotlin coroutines, CoroutineContext determines on which thread a certain coroutine will run. Default dispatcher If you don\u2019t set any dispatcher, the one chosen by default is Dispatchers.Default, which is designed to run CPU-intensive operations. It has a pool of threads with a size equal to the number of cores in the machine your code is running on (but not less than two) . At least theoretically, this is the optimal number of threads, assuming you are using these threads efficiently, i.e., performing CPU-intensive calculations and not blocking them. IO dispatcher or instance, if you need to perform long I/O operations (e.g., read big files) or if you need to use a library with blocking functions. You cannot block the Main thread, because your application would freeze. If you block your default dispatcher, you risk blocking all the threads in the thread pool, in which case you wouldn't be able to do any calculations. This is why we need a dispatcher for such a situation, and it is Dispatchers.IO. Dispatchers.IO is designed to be used when we block threads with I/O operations, for instance, when we read/write files, use Android shared preferences, or call blocking functions. The code below takes around 1 second because Dispatchers.IO allows more than 50 active threads at the same time. suspend fun main() { val time = measureTimeMillis { coroutineScope { repeat(50) { launch(Dispatchers.IO) { Thread.sleep(1000) } } println(time) // ~1000 } } } How does it work? Imagine an unlimited pool of threads. Initially, it is empty, but as we need more threads, they are created and kept active until they are not used for some time. Such a pool exists, but it wouldn't be safe to use it directly. With too many active threads, the performance degrades in a slow but unlimited manner, eventually causing out-of-memory errors. This is why we create dispatchers that have a limited number of threads they can use at the same time. Dispatchers.Default is limited by the number of cores in your processor. The limit of Dispatchers.IO is 64 (or the number of cores if there are more). As we mentioned, both Dispatchers.Default and Dispatchers.IO share the same pool of threads. This is an important optimization. Threads are reused, and often redispatching is not needed. For instance, let\u2019s say you are running on Dispatchers.Default and then execution reaches withContext(Dispatchers.IO) { ... }. Most often, you will stay on the same thread33, but what changes is that this thread counts not towards the Dispatchers.Default limit but towards the Dispatchers.IO limit. Their limits are independent, so they will never starve each other. IO dispatcher with a custom pool of threads Dispatchers.IO has a special behavior defined for the limitedParallelism function. It creates a new dispatcher with an independent pool of threads. What is more, this pool is not limited to 64 as we can decide to limit it to as many threads as we want. For example, imagine you start 100 coroutines, each of which blocks a thread for a second. If you run these coroutines on Dispatchers.IO, it will take 2 seconds. If you run them on Dispatchers.IO with limitedParallelism set to 100 threads, it will take 1 second. Execution time for both dispatchers can be measured at the same time because the limits of these two dispatchers are independent anyway. Sharing a state For all dispatchers using multiple threads, we need to consider the shared state problem. Notice that in the example below 10,000 coroutines are increasing i by 1. So, its value should be 10,000, but it is a smaller number. This is a result of a shared state (i property) modification on multiple threads at the same time. var i = 0 suspend fun main(): Unit = coroutineScope { repeat(10_000) { launch(Dispatchers.IO) { // or Default i++ } } delay(1000) println(i) // ~9930 } There are many ways to solve this problem, but one option is to use a dispatcher with just a single thread. If we use just a single thread at a time, we do not need any other synchronization. var i = 0 suspend fun main(): Unit = coroutineScope { val dispatcher = Dispatchers.Default .limitedParallelism(1) repeat(10000) { launch(dispatcher) { i++ } } delay(1000) println(i) // 10000 } The biggest disadvantage is that because we have only one thread, our calls will be handled sequentially if we block it. Using virtual threads from Project Loom JVM platform introduced a new technology known as Project Loom. Its biggest innovation is the introduction of virtual threads, which are much lighter than regular threads. It costs much less to have blocked virtual threads than to have a regular thread blocked. At the moment, Project Loom is still young, and it is hard actually to use it, but I must say it is an exciting substitution for Dispatchers.IO. However, you will likely not need it in the future, as the Kotlin Coroutines team expresses their willingness to use virtual threads by default once Project Loom gets stable. I hope it will happen soon. Unconfined dispatcher The last dispatcher we need to discuss is Dispatchers.Unconfined. This dispatcher is different from the previous one as it does not change any threads. When it is started, it runs on the thread on which it was started. If it is resumed, it runs on the thread that resumed it. This is sometimes useful for unit testing. Imagine that you need to test a function that calls launch. Synchronizing the time might not be easy. One solution is to use Dispatchers.Unconfined instead of all other dispatchers. If it is used in all scopes, everything runs on the same thread, and we can more easily control the order of operations. This trick is not needed if we use runTest from kotlinx-coroutines-test. We will discuss this later in the book. From the performance point of view, this dispatcher is the cheapest as it never requires thread switching. So, we might choose it if we do not care at all on which thread our code is running. However, in practice, it is not considered good to use it so recklessly. What if, by accident, we miss a blocking call, and we are running on the Main thread? This could lead to blocking the entire application. Performance of dispatchers against different tasks There are a few important observations you can make: When we are just suspending, it doesn\u2019t really matter how many threads we are using. When we are blocking, the more threads we are using, the faster all these coroutines will be finished. With CPU-intensive operations, Dispatchers.Default is the best option. If we are dealing with a memory-intensive problem, more threads might provide some (but not a significant) improvement. Summary of dispatchers Dispatchers determine on which thread or thread pool a coroutine will be running (starting and resuming). The most important options are: \u2022 Dispatchers.Default, which we use for CPU-intensive operations; \u2022 Dispatchers.Main, which we use to access the Main thread on Android, Swing, or JavaFX; \u2022 Dispatchers.Main.immediate, which runs on the same thread as Dispatchers.Main but is not re-dispatched if it is not necessary; \u2022 Dispatchers.IO, which we use when we need to do some blocking operations; \u2022 Dispatchers.IO with limited parallelism or a custom dispatcher with a pool of threads, which we use when we might have a big number of blocking calls; \u2022 Dispatchers.Default or Dispatchers.IO with parallelism limited to 1, or a custom dispatcher with a single thread, which is used when we need to secure shared state modifications; \u2022 Dispatchers.Unconfined, which we use when we do not care where the coroutine will be executed. Constructing a coroutine scope CoroutineScope is an interface with a single property coroutineContext. interface CoroutineScope { val coroutineContext: CoroutineContext } Therefore, we can make a class implement this interface and just directly call coroutine builders in it. class SomeClass : CoroutineScope { override val coroutineContext: CoroutineContext = Job() fun onStart() { launch { // ... } } } However, this approach is not very popular. On one hand, it is convenient; on the other, it is problematic that in such a class we can directly call other CoroutineScope methods like cancel or ensureActive. Even accidentally, someone might cancel the whole scope, and coroutines will not start anymore. Instead, we generally prefer to hold a coroutine scope as an object in a property and use it to call coroutine builders. Constructing a scope on Android This is how proper implementation can look like: abstract class BaseViewModel( private val onError: (Throwable) -> Unit ) : ViewModel() { private val exceptionHandler = CoroutineExceptionHandler { _, throwable -> onError(throwable) } private val context = Dispatchers.Main + SupervisorJob() + exceptionHandler protected val scope = CoroutineScope(context) override fun onCleared() { context.cancelChildren() } } viewModelScope and lifecycleScope In modern your(needs version 2.2.0 or higher) or lifecycleScope (needs androidx.lifecycle:lifecycle-runtime-ktx version 2.2.0 or higher). How they work is nearly identical to what we\u2019ve just constructed: they use Dispatchers.Main and SupervisorJob, and they cancel the job when the view model or lifecycle owner gets destroyed. Using viewModelScope and lifecycleScope is convenient and recommended if we do not need any special context as a part of our scope (like CoroutineExceptionHandler). This is why this approach is chosen by many (maybe most) Android applications. Constructing a scope for additional calls As explained in the Additional operations section of the Coroutine scope functions chapter, we often make scopes for starting additional operations. These scopes are then typically injected via arguments to functions or the constructor. If we only plan to use these scopes to suspend calls, it is enough if they just have a SupervisorScope. val analyticsScope = CoroutineScope(SupervisorJob()) The problem with shared state given: class UserDownloader( private val api: NetworkService ) { private val users = mutableListOf<User>() fun downloaded(): List<User> = users.toList() suspend fun fetchUser(id: Int) { val newUser = api.fetchUser(id) users.add(newUser) } } Since it can be started on more than one thread at the same time, we say users is a shared state , therefore it needs to be secured. This is because concurrent modifications can lead to conflicts. Users will be added at the same time by different threads which will cause that some of them won't be saved. More on this in Multithreading To solve above we can try below solutions: Blocking synchronization Issues: inside synchronized block you cannot use suspending functions. this is blocking threads when a coroutine is waiting for its turn AtomicValue private var counter = AtomicInteger() fun main() = runBlocking { massiveRun { counter.incrementAndGet() } println(counter.get()) // 1000000 } It works perfectly here, but the utility of atomic values is generally very limited, therefore we need to be careful: just knowing a single operation will be atomic does not help us when we have a bundle of operations. private var counter = AtomicInteger() fun main() = runBlocking { massiveRun { counter.set(counter.get() + 1) } println(counter.get()) // ~430467 } To secure our UserDownloader , we could use the AtomicReference wrapping around the read-only list of users. We can use the getAndUpdate atomic function to update its value without conflicts. class UserDownloader( private val api: NetworkService ) { private val users = AtomicReference(listOf<User>()) fun downloaded(): List<User> = users.get() suspend fun fetchUser(id: Int) { val newUser = api.fetchUser(id) users.getAndUpdate { it + newUser } } } A dispatcher limited to a single thread We saw a dispatcher with parallelism limited to a single thread in the Dispatchers chapter. This is the easiest solution for most problems with shared states. val dispatcher = Dispatchers.IO.limitedParallelism(1) var counter = 0 fun main() = runBlocking { massiveRun { withContext(dispatcher) { counter++ } } println(counter) // 1000000 } In practice, this approach can be used in two ways: coarse-grained thread confinement we just wrap the whole function with withContext , with a dispatcher limited to a single thread. Single thread for doing a whole job. This approach is known as coarse-grained thread confinement. fine-grained thread confinement we wrap only those statements which modify the state. This approach is more demanding, but it offers us better performance Mutex The last popular approach is to use a Mutex . You can imagine it as a room with a single key (or maybe a toilet at a cafeteria). Its most important function is lock. When the first coroutine calls it, it kind of takes the key and passes through lock without suspension. If another coroutine then calls lock, it will be suspended until the first coroutine calls unlock (like a person waiting for a key to the toilet). suspend fun main() = coroutineScope { repeat(5) { launch { delayAndPrint() } } } val mutex = Mutex() suspend fun delayAndPrint() { mutex.lock() delay(1000) println(\"Done\") mutex.unlock() } // (1 sec) // Done // (1 sec) // Done // (1 sec) // Done // (1 sec) // Done // (1 sec) // Done Using lock and unlock directly is risky , as any exception (or premature return) in between would lead to the key never being given back (unlock never been called), and as a result, no other coroutines would be able to pass through the lock. This is a serious problem known as a deadlock (imagine a toilet that cannot be used because someone was in a hurry and forgot to give back the key). So, instead we can use the withLock function, which starts with lock but calls unlock on the finally block so that any exceptions thrown inside the block will successfully release the lock. In use, it is similar to a synchronized block. val mutex = Mutex() var counter = 0 fun main() = runBlocking { massiveRun { mutex.withLock { counter++ } } println(counter) // 1000000 } The important advantage of mutex over a synchronized block is that we suspend a coroutine instead of blocking a thread. This is a safer and lighter approach. It has one important danger : a coroutine cannot get past the lock twice (maybe the key stays in the door, so another door requiring the same key would be impossible to get past). The second problem with mutex is that it is not unlocked when a coroutine is suspended. Take a look at the code below. It takes over 5 seconds because mutex is still locked during delay. class MessagesRepository { private val messages = mutableListOf<String>() private val mutex = Mutex() suspend fun add(message: String) = mutex.withLock { delay(1000) // we simulate network call messages.add(message) } } suspend fun main() { val repo = MessagesRepository() val timeMillis = measureTimeMillis { coroutineScope { repeat(5) { launch { } } } repo.add(\"Message$it\") } println(timeMillis) // ~5120 } When we use a dispatcher that is limited to a single thread, we don\u2019t have such a problem. When a delay or a network call suspends a coroutine, the thread can be used by other coroutines. class MessagesRepository { private val messages = mutableListOf<String>() private val dispatcher = Dispatchers.IO .limitedParallelism(1) suspend fun add(message: String) = withContext(dispatcher) { delay(1000) // we simulate network call messages.add(message) } } suspend fun main() { val repo = MessagesRepository() val timeMillis = measureTimeMillis { coroutineScope { repeat(5) { launch { } } } repo.add(\"Message$it\") } println(timeMillis) // 1058 } This is why we avoid using mutex to wrap whole functions (coarsegrained approach). When we use it at all, we need to do so with great care to avoid locking twice and calling suspending functions. Semaphore Works in similar way to Mutex but can have more than one permit (lock). Regarding Mutex, we speak of a single lock, so it has functions lock , unlock and withLock So it has functions acquire , release and withPermit . suspend fun main() = coroutineScope { val semaphore = Semaphore(2) repeat(5) { launch { } } } // 01 // (1 sec) // 23 // (1 sec) // 4 Semaphore does not help us with the problem of shared state, but it can be used to limit the number of concurrent requests, so to implement rate limiting. class LimitedNetworkUserRepository( private val api: UserApi, ) { // We limit to 10 concurrent requests private val semaphore = Semaphore(10) suspend fun requestUser(userId: String) = semaphore.withPermit { api.requestUser(userId) } } Summary The most practical solution is to modify a shared state in a dispatcher that is limited to a single thread. Testing Kotlin Coroutines Testing suspending functions in most cases is not different from testing normal functions. @Test fun `should construct user`() = runBlocking {/*...*/ } Testing time dependencies The difference arises when we want to start testing time dependen- cies. For example, think of the following functions: suspend fun produceCurrentUserSeq(): User { val profile = repo.getProfile() val friends = repo.getFriends() return User(profile, friends) } suspend fun produceCurrentUserSym(): User = coroutineScope { val profile = async { repo.getProfile() } val friends = async { repo.getFriends() } User(profile.await(), friends.await()) } the difference is that the first one does it sequentially, while the second one does it simultaneously. The difference is that if fetching the profile and the friends takes 1 second each, then the first function would require around 2 seconds, whereas the first would require only 1. How would you test this? Notice that the difference arises only when execution of getProfile and getFriends truly takes some time. If they are immediate, both ways of producing the user are indistinguishable. So, we might help ourselves by delaying fake functions using delay to simulate a delayed data loading scenario: class FakeDelayedUserDataRepository : UserDataRepository { override suspend fun getProfile(): Profile { delay(1000) return Profile(\"Example description\") } override suspend fun getFriends(): List<Friend> { delay(1000) return listOf(Friend(\"some-friend-id-1\")) } } the difference will be visible in unit tests: the produceCurrentUserSeq call will take around 1 second, and the produceCurrentUserSym call will take around 2 seconds. The problem is that we do not want a single unit test to take so much time. We typically have thousands of unit tests in our projects, and we want all of them to execute as quickly as possible. How to have your cake and eat it too? For that, we need to operate in simulated time. Here comes the kotlinx-coroutines-test library to the rescue with its StandardTestDispatcher TestCoroutineScheduler and StandardTestDispatcher When we call delay, our coroutine is suspended and resumed after a set time. This behavior can be altered thanks to TestCoroutineScheduler from kotlinx-coroutines-test, which makes delay operate in virtual time, which is fully simulated and does not depend on real time. fun main() { val scheduler = TestCoroutineScheduler() println(scheduler.currentTime) // 0 scheduler.advanceTimeBy(1_000) println(scheduler.currentTime) // 1000 scheduler.advanceTimeBy(1_000) println(scheduler.currentTime) // 2000 } To use TestCoroutineScheduler on coroutines, we should use a dispatcher that supports it. The standard option is StandardTestDispatcher. Unlike most dispatchers, it is not used just to decide on which thread a coroutine should run. Coroutines started with such a dispatcher will not run until we advance virtual time. The most typical way to do this is by using advanceUntilIdle , which advances virtual time and invokes all the operations that would be called during that time if this were real time.","title":"Kotlin Coroutines Deep Dive"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#kotlin-coroutines-deep-dive","text":"","title":"Kotlin Coroutines Deep Dive"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#part-1-understanding-kotlincoroutines","text":"","title":"Part 1: Understanding KotlinCoroutines"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#why-kotlin-coroutines","text":"Threads issues: There is no mechanism here to cancel these threads, so we often face memory leaks. Making so many threads is costly. Frequently switching threads is confusing and hard to manage. The code will unnecessarily get bigger and more complicated. Callbacks: Getting data parallelized, is not so straightforward with callbacks supporting cancellation requires a lot of additional effort. The increasing number of indentations make this code hard to read (code with multiple callbacks is often considered highly unreadable). Such a situation is called \u201ccallback hell\u201d. When we use callbacks, it is hard to control when things are triggered. Rxjava/ReactiveStreams You need to learn different functions, like subscribeOn, observeOn, map, or subscribe, Cancelling needs to be explicit. Functions need to return objects wrapped inside Observable or Single classes. In practice, when we introduce RxJava, we need to reorganize our code a lot.","title":"Why Kotlin Coroutines?"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#using-kotlin-coroutines","text":"core functionality is the ability to suspend a coroutine at some point and resume it in the future. Suspended coroutine released the thread, so thread is not blocked! suspendCoroutine<Unit> {continuation -> continuation.resume(Unit} suspendCoroutine needs to be called with resume to progress, otherwise it will always be suspended. Suspending a coroutine, not a function we suspend a coroutine, not a function. Suspending functions are not coroutines, just functions that can suspend a coroutine.","title":"Using Kotlin coroutines"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#coroutines-under-the-hood","text":"suspend fun in reality is a fun with additional parameter at the end: continuation suspend fun in reality is like state machine, with a possible state at the beginning of the function and after each suspending function call. Both the number identifying the state and the local data are kept in the continuation object. continuation of a function decorates a continuation of its caller function. As a result, all these continuations represent a call stack that is used when we resume or a resumed function completes.","title":"Coroutines under the hood"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#part-2-kotlin-coroutines-library","text":"","title":"Part 2: Kotlin Coroutines library"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#coroutine-builders","text":"Suspend function can't be called from normal function, it can either be started in another suspended function or from coroutine builder - bridge from the normal to the suspending world. most common used: launch runBlocking async","title":"Coroutine builders"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#launch","text":"The way launch works is conceptually similar to starting a new thread (thread function). launch is an extension function on the CoroutineScope interface. This is part of an important mechanism called structured concurrency , whose purpose is to build a relationship between the parent coroutine and a child coroutine. To some degree, how launch works is similar to a daemon thread but much cheaper. fun main() { thread(isDaemon = true) { Thread.sleep(1000L) println(\"World!\") } thread(isDaemon = true) { Thread.sleep(1000L) println (\"World!\") } thread(isDaemon = true) { Thread.sleep(1000L) println(\"World!\") } println(\"Hello,\") Thread.sleep(2000L) } fun main() { GlobalScope.launch { delay(1000L) println(\"World!\") } GlobalScope.launch { delay(1000L) println(\"World!\") } GlobalScope.launch { delay(1000L) println(\"World!\") } println(\"Hello,\") Thread.sleep(2000L) }","title":"launch"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#runblocking-builder-currently-rarely-used","text":"runBlocking is a very atypical builder. It blocks the thread it has been started on whenever its coroutine is suspended (similar to suspending main). This means that delay(1000L) inside runBlocking will behave like Thread.sleep(1000L) : fun main() { Thread.sleep(1000L) println(\"World!\") Thread.sleep(1000L) println(\"World!\") Thread.sleep(1000L) println(\"World!\") println(\"Hello,\") } fun main() { runBlocking { delay(1000L) println(\"World!\") } runBlocking { delay(1000L) println(\"World!\") } runBlocking { delay(1000L) println(\"World!\") } println(\"Hello,\") } Use cases in which runBlocking is used: main function, where we need to block the thread, because otherwise the program will end. unit tests, where we need to block the thread for the same reason.","title":"runBlocking builder (currently rarely used)"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#async-builder","text":"Similar to launch , but produce a value. The async function returns an object of type Deferred<T> , where T is the type of the produced value. Deferred has a suspending method await, which returns this value once it is ready. Just like the launch builder, async starts a coroutine immediately when it is called. So, it is a way to start a few processes at once and then await all their results. The returned Deferred stores a value inside itself once it is produced, so once it is ready it will be immediately returned from await . However, if we call await before the value is produced, we are suspended until the value is ready. fun main() = runBlocking { val res1 = GlobalScope.async { delay(1000L) \"Text 1\" } val res2 = GlobalScope.async { delay(3000L) \"Text 2\" } val res3 = GlobalScope.async { delay(2000L) \"Text 3\" } println(res1.await()) println(res2.await()) println(res3.await()) } How the async builder works is very similar to launch , but it has additional support for returning a value. If all launch functions were replaced with async , the code would still work fine. But don\u2019t do that! async is about producing a value, so if we don\u2019t need a value, we should use launch . fun main() = runBlocking { // Don't do that! // this is misleading to use async as launch GlobalScope.async { delay(1000L) println(\"World!\") } println(\"Hello,\") delay(2000L) } The async builder is often used to parallelize two processes, such as obtaining data from two different places, to combine them together. scope.launch { val news = async { newsRepo.getNews() .sortedByDescending { it.date } } val newsSummary = newsRepo.getNewsSummary() // we could wrap it with async as well, // but it would be redundant view.showNews( newsSummary, news.await() ) }","title":"async builder"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#structured-concurrency","text":"If a coroutine is started on GlobalScope , the program will not wait for it. As previously mentioned, coroutines do not block any threads, and nothing prevents the program from ending. This is why, in the below example, an additional delay at the end of runBlocking needs to be called if we want to see \u201cWorld!\u201d printed. fun main() = runBlocking { GlobalScope.launch { delay(1000L) println(\"World!\") } GlobalScope.launch { delay(2000L) println(\"World!\") } println(\"Hello,\") // delay(3000L) } // Hello, Why do we need this GlobalScope in the first place? It is because launch and async are extension functions on CoroutineScope . However, if you take a look at the definitions of these and of runBlocking , you will see that the block parameter is a function type whose receiver type is also CoroutineScope . This means we don't need GlobalScope , instead, launch can be called on the receiver provided by runBlocking . fun main() = runBlocking { this.launch { // same as just launch delay(1000L) println(\"World!\") } launch { // same as this.launch delay(2000L) println(\"World!\") } println(\"Hello,\") }","title":"Structured Concurrency"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#parent-child-relationship","text":"A parent provides a scope for its children, and they are called in this scope. This builds a relationship that is called a structured concurrency. Here are the most important effects of the parent-child relationship: children inherit context from their parent (but they can also overwrite) a parent suspends until all the children are finished when the parent is cancelled,its child coroutines are cancelled too when a child raises an error,it destroys the parent as well Notice that, unlike other coroutine builders, runBlocking is not an extension function on CoroutineScope. This means that it cannot be a child: it can only be used as a root coroutine (the parent of all the children in a hierarchy). This means that runBlocking will be used in different cases than other coroutines. As we mentioned before, this is very different from other builders.","title":"parent-child relationship"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#coroutine-context","text":"CoroutineContext is conceptually similar to a map or a set collection. It is an indexed set of Element instances, where each Element is also a CoroutineContext . Every element in it has a unique Key that is used to identify it. This way, CoroutineContext is just a universal way to group and pass objects to coroutines. These objects are kept by the coroutines and can determine how these coroutines should be running (what their state is, in which thread, etc). Adding contexts - What makes CoroutineContext truly useful is the ability to merge two of them together. When two elements with different keys are added, the resulting context responds to both keys. fun main() { val ctx1: CoroutineContext = CoroutineName(\"Name1\") println(ctx1[CoroutineName]?.name) // Name1 println(ctx1[Job]?.isActive) // null val ctx2: CoroutineContext = Job() println(ctx2[CoroutineName]?.name) // null println(ctx2[Job]?.isActive) // true, because \"Active\" // is the default state of a job created this way val ctx3 = ctx1 + ctx2 println(ctx3[CoroutineName]?.name) // Name1 println(ctx3[Job]?.isActive) // true } When another element with the same key is added, just like in a map , the new element replaces the previous one. fun main() { val ctx1: CoroutineContext = CoroutineName(\"Name1\") println(ctx1[CoroutineName]?.name) // Name1 val ctx2: CoroutineContext = CoroutineName(\"Name2\") println(ctx2[CoroutineName]?.name) // Name2 val ctx3 = ctx1 + ctx2 println(ctx3[CoroutineName]?.name) // Name2 } Subtracting elements - Elements can also be removed from a context by their key using the minusKey function. Folding context - If we need to do something for each element in a context, we can use the fold method, which is similar to fold for other collections.","title":"Coroutine context"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#coroutine-context-and-builders","text":"So CoroutineContext is just a way to hold and pass data. By default, the parent passes its context to the child, which is one of the parent-child relationship effects. We say that the child inherits context from its parent. Since new elements always replace old ones with the same key, the child context always overrides elements with the same key from the parent context. The defaults are used only for keys that are not specified anywhere else. Currently, the defaults only set Dispatchers.Default when no ContinuationInterceptor is set, and they only set CoroutineId when the application is in debug mode. There is a special context called Job , which is mutable and is used to communicate between a coroutine\u2019s child and its parent. Accessing context in a suspending function Context is referenced by continuations, which are passed to each suspending function. So, it is possible to access a parent\u2019s context in a suspending function. To do this, we use the coroutineContext property, which is available in every suspending scope. suspend fun printName() { println(coroutineContext[CoroutineName]?.name) } suspend fun main() = withContext(CoroutineName(\"Outer\")) { printName() // Outer launch(CoroutineName(\"Inner\")) { printName() // Inner } delay(10) printName() // Outer } Creating our own context It is not a common need, but we can create our own coroutine context pretty easily. To do this, the easiest way is to create a class that implements the CoroutineContext.Element interface. Such a class needs a property key of type CoroutineContext.Key<*>. This key will be used as the key that identifies this context. The common practice is to use this class\u2019s companion object as a key. This is how a very simple coroutine context can be implemented: class MyCustomContext : CoroutineContext.Element { override val key: CoroutineContext.Key<*> = Key companion object Key : CoroutineContext.Key<MyCustomContext> }","title":"Coroutine context and builders"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#job","text":"Conceptually, a job represents a cancellable thing with a lifecycle. Formally, Job is an interface, but it has a concrete contract and state, so it might be treated similarly to an abstract class. A job lifecycle is represented by its state. Here is a graph of states and the transitions between them: In the \u201cActive\u201d state, a job is running and doing its job. If the job is created with a coroutine builder, this is the state where the body of this coroutine will be executed. In this state, we can start child coroutines. Most coroutines will start in the \u201cActive\u201d state. Only those that are started lazily will start with the \u201cNew\u201d state. These need to be started in order for them to move to the \u201cActive\u201d state. When a coroutine is executing its body, it is surely in the \u201cActive\u201d state. When it is done, its state changes to \u201cCompleting\u201d, where it waits for its children. Once all its children are done, the job changes its state to \u201cCompleted\u201d, which is a terminal one. Alternatively, if a job cancels or fails when running (in the \u201cActive\u201d or \u201cCompleting\u201d state), its state will change to \u201cCancelling\u201d. In this state, we have the last chance to do some clean-up, like closing connections or freeing resources (we will see how to do this in the next chapter). Once this is done, the job will move to the \u201cCancelled\u201d state. Every coroutine builder from the Kotlin Coroutines library creates its own job. Most coroutine builders return their jobs, so it can be used elsewhere. This is clearly visible for launch, where Job is an explicit result type. There is a very important rule: Job is the only coroutine context that is not inherited by a coroutine from a coroutine . Every coroutine creates its own Job, and the job from an argument or parent coroutine is used as a parent of this new job. The parent can reference all its children, and the children can refer to the parent. This parent-child relationship (Job reference storing) enables the implementation of cancellation and exception handling inside a coroutine\u2019s scope. Structured concurrency mechanisms will not work if a new Job context replaces the one from the parent. To see this, we might use the Job() function, which creates a Job context (this will be explained later). fun main(): Unit = runBlocking { launch(Job()) { // the new job replaces one from parent delay(1000) println(\"Will not be printed\") } } // (prints nothing, finishes immediately) In the above example, the parent does not wait for its children because it has no relation with them. This is because the child uses the job from the argument as a parent, so it has no relation to the runBlocking. When a coroutine has its own (independent) job, it has nearly no relation to its parent. It only inherits other contexts, but other results of the parent-child relationship will not apply. This causes us to lose structured concurrency, which is a problematic situation that should be avoided. The first important advantage of a job is that it can be used to wait until the coroutine is completed. For that, we use the join method. This is a suspending function that suspends until a concrete job reaches a final state (either Completed or Cancelled). fun main(): Unit = runBlocking { val job1 = launch { delay(1000) println(\"Test1\") } val job2 = launch { delay(2000) println(\"Test2\") } job1.join() job2.join() println(\"All tests are done\") } // (1 sec) // Test1 // (1 sec) // Test2 // All tests are done The Job interface also exposes a children property that lets us reference all its children. We might as well use it to wait until all children are in a final state. val children = coroutineContext[Job]?.children children?.forEach { it.join() } println(\"All tests are done\")","title":"job"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#cancellation","text":"Basic cancellation The Job interface has a cancel method, which allows its cancellation. Calling it triggers the following effects: \u2022 Such a coroutine ends the job at the first suspension point ( delay in the example below). \u2022 If a job has some children, they are also cancelled (but its parent is not affected). \u2022 Once a job is cancelled, it cannot be used as a parent for any new coroutines. It is first in the Cancelling and then in the Cancelled state. We might cancel with a different exception (by passing an exception as an argument to the cancel function) to specify the cause. This cause needs to be a subtype of CancellationException, because only an exception to this type can be used to cancel a coroutine. After cancel, we often also add join to wait for the cancellation to finish before we can proceed. Without this, we would have some race conditions. The snippet below shows an example in which without join we will see \u201cPrinting 4\u201d after \u201cCancelled successfully\u201d. suspend fun main() = coroutineScope { val job = launch { repeat(1_000) { i -> delay(100) Thread.sleep(100) // We simulate long operation println(\"Printing $i\") } } delay(1000) job.cancel() println(\"Cancelled successfully\") } // Printing 0 // Printing 1 // Printing 2 // Printing 3 // Cancelled successfully // Printing 4 Adding job.join() would change this because it suspends until a coroutine has finished cancellation (I guess currently it's in cancelling state, hence it's still able to produce values). To make it easier to call cancel and join together, the kotlinx.coroutines library offers a convenient extension function with a self-descriptive name, cancelAndJoin . Keep in mind that a cancelled coroutine is not just stopped: it is cancelled internally using an exception. Therefore, we can freely clean up everything inside the finally block. For instance, we can use a finally block to close a file or a database connection. Since most resource-closing mechanisms rely on the finally block (for instance, if we read a file using useLines), we simply do not need to worry about them.","title":"Cancellation"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#just-one-more-call","text":"Since we can catch CancellationException and invoke more operations before the coroutine truly ends, you might be wondering where the limit is. The coroutine can run as long as it needs to clean up all the resources. However, suspension is no longer allowed. The Job is already in a \u201cCancelling\u201d state, in which suspension or starting another coroutine is not possible at all. If we try to start another coroutine, it will just be ignored. If we try to suspend, it will throw CancellationException. suspend fun main(): Unit = coroutineScope { val job = Job() launch(job) { try { delay(2000) println(\"Job is done\") } finally { println(\"Finally\") launch { // will be ignored println(\"Will not be printed\") } delay(1000) // here exception is thrown println(\"Will not be printed\") } } delay(1000) job.cancelAndJoin() println(\"Cancel done\") } // (1 sec) // Finally // Cancel done Sometimes, we truly need to use a suspending call when a coroutine is already cancelled. For instance, we might need to roll back changes in a database. In this case, the preferred way is to wrap this call with the withContext( NonCancellable) function. We will later explain in detail how withContext works. For now, all we need to know is that it changes the context of a block of code. Inside withContext, we used the NonCancellable object, which is a Job that cannot be cancelled. So, inside the block the job is in the active state, and we can call whatever suspending functions we want.","title":"Just one more call"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#stopping-the-unstoppable","text":"Because cancellation happens at the suspension points, it will not happen if there is no suspension point. To simulate such a situation, we could use Thread.sleep instead of delay. This is a terrible practice, so please don\u2019t do this in any real-life projects. suspend fun main(): Unit = coroutineScope { val job = Job() launch(job) { repeat(1_000) { i -> Thread.sleep(200) // We might have some // complex operations or reading files here // without suspension println(\"Printing $i\") } } delay(1000) job.cancelAndJoin() println(\"Cancelled successfully\") delay(1000) } // Printing 0 // Printing 1 // Printing 2 // ... (up to 1000) solution to lack of suspension: using yield() - It is a good practice to use yield in suspend functions, between blocks of non-suspended CPU-intensive or time-intensive operations. launch(job) { repeat(1_000) { i -> Thread.sleep(200) yield() println(\"Printing $i\") } } check if the current job is active launch(job) { do { Thread.sleep(200) println(\"Printing\") } while (isActive) } Use ensureActive() which throws CancellationException if Job is not active launch(job) { repeat(1000) { num -> Thread.sleep(200) ensureActive() println(\"Printing $num\") } } The result of ensureActive() and yield() seem similar, but they are very different. The function ensureActive() needs to be called on a CoroutineScope (or CoroutineContext, or Job). All it does is throw an exception if the job is no longer active. It is lighter, so generally it should be preferred. The function yield is a regular top-level suspension function. It does not need any scope, so it can be used in regular suspending functions. Since it does suspension and resuming, other effects might arise, such as thread changing if we use a dispatcher with a pool of threads (more about this in the Dispatchers chapter). yield is more often used just in suspending functions that are CPU intensive or are blocking threads.","title":"Stopping the unstoppable"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#suspendcancellablecoroutine","text":"Most often we use it to cancel processes in a library or to free some resources. Here, you might remind yourself of the suspendCancellableCoroutine function introduced in the How does suspension work? chapter. It behaves like suspendCoroutine, but its continuation is wrapped into CancellableContinuation , which provides some additional methods. The most important one is invokeOnCancellation, which we use to define what should happen when a coroutine is cancelled. suspend fun someTask() = suspendCancellableCoroutine { cont -> cont.invokeOnCancellation { // do cleanup } // rest of the implementation }","title":"suspendCancellableCoroutine"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#exception-handling","text":"A very important part of how coroutines behave is their exception handling. Just as a program breaks when an uncaught exception slips by, a coroutine breaks in the case of an uncaught exception. This behavior is nothing new: for instance, threads also end in such cases. The difference is that coroutine builders also cancel their parents, and each cancelled parent cancels all its children. Let\u2019s look at the example below. Once a coroutine receives an exception, it cancels itself and propagates the exception to its parent ( launch ). The parent cancels itself and all its children, then it propagates the exception to its parent ( runBlocking ). runBlocking is a root coroutine (it has no parent), so it just ends the program ( runBlocking rethrows the exception). fun main(): Unit = runBlocking { launch { launch { delay(1000) throw Error(\"Some error\") } launch { delay(2000) println(\"Will not be printed\") } launch { delay(500) // faster than the exception println(\"Will be printed\") } } launch { delay(2000) println(\"Will not be printed\") } } // Will be printed // Exception in thread \"main\" java.lang.Error: Some error... Exception propagation is bidirectional : the exception is propagated from child to parent, and when those parents are cancelled, they cancel their children. Thus, if exception propagation is not stopped, all coroutines in the hierarchy will be cancelled.","title":"Exception handling"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#stop-breaking-my-coroutines","text":"Catching an exception before it breaks a coroutine is helpful, but any later is too late. Communication happens via a job, so wrapping a coroutine builder with a try-catch is not helpful at all. fun main(): Unit = runBlocking { // Don't wrap in a try-catch here. It will be ignored. try { launch { delay(1000) throw Error(\"Some error\") } } catch (e: Throwable) { // nope, does not help here println(\"Will not be printed\") } launch { delay(2000) println(\"Will not be printed\") } } // Exception in thread \"main\" java.lang.Error: Some error...","title":"Stop breaking my coroutines"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#supervisorjob","text":"The most important way to stop coroutines breaking is by using a SupervisorJob. This is a special kind of job that ignores all exceptions in its children. SupervisorJob is generally used as part of a scope in which we start multiple coroutines (more about this in the Constructing coroutine scope chapter). fun main(): Unit = runBlocking { val scope = CoroutineScope(SupervisorJob()) scope.launch { delay(1000) throw Error(\"Some error\") } scope.launch { delay(2000) println(\"Will be printed\") } delay(3000) } // Exception... // Will be printed A common mistake is to use a SupervisorJob as an argument to a parent coroutine, like in the code below. It won\u2019t help us handle exceptions, because in such a case SupervisorJob has only one direct child, namely the launch defined at 1 that received this SupervisorJob as an argument. So, in such a case there is no advantage of using SupervisorJob over Job (in both cases, the exception will not prop-agate to runBlocking because we are not using its job). fun main(): Unit = runBlocking { // Don't do that, SupervisorJob with one child // and no parent works similar to just Job launch(SupervisorJob()) { // 1 launch { delay(1000) throw Error(\"Some error\") } launch { delay(2000) println(\"Will not be printed\") } } delay(3000) } // Exception... It would make more sense if we used the same job as a context for multiple coroutine builders because each of them can be cancelled, but they won\u2019t cancel each other. fun main(): Unit = runBlocking { val job = SupervisorJob() launch(job) { delay(1000) throw Error(\"Some error\") } launch(job) { delay(2000) println(\"Will be printed\") } job.join() } // (1 sec) // Exception... // (1 sec) // Will be printed","title":"SupervisorJob"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#supervisorscope","text":"Another way to stop exception propagation is to wrap coroutine builders with supervisorScope. This is very convenient as we still keep a connection to the parent, yet any exceptions from the coroutine will be silenced. fun main(): Unit = runBlocking { supervisorScope { launch { delay(1000) throw Error(\"Some error\") } launch { delay(2000) println(\"Will be printed\") } } delay(1000) println(\"Done\") } // Exception... // Will be printed // (1 sec) // Done The common way to use it is to start multiple independent tasks . suspend fun notifyAnalytics(actions: List<UserAction>) = supervisorScope { actions.forEach { action -> launch { notifyAnalytics(action) } } } Beware, that supervisorScope cannot be replaced with withContext(SupervisorJob())! Take a look at the below snippet. // DON'T DO THAT! suspend fun sendNotifications( notifications: List<Notification> ) = withContext(SupervisorJob()) { for (notification in notifications) { launch { client.send(notification) } } } The problem here is that Job is the only context that is not inherited. Each coroutine needs its own job, and passing a job to a coroutine makes it a parent. So here SupervisorJob is a parent of withContext coroutine. When a child has an exception, it propagates to coroutine coroutine, cancels its Job, cancels children, and throws an exception. The fact that SupervisorJob is a parent changes nothing.","title":"supervisorScope"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#cancellationexception-does-not-propagate-to-its-parent","text":"If an exception is a subclass of CancellationException, it will not be propagated to its parent. It will only cause cancellation of the current coroutine. CancellationException is an open class, so it can be extended by our own classes or objects. object MyNonPropagatingException : CancellationException() suspend fun main(): Unit = coroutineScope { launch { // 1 launch { // 2 delay(2000) println(\"Will not be printed\") } throw MyNonPropagatingException // 3 } launch { // 4 delay(2000) println(\"Will be printed\") } } // (2 sec) // Will be printed In the above snippet, we start two coroutines with builders at 1 and 4. At 3, we throw a MyNonPropagatingException exception, which is a subtype of CancellationException. This exception is caught by launch (started at 1). This builder cancels itself, then it also cancels its children, namely the builder defined at 2. The launch started at 4 is not affected, so it prints \u201cWill be printed\u201d after 2 seconds.","title":"CancellationException does not propagate to its parent"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#coroutine-exception-handler","text":"When dealing with exceptions, sometimes it is useful to define default behavior for all of them. This is where the CoroutineExceptionHandler context comes in handy. It does not stop the exception propagating, but it can be used to define what should happen in the case of an exception (by default, it prints the exception stack trace). fun main(): Unit = runBlocking { val handler = CoroutineExceptionHandler { ctx, exception -> println(\"Caught $exception\") } val scope = CoroutineScope(SupervisorJob() + handler) scope.launch { delay(1000) throw Error(\"Some error\") } scope.launch { delay(2000) println(\"Will be printed\") } delay(3000) } // Caught java.lang.Error: Some error // Will be printed This context is useful on many platforms to add a default way of dealing with exceptions. For Android, it often informs the user about a problem by showing a dialog or an error message.","title":"Coroutine exception handler"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#coroutine-scope-functions","text":"GlobalScope is just a scope with EmptyCoroutineContext. object GlobalScope : CoroutineScope { override val coroutineContext: CoroutineContext get() = EmptyCoroutineContext } If we call async on a GlobalScope, we will have no relationship to the parent coroutine. This means that the async coroutine: cannot be cancelled(if the parent is cancelled,functions inside async still run, thus wasting resources until they are done); does not inherit a scope from any parent (it will always run on the default dispatcher and will not respect any context from the parent). The most important consequences are: potential memory leaks and redundant CPU usage; the tools for unit testing coroutines will not work here, so testing this function is very hard.","title":"Coroutine scope functions"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#coroutinescope","text":"Unlike async or launch, the body of coroutineScope is called in-place. It formally creates a new coroutine, but it suspends the previous one until the new one is finished, so it does not start any concurrent process. Take a look at the below example, in which both delay calls suspend runBlocking. fun main() = runBlocking { val a = coroutineScope { delay(1000) 10 } println(\"a is calculated\") val b = coroutineScope { delay(1000) 20 } println(a) // 10 println(b) // 20 } // (1 sec) // a is calculated // (1 sec) // 10 // 20 The provided scope inherits its coroutineContext from the outer scope, but it overrides the context\u2019s Job. Thus, the produced scope respects its parental responsibilities: inherits a context from its parent; waits for all its children before it can finish itself; cancels all its children when the parent is cancelled. In the example below, you can observe that \u201cAfter\u201d will be printed at the end because coroutineScope will not finish until all its children are finished. Also, CoroutineName is properly passed from parent to child. Coroutine builders (except for runBlocking) Coroutine scope functions launch, async, produce coroutineScope, supervisorScope, withContext, withTimeout Are extension functions on CoroutineScope. Are suspending functions. Take coroutine context from CoroutineScope receiver. Take coroutine context from suspending function continuation. Exceptions are propagated to the parent through Job. Exceptions are thrown in the same way as they are from/by regular functions. Starts an asynchronous coroutine. Starts a coroutine that is called in-place.","title":"coroutineScope"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#withcontext","text":"The withContext function is similar to coroutineScope, but it additionally allows some changes to be made to the scope. The context provided as an argument to this function overrides the context from the parent scope (the same way as in coroutine builders). This means that withContext(EmptyCoroutineContext) and coroutineScope() behave in exactly the same way it\u2019s better to use coroutineScope and withContext, and avoid async with immediate await.","title":"withContext"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#supervisorscope_1","text":"The supervisorScope function also behaves a lot like coroutineScope: it creates a CoroutineScope that inherits from the outer scope and calls the specified suspend block in it. The difference is that it overrides the context\u2019s Job with SupervisorJob, so it is not cancelled when a child raises an exception. supervisorScope is mainly used in functions that start multiple independent tasks.","title":"supervisorScope"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#withtimeout","text":"Another function that behaves a lot like coroutineScope is withTimeout. It also creates a scope and returns a value. Actually, withTimeout with a very big timeout behaves just like coroutineScope. The difference is that withTimeout additionally sets a time limit for its body execution. If it takes too long, it cancels this body and throws TimeoutCancellationException (a subtype of CancellationException). The function withTimeout is especially useful for testing. It can be used to test if some function takes more or less than some time. If it is used inside runTest, it will operate in virtual time. We also use it inside runBlocking to just limit the execution time of some function (this is then like setting timeout on @Test). class Test { @Test fun testTime2() = runTest { withTimeout(1000) { // something that should take less than 1000 delay(900) // virtual time } } @Test(expected = TimeoutCancellationException::class) fun testTime1() = runTest { withTimeout(1000) { // something that should take more than 1000 delay(1100) // virtual time } } @Test fun testTime3() = runBlocking { withTimeout(1000) { } } } Beware that withTimeout throws TimeoutCancellationException, which is a subtype of CancellationException (the same exception that is thrown when a coroutine is cancelled). So, when this exception is thrown in a coroutine builder, it only cancels it and does not affect its parent (as explained in the previous chapter).","title":"withTimeout"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#additional-operations","text":"Imagine a case in which in the middle of some processing you need to execute an additional operation. For example, after showing a user profile you want to send a request for analytics purposes. People often do this with just a regular launch in the same scope: However, there are some problems with this approach. Firstly, this launch does nothing here because coroutineScope needs to await its completion anyway. So if you are showing a progress bar when updating the view, the user needs to wait until this notifyProfileShown is finished as well. This does not make much sense. The second problem is cancellation. Coroutines are designed (by default) to cancel other operations when there is an exception. This is great for essential operations. If getProfile has an exception, we should cancel getName and getFriends because their response would be useless anyway. However, canceling a process just because an analytics call has failed does not make much sense. So what should we do? When you have an additional (non-essential) operation that should not influence the main process, it is better to start it on a separate scope. Creating your own scope is easy. In this example, we create an analyticsScope. val analyticsScope = CoroutineScope(SupervisorJob()) For unit testing and controlling this scope, it is better to inject it via a constructor.","title":"Additional operations"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#dispatchers","text":"In the English dictionary, a dispatcher is defined as \u201ca person who is responsible for sending people or vehicles to where they are needed, especially emergency vehicles\u201d. In Kotlin coroutines, CoroutineContext determines on which thread a certain coroutine will run.","title":"Dispatchers"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#default-dispatcher","text":"If you don\u2019t set any dispatcher, the one chosen by default is Dispatchers.Default, which is designed to run CPU-intensive operations. It has a pool of threads with a size equal to the number of cores in the machine your code is running on (but not less than two) . At least theoretically, this is the optimal number of threads, assuming you are using these threads efficiently, i.e., performing CPU-intensive calculations and not blocking them.","title":"Default dispatcher"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#io-dispatcher","text":"or instance, if you need to perform long I/O operations (e.g., read big files) or if you need to use a library with blocking functions. You cannot block the Main thread, because your application would freeze. If you block your default dispatcher, you risk blocking all the threads in the thread pool, in which case you wouldn't be able to do any calculations. This is why we need a dispatcher for such a situation, and it is Dispatchers.IO. Dispatchers.IO is designed to be used when we block threads with I/O operations, for instance, when we read/write files, use Android shared preferences, or call blocking functions. The code below takes around 1 second because Dispatchers.IO allows more than 50 active threads at the same time. suspend fun main() { val time = measureTimeMillis { coroutineScope { repeat(50) { launch(Dispatchers.IO) { Thread.sleep(1000) } } println(time) // ~1000 } } } How does it work? Imagine an unlimited pool of threads. Initially, it is empty, but as we need more threads, they are created and kept active until they are not used for some time. Such a pool exists, but it wouldn't be safe to use it directly. With too many active threads, the performance degrades in a slow but unlimited manner, eventually causing out-of-memory errors. This is why we create dispatchers that have a limited number of threads they can use at the same time. Dispatchers.Default is limited by the number of cores in your processor. The limit of Dispatchers.IO is 64 (or the number of cores if there are more). As we mentioned, both Dispatchers.Default and Dispatchers.IO share the same pool of threads. This is an important optimization. Threads are reused, and often redispatching is not needed. For instance, let\u2019s say you are running on Dispatchers.Default and then execution reaches withContext(Dispatchers.IO) { ... }. Most often, you will stay on the same thread33, but what changes is that this thread counts not towards the Dispatchers.Default limit but towards the Dispatchers.IO limit. Their limits are independent, so they will never starve each other.","title":"IO dispatcher"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#io-dispatcher-with-a-custom-pool-of-threads","text":"Dispatchers.IO has a special behavior defined for the limitedParallelism function. It creates a new dispatcher with an independent pool of threads. What is more, this pool is not limited to 64 as we can decide to limit it to as many threads as we want. For example, imagine you start 100 coroutines, each of which blocks a thread for a second. If you run these coroutines on Dispatchers.IO, it will take 2 seconds. If you run them on Dispatchers.IO with limitedParallelism set to 100 threads, it will take 1 second. Execution time for both dispatchers can be measured at the same time because the limits of these two dispatchers are independent anyway.","title":"IO dispatcher with a custom pool of threads"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#sharing-a-state","text":"For all dispatchers using multiple threads, we need to consider the shared state problem. Notice that in the example below 10,000 coroutines are increasing i by 1. So, its value should be 10,000, but it is a smaller number. This is a result of a shared state (i property) modification on multiple threads at the same time. var i = 0 suspend fun main(): Unit = coroutineScope { repeat(10_000) { launch(Dispatchers.IO) { // or Default i++ } } delay(1000) println(i) // ~9930 } There are many ways to solve this problem, but one option is to use a dispatcher with just a single thread. If we use just a single thread at a time, we do not need any other synchronization. var i = 0 suspend fun main(): Unit = coroutineScope { val dispatcher = Dispatchers.Default .limitedParallelism(1) repeat(10000) { launch(dispatcher) { i++ } } delay(1000) println(i) // 10000 } The biggest disadvantage is that because we have only one thread, our calls will be handled sequentially if we block it.","title":"Sharing a state"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#using-virtual-threads-from-project-loom","text":"JVM platform introduced a new technology known as Project Loom. Its biggest innovation is the introduction of virtual threads, which are much lighter than regular threads. It costs much less to have blocked virtual threads than to have a regular thread blocked. At the moment, Project Loom is still young, and it is hard actually to use it, but I must say it is an exciting substitution for Dispatchers.IO. However, you will likely not need it in the future, as the Kotlin Coroutines team expresses their willingness to use virtual threads by default once Project Loom gets stable. I hope it will happen soon.","title":"Using virtual threads from Project Loom"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#unconfined-dispatcher","text":"The last dispatcher we need to discuss is Dispatchers.Unconfined. This dispatcher is different from the previous one as it does not change any threads. When it is started, it runs on the thread on which it was started. If it is resumed, it runs on the thread that resumed it. This is sometimes useful for unit testing. Imagine that you need to test a function that calls launch. Synchronizing the time might not be easy. One solution is to use Dispatchers.Unconfined instead of all other dispatchers. If it is used in all scopes, everything runs on the same thread, and we can more easily control the order of operations. This trick is not needed if we use runTest from kotlinx-coroutines-test. We will discuss this later in the book. From the performance point of view, this dispatcher is the cheapest as it never requires thread switching. So, we might choose it if we do not care at all on which thread our code is running. However, in practice, it is not considered good to use it so recklessly. What if, by accident, we miss a blocking call, and we are running on the Main thread? This could lead to blocking the entire application.","title":"Unconfined dispatcher"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#performance-of-dispatchers-against-different-tasks","text":"There are a few important observations you can make: When we are just suspending, it doesn\u2019t really matter how many threads we are using. When we are blocking, the more threads we are using, the faster all these coroutines will be finished. With CPU-intensive operations, Dispatchers.Default is the best option. If we are dealing with a memory-intensive problem, more threads might provide some (but not a significant) improvement.","title":"Performance of dispatchers against different tasks"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#summary-of-dispatchers","text":"Dispatchers determine on which thread or thread pool a coroutine will be running (starting and resuming). The most important options are: \u2022 Dispatchers.Default, which we use for CPU-intensive operations; \u2022 Dispatchers.Main, which we use to access the Main thread on Android, Swing, or JavaFX; \u2022 Dispatchers.Main.immediate, which runs on the same thread as Dispatchers.Main but is not re-dispatched if it is not necessary; \u2022 Dispatchers.IO, which we use when we need to do some blocking operations; \u2022 Dispatchers.IO with limited parallelism or a custom dispatcher with a pool of threads, which we use when we might have a big number of blocking calls; \u2022 Dispatchers.Default or Dispatchers.IO with parallelism limited to 1, or a custom dispatcher with a single thread, which is used when we need to secure shared state modifications; \u2022 Dispatchers.Unconfined, which we use when we do not care where the coroutine will be executed.","title":"Summary of dispatchers"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#constructing-a-coroutine-scope","text":"CoroutineScope is an interface with a single property coroutineContext. interface CoroutineScope { val coroutineContext: CoroutineContext } Therefore, we can make a class implement this interface and just directly call coroutine builders in it. class SomeClass : CoroutineScope { override val coroutineContext: CoroutineContext = Job() fun onStart() { launch { // ... } } } However, this approach is not very popular. On one hand, it is convenient; on the other, it is problematic that in such a class we can directly call other CoroutineScope methods like cancel or ensureActive. Even accidentally, someone might cancel the whole scope, and coroutines will not start anymore. Instead, we generally prefer to hold a coroutine scope as an object in a property and use it to call coroutine builders.","title":"Constructing a coroutine scope"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#constructing-a-scope-on-android","text":"This is how proper implementation can look like: abstract class BaseViewModel( private val onError: (Throwable) -> Unit ) : ViewModel() { private val exceptionHandler = CoroutineExceptionHandler { _, throwable -> onError(throwable) } private val context = Dispatchers.Main + SupervisorJob() + exceptionHandler protected val scope = CoroutineScope(context) override fun onCleared() { context.cancelChildren() } }","title":"Constructing a scope on Android"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#viewmodelscope-and-lifecyclescope","text":"In modern your(needs version 2.2.0 or higher) or lifecycleScope (needs androidx.lifecycle:lifecycle-runtime-ktx version 2.2.0 or higher). How they work is nearly identical to what we\u2019ve just constructed: they use Dispatchers.Main and SupervisorJob, and they cancel the job when the view model or lifecycle owner gets destroyed. Using viewModelScope and lifecycleScope is convenient and recommended if we do not need any special context as a part of our scope (like CoroutineExceptionHandler). This is why this approach is chosen by many (maybe most) Android applications.","title":"viewModelScope and lifecycleScope"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#constructing-a-scope-for-additional-calls","text":"As explained in the Additional operations section of the Coroutine scope functions chapter, we often make scopes for starting additional operations. These scopes are then typically injected via arguments to functions or the constructor. If we only plan to use these scopes to suspend calls, it is enough if they just have a SupervisorScope. val analyticsScope = CoroutineScope(SupervisorJob())","title":"Constructing a scope for additional calls"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#the-problem-with-shared-state","text":"given: class UserDownloader( private val api: NetworkService ) { private val users = mutableListOf<User>() fun downloaded(): List<User> = users.toList() suspend fun fetchUser(id: Int) { val newUser = api.fetchUser(id) users.add(newUser) } } Since it can be started on more than one thread at the same time, we say users is a shared state , therefore it needs to be secured. This is because concurrent modifications can lead to conflicts. Users will be added at the same time by different threads which will cause that some of them won't be saved. More on this in Multithreading To solve above we can try below solutions:","title":"The problem with shared state"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#blocking-synchronization","text":"Issues: inside synchronized block you cannot use suspending functions. this is blocking threads when a coroutine is waiting for its turn","title":"Blocking synchronization"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#atomicvalue","text":"private var counter = AtomicInteger() fun main() = runBlocking { massiveRun { counter.incrementAndGet() } println(counter.get()) // 1000000 } It works perfectly here, but the utility of atomic values is generally very limited, therefore we need to be careful: just knowing a single operation will be atomic does not help us when we have a bundle of operations. private var counter = AtomicInteger() fun main() = runBlocking { massiveRun { counter.set(counter.get() + 1) } println(counter.get()) // ~430467 } To secure our UserDownloader , we could use the AtomicReference wrapping around the read-only list of users. We can use the getAndUpdate atomic function to update its value without conflicts. class UserDownloader( private val api: NetworkService ) { private val users = AtomicReference(listOf<User>()) fun downloaded(): List<User> = users.get() suspend fun fetchUser(id: Int) { val newUser = api.fetchUser(id) users.getAndUpdate { it + newUser } } }","title":"AtomicValue"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#a-dispatcher-limited-to-a-single-thread","text":"We saw a dispatcher with parallelism limited to a single thread in the Dispatchers chapter. This is the easiest solution for most problems with shared states. val dispatcher = Dispatchers.IO.limitedParallelism(1) var counter = 0 fun main() = runBlocking { massiveRun { withContext(dispatcher) { counter++ } } println(counter) // 1000000 } In practice, this approach can be used in two ways: coarse-grained thread confinement we just wrap the whole function with withContext , with a dispatcher limited to a single thread. Single thread for doing a whole job. This approach is known as coarse-grained thread confinement. fine-grained thread confinement we wrap only those statements which modify the state. This approach is more demanding, but it offers us better performance","title":"A dispatcher limited to a single thread"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#mutex","text":"The last popular approach is to use a Mutex . You can imagine it as a room with a single key (or maybe a toilet at a cafeteria). Its most important function is lock. When the first coroutine calls it, it kind of takes the key and passes through lock without suspension. If another coroutine then calls lock, it will be suspended until the first coroutine calls unlock (like a person waiting for a key to the toilet). suspend fun main() = coroutineScope { repeat(5) { launch { delayAndPrint() } } } val mutex = Mutex() suspend fun delayAndPrint() { mutex.lock() delay(1000) println(\"Done\") mutex.unlock() } // (1 sec) // Done // (1 sec) // Done // (1 sec) // Done // (1 sec) // Done // (1 sec) // Done Using lock and unlock directly is risky , as any exception (or premature return) in between would lead to the key never being given back (unlock never been called), and as a result, no other coroutines would be able to pass through the lock. This is a serious problem known as a deadlock (imagine a toilet that cannot be used because someone was in a hurry and forgot to give back the key). So, instead we can use the withLock function, which starts with lock but calls unlock on the finally block so that any exceptions thrown inside the block will successfully release the lock. In use, it is similar to a synchronized block. val mutex = Mutex() var counter = 0 fun main() = runBlocking { massiveRun { mutex.withLock { counter++ } } println(counter) // 1000000 } The important advantage of mutex over a synchronized block is that we suspend a coroutine instead of blocking a thread. This is a safer and lighter approach. It has one important danger : a coroutine cannot get past the lock twice (maybe the key stays in the door, so another door requiring the same key would be impossible to get past). The second problem with mutex is that it is not unlocked when a coroutine is suspended. Take a look at the code below. It takes over 5 seconds because mutex is still locked during delay. class MessagesRepository { private val messages = mutableListOf<String>() private val mutex = Mutex() suspend fun add(message: String) = mutex.withLock { delay(1000) // we simulate network call messages.add(message) } } suspend fun main() { val repo = MessagesRepository() val timeMillis = measureTimeMillis { coroutineScope { repeat(5) { launch { } } } repo.add(\"Message$it\") } println(timeMillis) // ~5120 } When we use a dispatcher that is limited to a single thread, we don\u2019t have such a problem. When a delay or a network call suspends a coroutine, the thread can be used by other coroutines. class MessagesRepository { private val messages = mutableListOf<String>() private val dispatcher = Dispatchers.IO .limitedParallelism(1) suspend fun add(message: String) = withContext(dispatcher) { delay(1000) // we simulate network call messages.add(message) } } suspend fun main() { val repo = MessagesRepository() val timeMillis = measureTimeMillis { coroutineScope { repeat(5) { launch { } } } repo.add(\"Message$it\") } println(timeMillis) // 1058 } This is why we avoid using mutex to wrap whole functions (coarsegrained approach). When we use it at all, we need to do so with great care to avoid locking twice and calling suspending functions.","title":"Mutex"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#semaphore","text":"Works in similar way to Mutex but can have more than one permit (lock). Regarding Mutex, we speak of a single lock, so it has functions lock , unlock and withLock So it has functions acquire , release and withPermit . suspend fun main() = coroutineScope { val semaphore = Semaphore(2) repeat(5) { launch { } } } // 01 // (1 sec) // 23 // (1 sec) // 4 Semaphore does not help us with the problem of shared state, but it can be used to limit the number of concurrent requests, so to implement rate limiting. class LimitedNetworkUserRepository( private val api: UserApi, ) { // We limit to 10 concurrent requests private val semaphore = Semaphore(10) suspend fun requestUser(userId: String) = semaphore.withPermit { api.requestUser(userId) } }","title":"Semaphore"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#summary","text":"The most practical solution is to modify a shared state in a dispatcher that is limited to a single thread.","title":"Summary"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#testing-kotlin-coroutines","text":"Testing suspending functions in most cases is not different from testing normal functions. @Test fun `should construct user`() = runBlocking {/*...*/ }","title":"Testing Kotlin Coroutines"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#testing-time-dependencies","text":"The difference arises when we want to start testing time dependen- cies. For example, think of the following functions: suspend fun produceCurrentUserSeq(): User { val profile = repo.getProfile() val friends = repo.getFriends() return User(profile, friends) } suspend fun produceCurrentUserSym(): User = coroutineScope { val profile = async { repo.getProfile() } val friends = async { repo.getFriends() } User(profile.await(), friends.await()) } the difference is that the first one does it sequentially, while the second one does it simultaneously. The difference is that if fetching the profile and the friends takes 1 second each, then the first function would require around 2 seconds, whereas the first would require only 1. How would you test this? Notice that the difference arises only when execution of getProfile and getFriends truly takes some time. If they are immediate, both ways of producing the user are indistinguishable. So, we might help ourselves by delaying fake functions using delay to simulate a delayed data loading scenario: class FakeDelayedUserDataRepository : UserDataRepository { override suspend fun getProfile(): Profile { delay(1000) return Profile(\"Example description\") } override suspend fun getFriends(): List<Friend> { delay(1000) return listOf(Friend(\"some-friend-id-1\")) } } the difference will be visible in unit tests: the produceCurrentUserSeq call will take around 1 second, and the produceCurrentUserSym call will take around 2 seconds. The problem is that we do not want a single unit test to take so much time. We typically have thousands of unit tests in our projects, and we want all of them to execute as quickly as possible. How to have your cake and eat it too? For that, we need to operate in simulated time. Here comes the kotlinx-coroutines-test library to the rescue with its StandardTestDispatcher","title":"Testing time dependencies"},{"location":"books/kotlin_coroutines/kotlin_coroutines/#testcoroutinescheduler-and-standardtestdispatcher","text":"When we call delay, our coroutine is suspended and resumed after a set time. This behavior can be altered thanks to TestCoroutineScheduler from kotlinx-coroutines-test, which makes delay operate in virtual time, which is fully simulated and does not depend on real time. fun main() { val scheduler = TestCoroutineScheduler() println(scheduler.currentTime) // 0 scheduler.advanceTimeBy(1_000) println(scheduler.currentTime) // 1000 scheduler.advanceTimeBy(1_000) println(scheduler.currentTime) // 2000 } To use TestCoroutineScheduler on coroutines, we should use a dispatcher that supports it. The standard option is StandardTestDispatcher. Unlike most dispatchers, it is not used just to decide on which thread a coroutine should run. Coroutines started with such a dispatcher will not run until we advance virtual time. The most typical way to do this is by using advanceUntilIdle , which advances virtual time and invokes all the operations that would be called during that time if this were real time.","title":"TestCoroutineScheduler and StandardTestDispatcher"},{"location":"hobbies/pool/","text":"Pool improving your game proper posture everything needs to be inline, keep the proper distance from the cue ball (enough space for aiming and continuation with cue) bridge hand (we should adjust the bridge height based on where we plan to hit the cue ball) grip should be relaxed ** always look at the ghost ball when hitting the cue ball** throw effect when aiming with cut angle you need to adjust for the thrown angle cause by spin always follow through with cue do not rush with decision ** everytime you change decision (or adjust) stand up** stay still after the shot ** how to break** make sure that rack is tight use cushion to form bridge aim bellow the middle the cue ball as the force will likely move the cue higher ** positional play ** think about which areas for the cue ball will allow you to continue according to your plan. 1 solution how to approach the order is to reverse the trace. \"which position is the easiest to put the black ball?\" then find the ball that will allows you to be in that spot after the ball will be putted. repeat for all balls.","title":"Pool"},{"location":"hobbies/pool/#pool","text":"","title":"Pool"},{"location":"hobbies/pool/#improving-your-game","text":"proper posture everything needs to be inline, keep the proper distance from the cue ball (enough space for aiming and continuation with cue) bridge hand (we should adjust the bridge height based on where we plan to hit the cue ball) grip should be relaxed ** always look at the ghost ball when hitting the cue ball** throw effect when aiming with cut angle you need to adjust for the thrown angle cause by spin always follow through with cue do not rush with decision ** everytime you change decision (or adjust) stand up** stay still after the shot ** how to break** make sure that rack is tight use cushion to form bridge aim bellow the middle the cue ball as the force will likely move the cue higher ** positional play ** think about which areas for the cue ball will allow you to continue according to your plan. 1 solution how to approach the order is to reverse the trace. \"which position is the easiest to put the black ball?\" then find the ball that will allows you to be in that spot after the ball will be putted. repeat for all balls.","title":"improving your game"},{"location":"hobbies/tennis/","text":"Grip Forehand put the racket on the ground, and pick it up - done position - (around) 45 degree to baseline when finished stroke - then right elbow is pointing to the other side (of the net) Backhand pick the racket vertical to the ground (90 degree from Forehand) - continental grip when finished stroke - left elbow is pointing to the other side (of the net) and you need to rotate with the shoot Switching Grip switching grip should be done from the beginning (otherwise your learning wrong/harder/more prone to the injures way) Serving continental grip position - perpendicularly to the court ball in hand with palms facing sky trophy position Ball thrown little upfront Volley don't do windshield wipers don't use forehand grip, use continental grip don't swing (freeze the racket), just let the ball bounce Overhead similarly to serving, side stand - not facing the net Rally sequence of back and forth shots between players, within a point. A rally starts with the serve and the return of the serve, followed by continuous return shots until a point is scored which ends the rally. Field baseline - line from which you are serving service line - line that form square with net","title":"Grip"},{"location":"hobbies/tennis/#grip","text":"","title":"Grip"},{"location":"hobbies/tennis/#forehand","text":"put the racket on the ground, and pick it up - done position - (around) 45 degree to baseline when finished stroke - then right elbow is pointing to the other side (of the net)","title":"Forehand"},{"location":"hobbies/tennis/#backhand","text":"pick the racket vertical to the ground (90 degree from Forehand) - continental grip when finished stroke - left elbow is pointing to the other side (of the net) and you need to rotate with the shoot","title":"Backhand"},{"location":"hobbies/tennis/#switching-grip","text":"switching grip should be done from the beginning (otherwise your learning wrong/harder/more prone to the injures way)","title":"Switching Grip"},{"location":"hobbies/tennis/#serving","text":"continental grip position - perpendicularly to the court ball in hand with palms facing sky trophy position Ball thrown little upfront","title":"Serving"},{"location":"hobbies/tennis/#volley","text":"don't do windshield wipers don't use forehand grip, use continental grip don't swing (freeze the racket), just let the ball bounce","title":"Volley"},{"location":"hobbies/tennis/#overhead","text":"similarly to serving, side stand - not facing the net","title":"Overhead"},{"location":"hobbies/tennis/#rally","text":"sequence of back and forth shots between players, within a point. A rally starts with the serve and the return of the serve, followed by continuous return shots until a point is scored which ends the rally.","title":"Rally"},{"location":"hobbies/tennis/#field","text":"baseline - line from which you are serving service line - line that form square with net","title":"Field"},{"location":"programming/architecture/","text":"Architecture Interface and Classes that implements it: It's better to have FoodFactoryImplementation, then calling interface: FoodFactoryInterface(IFoodFactory etc.) When constructors are overloaded, use static factory methods with names that describe the arguments Don't use unnecessary information, if object is inside some module (SM), it does not require to call object SMFishCatalog Functions should hardly ever be 20 lines long We should avoid switch as they violate the Single Responsibility Principle and Open Closed Principle Don't pass boolean as argument to function if functions has more then 2 arguments probably it should have its own class real goal of programmer is to tell the story of the system Class structure should look like well written article From Headline to details Class should expose \"essence\" of the data without showing implementation -> use interfaces for communications Objects hide their data behind abstractions and expose functions that operate on that data Data classes shouldn't have any meaningful functions Data structure expose their data and have no meaningful functions. //////////////// banners like that should be used hardly ever, otherwise it will be just noise The Law of Demeter -> function talk only to friends empty objects over null Do Don't java Complex fulcrumPoint = Complex . FromRealNumber ( 23.0 ); java Complex fulcrumPoint = new Complex ( 23.0 ); Flow should be used for communication between Repo and ViewModel","title":"Architecture"},{"location":"programming/architecture/#architecture","text":"Interface and Classes that implements it: It's better to have FoodFactoryImplementation, then calling interface: FoodFactoryInterface(IFoodFactory etc.) When constructors are overloaded, use static factory methods with names that describe the arguments Don't use unnecessary information, if object is inside some module (SM), it does not require to call object SMFishCatalog Functions should hardly ever be 20 lines long We should avoid switch as they violate the Single Responsibility Principle and Open Closed Principle Don't pass boolean as argument to function if functions has more then 2 arguments probably it should have its own class real goal of programmer is to tell the story of the system Class structure should look like well written article From Headline to details Class should expose \"essence\" of the data without showing implementation -> use interfaces for communications Objects hide their data behind abstractions and expose functions that operate on that data Data classes shouldn't have any meaningful functions Data structure expose their data and have no meaningful functions. //////////////// banners like that should be used hardly ever, otherwise it will be just noise The Law of Demeter -> function talk only to friends empty objects over null Do Don't java Complex fulcrumPoint = Complex . FromRealNumber ( 23.0 ); java Complex fulcrumPoint = new Complex ( 23.0 ); Flow should be used for communication between Repo and ViewModel","title":"Architecture"},{"location":"programming/ascii/","text":"ASCII Converting uppercase to lowercase and so on is based on ASCII numbers and substracting the difference in position: a - A (97-65)","title":"ASCII"},{"location":"programming/ascii/#ascii","text":"Converting uppercase to lowercase and so on is based on ASCII numbers and substracting the difference in position: a - A (97-65)","title":"ASCII"},{"location":"programming/c/","text":"C w C array zawsze ma \"\\0\" null byte, dzieki temu mozna iterowac elementy by dowiedziec sie jaka jest dlugosc Main return 0 by default -> everything went OK, other values signals errors // &n - get address of variable n in memory int *p = &n // *p - variable p is pointing to memory that is of a type int printf(\"%i\", *p) - print argument int -> *p = \"get value from this pointer\"","title":"C"},{"location":"programming/c/#c","text":"w C array zawsze ma \"\\0\" null byte, dzieki temu mozna iterowac elementy by dowiedziec sie jaka jest dlugosc Main return 0 by default -> everything went OK, other values signals errors // &n - get address of variable n in memory int *p = &n // *p - variable p is pointing to memory that is of a type int printf(\"%i\", *p) - print argument int -> *p = \"get value from this pointer\"","title":"C"},{"location":"programming/markdown/","text":"Markdown Generating a table https://www.tablesgenerator.com/markdown_tables Mermaid graphs https://mermaid-js.github.io/mermaid/#/flowchart","title":"Markdown"},{"location":"programming/markdown/#markdown","text":"","title":"Markdown"},{"location":"programming/markdown/#generating-a-table","text":"https://www.tablesgenerator.com/markdown_tables","title":"Generating a table"},{"location":"programming/markdown/#mermaid-graphs","text":"https://mermaid-js.github.io/mermaid/#/flowchart","title":"Mermaid graphs"},{"location":"programming/mkdocs/","text":"MKDocs For full documentation visit mkdocs.org . Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"MKDocs"},{"location":"programming/mkdocs/#mkdocs","text":"For full documentation visit mkdocs.org .","title":"MKDocs"},{"location":"programming/mkdocs/#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"programming/mkdocs/#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"programming/notes/","text":"Notes Let's assume we have a class A which is responsible for sorting orders. Class A has dependency on class B which is used in some stage on sorting algorithm. We want to UniTest A class. the structure looks something like this. val orders = listOf () val b = B() val a = A(b) a.sortOrders(orders) fun sortOrders(orders: List ) : List { val doneOrders = order.filter { order -> b.isDone(order) return doneOrders.sortByDate() } what is the proper approach to unit tests in the above case? Should I mock the B class, if so, having a list of orders how can I assure that b.isDone() returns true for correct orders? Do I need to specify the response for each order e.g.? every {b.isDone(order1)} return true every {b.isDone(order2)} return false and so on for n orders?","title":"Notes"},{"location":"programming/notes/#notes","text":"Let's assume we have a class A which is responsible for sorting orders. Class A has dependency on class B which is used in some stage on sorting algorithm. We want to UniTest A class. the structure looks something like this. val orders = listOf () val b = B() val a = A(b) a.sortOrders(orders) fun sortOrders(orders: List ) : List { val doneOrders = order.filter { order -> b.isDone(order) return doneOrders.sortByDate() } what is the proper approach to unit tests in the above case? Should I mock the B class, if so, having a list of orders how can I assure that b.isDone() returns true for correct orders? Do I need to specify the response for each order e.g.? every {b.isDone(order1)} return true every {b.isDone(order2)} return false and so on for n orders?","title":"Notes"},{"location":"programming/solid/","text":"SOLID principles Single Responsibility Principal each entity should have on reason to change how to approach: Take features that you want to provide e.g. display a list of cats with images Imagine that all code is in single File Think about what would happen if business would require change: support list of dogs as well support different format (e.g. GIF) support caching adding to favorites (and displaying favorite animals) search by type adding your own picture of cat If more than 1 of required changes is probable then the entity would break SRP Therefore, functionalities should be extracted to separate entities. It's worth extracting the code even if we don't expect any changes but expect re-usage of code in different entity. Open-Close Principal Entity should be open for extension and close for modification We can achieve it by providing proper abstraction, therefore practical definition is: \"Open-Close Principal depends on stable abstraction and modifies system's behaviour by providing different realizations\" Take a feature that you want to add. e.g. display a list of dogs and cats with images Think what is going to happen to entity if you would like to display new types of animals If adding new type requires modifying entity for proper handling all animals: e.g. dogs, cats, bats, rats it breaks the OCP The proper way of handling: creating proper abstraction that will be used inside entity like animal which will be extended by all subtypes. Each implementation of \"animal\" is going to provide proper functionality on its own To check: \"strategy\" design patter, \"abstract factory\" pattern. Liskov Substitution Principle Subtype to be named as a real subtype of a type, needs to fulfill certain rules. Method Signature rules Those rules don't apply for statically type languages as they are force by compiler by default Contravariant of arguments same number of arguments on subtype side argument passed can be only type or supertype of type in parent. classDiagram direction LR Service <|-- SubService Service: +doSomething(DoType type) class SubService{ +doSomething(DoSyperType type) } Zebra is passing an Number to Animal, and it must work the same as in Parent the Int Covariance of result either both type and subtype returns the result or neither does If there is as a result then result in subtype is type or subtype in Parent classDiagram direction LR Service <|-- SubService Service: +getSomething() Something class SubService{ +getSomething() SubSomething } Exception Rule Subtype should throw only same Exception and its sub Exception s that are handed by superclass Method Pre-condition and Post-condition rule Precondition Rule - subclass should be able to operate in all states that a superclass can. e.g. handling nullability classDiagram direction LR Service <|-- SubService Service: +setLucyNumber(@Nullable Integer luckyNumber) class SubService{ +setLucyNumber(@Nullable Integer luckyNumber) } Post condition Rule - Subclass can't have a weaker \"states\" than type e.g. returning null in below case classDiagram direction LR Service <|-- SubService Service: +getSomething() Something class SubService{ + @Nullable getSomething() Something } Class Property Rule Invariant rule - invariants guaranteed by a subclass must include all invariants guaranteed by a superclass e.g. the capacity of \"DuplicatedQueue\" that duplicates whatever is there has to have the same maxCapacity as superType. classDiagram direction LR Service <|-- SubService Service: Int maxCapacity = 32 class SubService{ Int maxCapacity = 32 } Constraint rule - constraints in superclass must be included in subtype invariant is same for all instances of a calls while constraints are per instance. e.g. max capacity for queue is constraint as long as is se in constructor. If it's fixed and not set then it's invariant. Interface Segregation Principle It's principle of the least knowledge and information hiding. Restricts what client can do with their services. Clients should not be forced to implement interfaces they don't use. Instead, those interfaces should be split into smaller, more specific interfaces. This makes the system more flexible, maintainable, and extensible. Instead of having an interface with different methods (hence functionalities) in one Big Interface it's better to have couple smaller per feature. example to illustrate this principle: Suppose we are building a system for managing a library. The system has an interface called LibraryItem that defines methods for checking out and returning books, as well as methods for checking out and returning movies. However, not all clients need to use all of these methods. For example, a client that only deals with books may not need the methods for checking out and returning movies. Without following the Interface Segregation Principle, the client would be forced to implement all of the methods in the LibraryItem interface, even if they don't use some of them. This would make the system inflexible and difficult to maintain. Instead, we can follow the Interface Segregation Principle and split the LibraryItem interface into two smaller, more specific interfaces: Book and Movie. This allows clients to implement only the methods they need, and makes the system more flexible and maintainable. pros: explicit and clear dependencies between client and service -> client knows what feature it's really needs and is restricted of using different ones. readability - no empty methods -> if not used. e.g. TextChangeLister from Android SDK is breaking ISP because it provides more methods than often required. easier to find clients that are using specific functionality -> e.g. when you're looking for a bug Safe and easy to add new messages - you don't need to change xx clients when new feature/ method is added (yes/no because without using the interface at all it would give same result, but it's not what we want) Dependency Inversion Principle High level module should not depend on low level module. Both should depend on abstraction and abstraction should not depend on details. Details should depend on abstraction. Benefits: usability flexible maintainable breaking dependency on external modules Here is an example to illustrate this principle: Suppose we are building a system for managing a shopping cart. The system has two modules: a low-level module for storing the items in the cart, and a high-level module for calculating the total price of the items in the cart. Without following the Dependency Inversion Principle, the high-level module would directly depend on the low-level module. This would make the system inflexible, because if we wanted to change the way the items are stored (for example, switching from a database to a file system), we would have to change the high-level module as well. Instead, we can follow the Dependency Inversion Principle and create an abstraction for the storage of the items. This could be an interface that defines a method for storing and retrieving items. Both the low-level and high-level modules would depend on this abstraction, rather than depending on each other directly. This decouples the modules from one another and makes the system more flexible. If we want to change the way the items are stored, we can simply implement the storage interface in a different way, without having to change the high-level module. This makes the system easier to maintain and extend.","title":"SOLID principles"},{"location":"programming/solid/#solid-principles","text":"","title":"SOLID principles"},{"location":"programming/solid/#single-responsibility-principal","text":"each entity should have on reason to change how to approach: Take features that you want to provide e.g. display a list of cats with images Imagine that all code is in single File Think about what would happen if business would require change: support list of dogs as well support different format (e.g. GIF) support caching adding to favorites (and displaying favorite animals) search by type adding your own picture of cat If more than 1 of required changes is probable then the entity would break SRP Therefore, functionalities should be extracted to separate entities. It's worth extracting the code even if we don't expect any changes but expect re-usage of code in different entity.","title":"Single Responsibility Principal"},{"location":"programming/solid/#open-close-principal","text":"Entity should be open for extension and close for modification We can achieve it by providing proper abstraction, therefore practical definition is: \"Open-Close Principal depends on stable abstraction and modifies system's behaviour by providing different realizations\" Take a feature that you want to add. e.g. display a list of dogs and cats with images Think what is going to happen to entity if you would like to display new types of animals If adding new type requires modifying entity for proper handling all animals: e.g. dogs, cats, bats, rats it breaks the OCP The proper way of handling: creating proper abstraction that will be used inside entity like animal which will be extended by all subtypes. Each implementation of \"animal\" is going to provide proper functionality on its own To check: \"strategy\" design patter, \"abstract factory\" pattern.","title":"Open-Close Principal"},{"location":"programming/solid/#liskov-substitution-principle","text":"Subtype to be named as a real subtype of a type, needs to fulfill certain rules.","title":"Liskov Substitution Principle"},{"location":"programming/solid/#method-signature-rules","text":"Those rules don't apply for statically type languages as they are force by compiler by default Contravariant of arguments same number of arguments on subtype side argument passed can be only type or supertype of type in parent. classDiagram direction LR Service <|-- SubService Service: +doSomething(DoType type) class SubService{ +doSomething(DoSyperType type) } Zebra is passing an Number to Animal, and it must work the same as in Parent the Int Covariance of result either both type and subtype returns the result or neither does If there is as a result then result in subtype is type or subtype in Parent classDiagram direction LR Service <|-- SubService Service: +getSomething() Something class SubService{ +getSomething() SubSomething } Exception Rule Subtype should throw only same Exception and its sub Exception s that are handed by superclass","title":"Method Signature rules"},{"location":"programming/solid/#method-pre-condition-and-post-condition-rule","text":"Precondition Rule - subclass should be able to operate in all states that a superclass can. e.g. handling nullability classDiagram direction LR Service <|-- SubService Service: +setLucyNumber(@Nullable Integer luckyNumber) class SubService{ +setLucyNumber(@Nullable Integer luckyNumber) } Post condition Rule - Subclass can't have a weaker \"states\" than type e.g. returning null in below case classDiagram direction LR Service <|-- SubService Service: +getSomething() Something class SubService{ + @Nullable getSomething() Something }","title":"Method Pre-condition and Post-condition rule"},{"location":"programming/solid/#class-property-rule","text":"Invariant rule - invariants guaranteed by a subclass must include all invariants guaranteed by a superclass e.g. the capacity of \"DuplicatedQueue\" that duplicates whatever is there has to have the same maxCapacity as superType. classDiagram direction LR Service <|-- SubService Service: Int maxCapacity = 32 class SubService{ Int maxCapacity = 32 } Constraint rule - constraints in superclass must be included in subtype invariant is same for all instances of a calls while constraints are per instance. e.g. max capacity for queue is constraint as long as is se in constructor. If it's fixed and not set then it's invariant.","title":"Class Property Rule"},{"location":"programming/solid/#interface-segregation-principle","text":"It's principle of the least knowledge and information hiding. Restricts what client can do with their services. Clients should not be forced to implement interfaces they don't use. Instead, those interfaces should be split into smaller, more specific interfaces. This makes the system more flexible, maintainable, and extensible. Instead of having an interface with different methods (hence functionalities) in one Big Interface it's better to have couple smaller per feature. example to illustrate this principle: Suppose we are building a system for managing a library. The system has an interface called LibraryItem that defines methods for checking out and returning books, as well as methods for checking out and returning movies. However, not all clients need to use all of these methods. For example, a client that only deals with books may not need the methods for checking out and returning movies. Without following the Interface Segregation Principle, the client would be forced to implement all of the methods in the LibraryItem interface, even if they don't use some of them. This would make the system inflexible and difficult to maintain. Instead, we can follow the Interface Segregation Principle and split the LibraryItem interface into two smaller, more specific interfaces: Book and Movie. This allows clients to implement only the methods they need, and makes the system more flexible and maintainable. pros: explicit and clear dependencies between client and service -> client knows what feature it's really needs and is restricted of using different ones. readability - no empty methods -> if not used. e.g. TextChangeLister from Android SDK is breaking ISP because it provides more methods than often required. easier to find clients that are using specific functionality -> e.g. when you're looking for a bug Safe and easy to add new messages - you don't need to change xx clients when new feature/ method is added (yes/no because without using the interface at all it would give same result, but it's not what we want)","title":"Interface Segregation Principle"},{"location":"programming/solid/#dependency-inversion-principle","text":"High level module should not depend on low level module. Both should depend on abstraction and abstraction should not depend on details. Details should depend on abstraction. Benefits: usability flexible maintainable breaking dependency on external modules Here is an example to illustrate this principle: Suppose we are building a system for managing a shopping cart. The system has two modules: a low-level module for storing the items in the cart, and a high-level module for calculating the total price of the items in the cart. Without following the Dependency Inversion Principle, the high-level module would directly depend on the low-level module. This would make the system inflexible, because if we wanted to change the way the items are stored (for example, switching from a database to a file system), we would have to change the high-level module as well. Instead, we can follow the Dependency Inversion Principle and create an abstraction for the storage of the items. This could be an interface that defines a method for storing and retrieving items. Both the low-level and high-level modules would depend on this abstraction, rather than depending on each other directly. This decouples the modules from one another and makes the system more flexible. If we want to change the way the items are stored, we can simply implement the storage interface in a different way, without having to change the high-level module. This makes the system easier to maintain and extend.","title":"Dependency Inversion Principle"},{"location":"programming/testing/","text":"Unit Testing Unit Tests: readability on the same level as business code Unit Tests: more than one assert is still ok if makes sense Truth.assertThat(flattened).containsExactlyElementsIn(expected) Test Driven Development (TDD) LAWS First Law: You may not write production code until you have written a failing unit test. Second Law: You may not write more of a unit test than is sufficient to fail, and not compiling is failing. Third Law: You may not write more production code than is sufficient to pass the currently failing test. UI tests Add test rule @Rule for activity, it will run: a) run before all @before methods b) created for each @test method c) will be destroyed after @after methods you can specify how it should start when creating it with parameter giving false for launchActivity cause that you have implement in @before method creating intent that will starts the activity Espresso: ViewMatchers - allows for selecting view to interact with with usage of: withId(),withText(), withState() and so on ViewAction - what you can perform() on view from viewMatcher, ViewAssertion - used inside check(viewAssertion) to verify state Instrumented Unit Test to make it work you need add: manifest: androidTestImplementation \"androidx.arch.core:core-testing:2.0.0\" testInstrumentationRunner \"androidx.test.runner.AndroidJUnitRunner\" androidTestImplementation 'androidx.test:runner:1.1.0' androidTestImplementation 'androidx.test:rules:1.1.0' class: @get:Rule var instantTaskExecutorRule = InstantTaskExecutorRule() var value: T? = null val latch = CountDownLatch(1) val observer = Observer { t -> value = t latch.countDown() } observeForever(observer) latch.await(2, TimeUnit.SECONDS) return value } Parameterized Unit Tests To keep the testing class clean from all the sources for the testing I extracted all testing data to separate file. When extracting the source/arguments to different file I noticed below behaviour: Using @JvmStatic on source/argument method is causing lint to stop working - I am not sure what is the reason, I couldn't find anything interesting while searching. To fix this, I started using @TestInstance(TestInstance.Lifecycle.PER_CLASS) on the test class. This leads to: object is not an instance of declaring class java.lang.IllegalArgumentException: object is not an instance of declaring class... Suppressed: org.junit.platform.commons.PreconditionViolationException: Configuration error: You must configure at least one set of arguments for this @ParameterizedTest I couldn't find explanation for this either. Though the working solution is implementing ArgumentsProvider for the source/arguments internal class MyTestData : ArgumentsProvider { override fun provideArguments(context: ExtensionContext?): Stream<out Arguments> { return Stream.of( Arguments.of(...), Arguments.of(...), Arguments.of(...) ); } } and instead of using @MethodSource(...) using @ArgumentsSource(MyTestData::class) This way arguments/sources are in separate file, and you have them nicely linked to the tested class (as you specify class, instead of the string). In case of using different file && @MethodSource(you.have.to.specify.whole.path.to.MyTestData#function) and it won't auto update itself when changing the package.","title":"Unit Testing"},{"location":"programming/testing/#unit-testing","text":"Unit Tests: readability on the same level as business code Unit Tests: more than one assert is still ok if makes sense Truth.assertThat(flattened).containsExactlyElementsIn(expected)","title":"Unit Testing"},{"location":"programming/testing/#test-driven-development-tdd","text":"","title":"Test Driven Development (TDD)"},{"location":"programming/testing/#laws","text":"First Law: You may not write production code until you have written a failing unit test. Second Law: You may not write more of a unit test than is sufficient to fail, and not compiling is failing. Third Law: You may not write more production code than is sufficient to pass the currently failing test.","title":"LAWS"},{"location":"programming/testing/#ui-tests","text":"Add test rule @Rule for activity, it will run: a) run before all @before methods b) created for each @test method c) will be destroyed after @after methods you can specify how it should start when creating it with parameter giving false for launchActivity cause that you have implement in @before method creating intent that will starts the activity Espresso: ViewMatchers - allows for selecting view to interact with with usage of: withId(),withText(), withState() and so on ViewAction - what you can perform() on view from viewMatcher, ViewAssertion - used inside check(viewAssertion) to verify state","title":"UI tests"},{"location":"programming/testing/#instrumented-unit-test","text":"to make it work you need add: manifest: androidTestImplementation \"androidx.arch.core:core-testing:2.0.0\" testInstrumentationRunner \"androidx.test.runner.AndroidJUnitRunner\" androidTestImplementation 'androidx.test:runner:1.1.0' androidTestImplementation 'androidx.test:rules:1.1.0' class: @get:Rule var instantTaskExecutorRule = InstantTaskExecutorRule() var value: T? = null val latch = CountDownLatch(1) val observer = Observer { t -> value = t latch.countDown() } observeForever(observer) latch.await(2, TimeUnit.SECONDS) return value }","title":"Instrumented Unit Test"},{"location":"programming/testing/#parameterized-unit-tests","text":"To keep the testing class clean from all the sources for the testing I extracted all testing data to separate file. When extracting the source/arguments to different file I noticed below behaviour: Using @JvmStatic on source/argument method is causing lint to stop working - I am not sure what is the reason, I couldn't find anything interesting while searching. To fix this, I started using @TestInstance(TestInstance.Lifecycle.PER_CLASS) on the test class. This leads to: object is not an instance of declaring class java.lang.IllegalArgumentException: object is not an instance of declaring class... Suppressed: org.junit.platform.commons.PreconditionViolationException: Configuration error: You must configure at least one set of arguments for this @ParameterizedTest I couldn't find explanation for this either. Though the working solution is implementing ArgumentsProvider for the source/arguments internal class MyTestData : ArgumentsProvider { override fun provideArguments(context: ExtensionContext?): Stream<out Arguments> { return Stream.of( Arguments.of(...), Arguments.of(...), Arguments.of(...) ); } } and instead of using @MethodSource(...) using @ArgumentsSource(MyTestData::class) This way arguments/sources are in separate file, and you have them nicely linked to the tested class (as you specify class, instead of the string). In case of using different file && @MethodSource(you.have.to.specify.whole.path.to.MyTestData#function) and it won't auto update itself when changing the package.","title":"Parameterized Unit Tests"},{"location":"programming/third_party_library/","text":"3rd Party library learning tests -> tests in which you test 3rd party library to understand it before usage","title":"3rd Party library"},{"location":"programming/third_party_library/#3rd-party-library","text":"learning tests -> tests in which you test 3rd party library to understand it before usage","title":"3rd Party library"},{"location":"programming/android/AndroidManifest/","text":"AndroidManifest.xml loci: 12A Bathroom manifest in front of the door Closing Doors with noise - affinity Locking the doors - standard opening toilet - singleTop sitting - singeTask it already exists - singleInstance rolls of paper - singleInstancePerTask flush - lyst issue story: I'm going through the crowd that is standing in front of the bathroom doors, I enter bathroom closing the doors with cracking noise. Next I am locking the doors and looks how after the locking, the lock is falling down and stacks on previously used locks. I can see that there are multiple lids on toilet so Im removing all of them except one and put the lid up. When I try to sit some people start to screaming that they were here before me and I should go to queue. I'm telling them that I was here before and show them photo, they exit. I'm doing my best, but it just can't happen. Then I realize that I was here before because of the same reason, so it means that somewhere it already exists! I take the rolls of toilet paper and use them as rods (paper is line) to find the instance. After fail attempt I flush everything and notice that rolls of paper are back where they were. \\ taskAffinity android:taskAffinity=\"string\" The affinity determines two things \u2014 the task that the activity is re-parented to (see the allowTaskReparenting attribute) and the task that will house the activity when it is launched with the FLAG_ACTIVITY_NEW_TASK flag. By default, the taskAffinity is based on Applicaiton namespace (when is not set it's taken from package). taskAffinity takes precedence over launchMode . launchMode overall launchMode on its own only decides how Activity should be launched (either in the same task or not). But it's not the only thing that can impact how Activity is started. It also depends on current stack. My feelings are that the best what we can do it to use standard behaviour as often as possible. In some specific cases we can use also singleTop . Using multiple activities can be painful otherwise! e.g. in below scenario: Task1: ActivityA(singleTask) Task2: ActivityB (singleInstance) now ActivityB wants to start ActivityC with flag Intent.FLAG_ACTIVITY_NEW_TASK. (All activities have the same affinity) What will be the list of Task and Activities after starting ActivityC? Task1: ActivityA(singleTask), ActivityC Task2: ActivityB (singleInstance) note: the task hierarchy is equivalent to the case if we wouldn't add the flag Intent.FLAG_ACTIVITY_NEW_TASK at all. Once ActivityC is opened pressing back button takes user to ActivityA In above case system checks that the task for the same affinity is existing and the task is not launched as singleInstance, so it attaches new Activity to it. to prevent the above we can use below: Intent.FLAG_ACTIVITY_NEW_TASK or Intent.FLAG_ACTIVITY_MULTIPLE_TASK using this will give below situation: Task1: ActivityA(singleTask), Task2: ActivityB (singleInstance) Task3: ActivityC(Intent.FLAG_ACTIVITY_NEW_TASK or Intent.FLAG_ACTIVITY_MULTIPLE_TASK) Once ActivityC is opened pressing back button takes user to ActivityB -> ActivityA alternative, we can use: Intent.FLAG_ACTIVITY_NEW_TASK or Intent.FLAG_ACTIVITY_CLEAR_TASK this will give below situation: Task1: ActivityC(Intent.FLAG_ACTIVITY_NEW_TASK or Intent.FLAG_ACTIVITY_CLEAR_TASK), Task2: ActivityB (singleInstance) so Task1 is reused, but everything in there is removed Once ActivityC is opened pressing back button takes user to ActivityB -> Launcher another apprach, we can use: Intent.FLAG_ACTIVITY_NEW_TASK or Intent.Intent.FLAG_ACTIVITY_CLEAR_TOP this will give below situation: Task1: ActivityA(singleTask), ActivityC(Intent.FLAG_ACTIVITY_NEW_TASK or Intent.FLAG_ACTIVITY_CLEAR_TOP), Task2: ActivityB (singleInstance) Once ActivityC is opened pressing back button takes user to ActivityA -> ActivityB // some chatGPT notes If you try to start the same Activity with different affinity and launchMode settings after the Activity has already been created with the SingleInstance launch mode, the behavior will depend on the specific settings you use. Here are a few possible scenarios: If you try to start the Activity with the same affinity and launchMode settings as the original instance, the existing instance will be reused and no new instance will be created. This means that the Activity will continue to be a singleton, and will be shared by all tasks that need to use it. If you try to start the Activity with a different affinity but the same launchMode settings as the original instance, the existing instance will be reused, but it will be placed in a new task with the specified affinity. This means that the Activity will continue to be a singleton, but it will be part of a new task, and will be isolated from the other activities in that task. If you try to start the Activity with a different launchMode but the same affinity as the original instance, the existing instance will be reused, but its launchMode will be updated to the specified launchMode. This means that the Activity will no longer be a singleton, and may be launched multiple times within the context of the specified affinity. If you try to start the Activity with a different affinity and launchMode, a new instance of the Activity will be created, and it will be placed in a new task with the specified affinity and launchMode. This means that the Activity will no longer be a singleton, and will be part of a new task, with its own behavior and characteristics. Overall, the specific behavior of the Activity in these scenarios will depend on the specific settings you use, and on the state of the original instance of the Activity. It is important to carefully consider these settings and their effects when starting an Activity in order to ensure that the Activity behaves as desired. StackOverflow link explaining it android:launchMode=\"standard|singleTop|singleTask|singleInstance|singleInstancePerTask\" standard - Default. The system always creates a new instance of the activity in the target task and routes the intent to it. singleTop - If an instance of the activity already exists at the top of the target task, the system routes the intent to that instance through a call to its onNewIntent() method, rather than creating a new instance of the activity. ONLY ONE ACTIVITY AT THE TOP OF THE STACK OF PARTICULAR TASK singleTask - The system creates the activity at the root of a new task or locates the activity on an existing task with the same affinity . If an instance of the activity already exists and is at the root of the task, the system routes the intent to existing instance through a call to its onNewIntent() method, rather than creating a new instance. Meanwhile, all the other activities on top of it are destroyed . FIND EXISTING ACTIVITY WITH SAME AFFINITY IN THE TASK OR CREATE NEW TASK singleInstance - The activity is always the single and only member of its task. , beside Same as \"singleTask\", holding the instance. This can be useful for activities that require a unique, persistent state, such as a login screen or a settings page. singleInstancePerTask - the first activity that created the task, and therefore there will only be one instance of this activity in a task; but activity can be instantiated multiple times in different tasks. task - stack of activities Start a task You can set up an activity as the entry point for a task by giving it an intent filter with \"android.intent.action.MAIN\" as the specified action and \"android.intent.category.LAUNCHER\" as the specified category. For example: <activity ... > <intent-filter ... > <action android:name=\"android.intent.action.MAIN\" /> <category android:name=\"android.intent.category.LAUNCHER\" /> </intent-filter> ... </activity> if activity is launched with launchMode: singleTask, singleInstance, singleInstancePerTask it's important to note that the activity will only clear the stack of its own task. e.g. ActivityA, launchMode:singleTask ActivityB, launchMode:singleInstance ActivityC, launchMode:standard each activity is started without additional flags as startActivity() note: if Activity is started as startActivityForResult() it belongs to the same task which started the activity. flow: A->B->C tasks [backstack]: [A] [B] [C] Each Activity will be in separate task, because ActivityB is forcing to be started as new task and as single element. Lyst Issue: The Stack of activities is cleared whenever we click on launcher. The problem is not affecting only NativeCheckoutAcitivty , but any activity that is opened from HomeActivity SplashActivity is always started as launchMode:SingleTask -> tapping on Launcher Icon will always clear the stack of activities above it, although in our case it\u2019s not really an issue because it\u2019s the only activity in this stack anyway because SplashActivitiy always calls finish() when navigating somewhere + HomeActivity settings cause it would happen anyway if finish() wouldn\u2019t be called. HomeActivity is always started as launchMode:SingleInstance -> tapping on Launcher Icon will always clear the stack of activities above HomeActivity , it is our case. Because it is started as SingleInstance whenever we put app in the background and comeback new SplashActivity is created which is opening HomeActivity , because the task for HomeActivity already exists, HomeActivity is reopened with clearing of the stack above. With current approach it\u2019s impossible to keep any other activity on TOP of HomeActivity when pressing launcher icon. sequenceDiagram actor User participant HomeScreen participant SplashActivity participant HomeActivity participant NativeCheckoutActivity User-->> HomeScreen: taps on icon launcher rect rgb(200, 150, 255) Note over SplashActivity: It runs in its own task HomeScreen->> SplashActivity: start(SINGLE_TASK) SplashActivity ->> SplashActivity: finish() end rect rgb(0, 150, 255) Note over HomeActivity: It runs in its own task* SplashActivity->> HomeActivity: start(singleInstance) HomeActivity ->> NativeCheckoutActivity: startActivityForResult() end NativeCheckoutActivity -->> HomeScreen: user taps on home button User-->> HomeScreen: taps on icon launcher rect rgb(200, 150, 255) Note over SplashActivity: It runs in its own task HomeScreen->> SplashActivity: start(SINGLE_TASK) SplashActivity ->> SplashActivity: finish() end rect rgb(0, 150, 255) Note over HomeActivity: It runs in its own task SplashActivity->> HomeActivity: start(singleInstance) end flowchart LR subgraph SplashActivityStack1 direction TB SplashActivity end subgraph HomeActivity1Stack direction TB NativeCheckoutActivity --- HomeActivity end subgraph SplashActivityStack2 direction TB SplashActivity2 end subgraph HomeActivity2Stack direction TB HomeActivity2 end SplashActivityStack1 --> HomeActivity1Stack HomeActivity1Stack --> SplashActivityStack2 SplashActivityStack2 --> HomeActivity2Stack HomeActivity2Stack --Missing--> NativeCheckoutActivity2 style SplashActivityStack1 fill:#c896ff style SplashActivityStack2 fill:#c896ff style HomeActivity1Stack fill:#0096ff style HomeActivity2Stack fill:#0096ff style NativeCheckoutActivity2 fill:#fcf5f5;stroke-width:2px,stroke-dasharray: 5 5,color:#F00,stroke:#f00 Possible Solutions for fixing the issue require changes in architecture: Changing the launchModes: In our case the SplashActivity flag is not so important, it could be even SingleInstance and it would produce similar result (as we are always finishing this activity). To improve performance from Android12 probably it would be good to remove SpashActivity HomeActivity can\u2019t keep launchMode:SingleInstance, as long as we will have it the stack above will be cleared. In reality, the task for NativeCheckout activity could potentially exist separately with some way of knowing that we need to navigate to it after coming back to app, but this solution looks too complicated - KISS. This solution is one recommended in Googles\u2019 documentation. Making sure that HomeActivity is always at the top of the stack - which would mean that we shouldn\u2019t have any navigation from HomeActivity that is an Activity (in practice, it means that each Activity should be replaced with Fragment). This might be easier to implement, but it would also require logic to show/hide the bottom navigation bar. In both cases, it requires at least medium effort to complete/fix the issue as not only we need to do the changes, but we need to make sure that we didn\u2019t break anything. We would also need to do thorough testing of the whole app as regression is probable. On top of it: The HomeActivity is started as singleInstance which should in theory make sure that it will be the only member of its task. Though because AccountActivity and NativeCheckoutActivity is started as startActivityForResult() it belongs to the same task as HomeActivity","title":"AndroidManifest.xml"},{"location":"programming/android/AndroidManifest/#androidmanifestxml","text":"loci: 12A Bathroom manifest in front of the door Closing Doors with noise - affinity Locking the doors - standard opening toilet - singleTop sitting - singeTask it already exists - singleInstance rolls of paper - singleInstancePerTask flush - lyst issue story: I'm going through the crowd that is standing in front of the bathroom doors, I enter bathroom closing the doors with cracking noise. Next I am locking the doors and looks how after the locking, the lock is falling down and stacks on previously used locks. I can see that there are multiple lids on toilet so Im removing all of them except one and put the lid up. When I try to sit some people start to screaming that they were here before me and I should go to queue. I'm telling them that I was here before and show them photo, they exit. I'm doing my best, but it just can't happen. Then I realize that I was here before because of the same reason, so it means that somewhere it already exists! I take the rolls of toilet paper and use them as rods (paper is line) to find the instance. After fail attempt I flush everything and notice that rolls of paper are back where they were.","title":"AndroidManifest.xml"},{"location":"programming/android/AndroidManifest/#_1","text":"","title":"\\"},{"location":"programming/android/AndroidManifest/#taskaffinity","text":"android:taskAffinity=\"string\" The affinity determines two things \u2014 the task that the activity is re-parented to (see the allowTaskReparenting attribute) and the task that will house the activity when it is launched with the FLAG_ACTIVITY_NEW_TASK flag. By default, the taskAffinity is based on Applicaiton namespace (when is not set it's taken from package). taskAffinity takes precedence over launchMode .","title":"taskAffinity"},{"location":"programming/android/AndroidManifest/#launchmode","text":"overall launchMode on its own only decides how Activity should be launched (either in the same task or not). But it's not the only thing that can impact how Activity is started. It also depends on current stack. My feelings are that the best what we can do it to use standard behaviour as often as possible. In some specific cases we can use also singleTop . Using multiple activities can be painful otherwise! e.g. in below scenario: Task1: ActivityA(singleTask) Task2: ActivityB (singleInstance) now ActivityB wants to start ActivityC with flag Intent.FLAG_ACTIVITY_NEW_TASK. (All activities have the same affinity) What will be the list of Task and Activities after starting ActivityC? Task1: ActivityA(singleTask), ActivityC Task2: ActivityB (singleInstance) note: the task hierarchy is equivalent to the case if we wouldn't add the flag Intent.FLAG_ACTIVITY_NEW_TASK at all. Once ActivityC is opened pressing back button takes user to ActivityA In above case system checks that the task for the same affinity is existing and the task is not launched as singleInstance, so it attaches new Activity to it. to prevent the above we can use below: Intent.FLAG_ACTIVITY_NEW_TASK or Intent.FLAG_ACTIVITY_MULTIPLE_TASK using this will give below situation: Task1: ActivityA(singleTask), Task2: ActivityB (singleInstance) Task3: ActivityC(Intent.FLAG_ACTIVITY_NEW_TASK or Intent.FLAG_ACTIVITY_MULTIPLE_TASK) Once ActivityC is opened pressing back button takes user to ActivityB -> ActivityA alternative, we can use: Intent.FLAG_ACTIVITY_NEW_TASK or Intent.FLAG_ACTIVITY_CLEAR_TASK this will give below situation: Task1: ActivityC(Intent.FLAG_ACTIVITY_NEW_TASK or Intent.FLAG_ACTIVITY_CLEAR_TASK), Task2: ActivityB (singleInstance) so Task1 is reused, but everything in there is removed Once ActivityC is opened pressing back button takes user to ActivityB -> Launcher another apprach, we can use: Intent.FLAG_ACTIVITY_NEW_TASK or Intent.Intent.FLAG_ACTIVITY_CLEAR_TOP this will give below situation: Task1: ActivityA(singleTask), ActivityC(Intent.FLAG_ACTIVITY_NEW_TASK or Intent.FLAG_ACTIVITY_CLEAR_TOP), Task2: ActivityB (singleInstance) Once ActivityC is opened pressing back button takes user to ActivityA -> ActivityB // some chatGPT notes If you try to start the same Activity with different affinity and launchMode settings after the Activity has already been created with the SingleInstance launch mode, the behavior will depend on the specific settings you use. Here are a few possible scenarios: If you try to start the Activity with the same affinity and launchMode settings as the original instance, the existing instance will be reused and no new instance will be created. This means that the Activity will continue to be a singleton, and will be shared by all tasks that need to use it. If you try to start the Activity with a different affinity but the same launchMode settings as the original instance, the existing instance will be reused, but it will be placed in a new task with the specified affinity. This means that the Activity will continue to be a singleton, but it will be part of a new task, and will be isolated from the other activities in that task. If you try to start the Activity with a different launchMode but the same affinity as the original instance, the existing instance will be reused, but its launchMode will be updated to the specified launchMode. This means that the Activity will no longer be a singleton, and may be launched multiple times within the context of the specified affinity. If you try to start the Activity with a different affinity and launchMode, a new instance of the Activity will be created, and it will be placed in a new task with the specified affinity and launchMode. This means that the Activity will no longer be a singleton, and will be part of a new task, with its own behavior and characteristics. Overall, the specific behavior of the Activity in these scenarios will depend on the specific settings you use, and on the state of the original instance of the Activity. It is important to carefully consider these settings and their effects when starting an Activity in order to ensure that the Activity behaves as desired. StackOverflow link explaining it android:launchMode=\"standard|singleTop|singleTask|singleInstance|singleInstancePerTask\" standard - Default. The system always creates a new instance of the activity in the target task and routes the intent to it. singleTop - If an instance of the activity already exists at the top of the target task, the system routes the intent to that instance through a call to its onNewIntent() method, rather than creating a new instance of the activity. ONLY ONE ACTIVITY AT THE TOP OF THE STACK OF PARTICULAR TASK singleTask - The system creates the activity at the root of a new task or locates the activity on an existing task with the same affinity . If an instance of the activity already exists and is at the root of the task, the system routes the intent to existing instance through a call to its onNewIntent() method, rather than creating a new instance. Meanwhile, all the other activities on top of it are destroyed . FIND EXISTING ACTIVITY WITH SAME AFFINITY IN THE TASK OR CREATE NEW TASK singleInstance - The activity is always the single and only member of its task. , beside Same as \"singleTask\", holding the instance. This can be useful for activities that require a unique, persistent state, such as a login screen or a settings page. singleInstancePerTask - the first activity that created the task, and therefore there will only be one instance of this activity in a task; but activity can be instantiated multiple times in different tasks. task - stack of activities Start a task You can set up an activity as the entry point for a task by giving it an intent filter with \"android.intent.action.MAIN\" as the specified action and \"android.intent.category.LAUNCHER\" as the specified category. For example: <activity ... > <intent-filter ... > <action android:name=\"android.intent.action.MAIN\" /> <category android:name=\"android.intent.category.LAUNCHER\" /> </intent-filter> ... </activity> if activity is launched with launchMode: singleTask, singleInstance, singleInstancePerTask it's important to note that the activity will only clear the stack of its own task. e.g. ActivityA, launchMode:singleTask ActivityB, launchMode:singleInstance ActivityC, launchMode:standard each activity is started without additional flags as startActivity() note: if Activity is started as startActivityForResult() it belongs to the same task which started the activity. flow: A->B->C tasks [backstack]: [A] [B] [C] Each Activity will be in separate task, because ActivityB is forcing to be started as new task and as single element. Lyst Issue: The Stack of activities is cleared whenever we click on launcher. The problem is not affecting only NativeCheckoutAcitivty , but any activity that is opened from HomeActivity SplashActivity is always started as launchMode:SingleTask -> tapping on Launcher Icon will always clear the stack of activities above it, although in our case it\u2019s not really an issue because it\u2019s the only activity in this stack anyway because SplashActivitiy always calls finish() when navigating somewhere + HomeActivity settings cause it would happen anyway if finish() wouldn\u2019t be called. HomeActivity is always started as launchMode:SingleInstance -> tapping on Launcher Icon will always clear the stack of activities above HomeActivity , it is our case. Because it is started as SingleInstance whenever we put app in the background and comeback new SplashActivity is created which is opening HomeActivity , because the task for HomeActivity already exists, HomeActivity is reopened with clearing of the stack above. With current approach it\u2019s impossible to keep any other activity on TOP of HomeActivity when pressing launcher icon. sequenceDiagram actor User participant HomeScreen participant SplashActivity participant HomeActivity participant NativeCheckoutActivity User-->> HomeScreen: taps on icon launcher rect rgb(200, 150, 255) Note over SplashActivity: It runs in its own task HomeScreen->> SplashActivity: start(SINGLE_TASK) SplashActivity ->> SplashActivity: finish() end rect rgb(0, 150, 255) Note over HomeActivity: It runs in its own task* SplashActivity->> HomeActivity: start(singleInstance) HomeActivity ->> NativeCheckoutActivity: startActivityForResult() end NativeCheckoutActivity -->> HomeScreen: user taps on home button User-->> HomeScreen: taps on icon launcher rect rgb(200, 150, 255) Note over SplashActivity: It runs in its own task HomeScreen->> SplashActivity: start(SINGLE_TASK) SplashActivity ->> SplashActivity: finish() end rect rgb(0, 150, 255) Note over HomeActivity: It runs in its own task SplashActivity->> HomeActivity: start(singleInstance) end flowchart LR subgraph SplashActivityStack1 direction TB SplashActivity end subgraph HomeActivity1Stack direction TB NativeCheckoutActivity --- HomeActivity end subgraph SplashActivityStack2 direction TB SplashActivity2 end subgraph HomeActivity2Stack direction TB HomeActivity2 end SplashActivityStack1 --> HomeActivity1Stack HomeActivity1Stack --> SplashActivityStack2 SplashActivityStack2 --> HomeActivity2Stack HomeActivity2Stack --Missing--> NativeCheckoutActivity2 style SplashActivityStack1 fill:#c896ff style SplashActivityStack2 fill:#c896ff style HomeActivity1Stack fill:#0096ff style HomeActivity2Stack fill:#0096ff style NativeCheckoutActivity2 fill:#fcf5f5;stroke-width:2px,stroke-dasharray: 5 5,color:#F00,stroke:#f00 Possible Solutions for fixing the issue require changes in architecture: Changing the launchModes: In our case the SplashActivity flag is not so important, it could be even SingleInstance and it would produce similar result (as we are always finishing this activity). To improve performance from Android12 probably it would be good to remove SpashActivity HomeActivity can\u2019t keep launchMode:SingleInstance, as long as we will have it the stack above will be cleared. In reality, the task for NativeCheckout activity could potentially exist separately with some way of knowing that we need to navigate to it after coming back to app, but this solution looks too complicated - KISS. This solution is one recommended in Googles\u2019 documentation. Making sure that HomeActivity is always at the top of the stack - which would mean that we shouldn\u2019t have any navigation from HomeActivity that is an Activity (in practice, it means that each Activity should be replaced with Fragment). This might be easier to implement, but it would also require logic to show/hide the bottom navigation bar. In both cases, it requires at least medium effort to complete/fix the issue as not only we need to do the changes, but we need to make sure that we didn\u2019t break anything. We would also need to do thorough testing of the whole app as regression is probable. On top of it: The HomeActivity is started as singleInstance which should in theory make sure that it will be the only member of its task. Though because AccountActivity and NativeCheckoutActivity is started as startActivityForResult() it belongs to the same task as HomeActivity","title":"launchMode"},{"location":"programming/android/UITesting/","text":"Hilt add complexity to UI testing when using Fragments (additionally when using multi-module project), in some cases it might be event impossible to implement (vide Lyst) as it would require a refactor of whole architecture of the app. Running Test Instrumented Test via ADV adb shell am instrument -w -e package com.justeat.ordersui -e class com.justeat.ordersui.OrderListWithSidePanelScreenshotTest#badgeIsShownOnTabletsButNotOnPhonesForCancelledOrder -e annotation com.justeat.uitestutils.IsScreenshotTest com.justeat.ordersui.test/com.justeat.TestRunner more commands","title":"UITesting"},{"location":"programming/android/UITesting/#running-test-instrumented-test-via-adv","text":"adb shell am instrument -w -e package com.justeat.ordersui -e class com.justeat.ordersui.OrderListWithSidePanelScreenshotTest#badgeIsShownOnTabletsButNotOnPhonesForCancelledOrder -e annotation com.justeat.uitestutils.IsScreenshotTest com.justeat.ordersui.test/com.justeat.TestRunner more commands","title":"Running Test Instrumented Test via ADV"},{"location":"programming/android/notes/","text":"Activity vs Fragment \"You may want to consider using the new Fragment APIs to replace this arbitrary stack of activities with a single activity that more tightly manages its memory. For example if you use the back stack facilities of fragments, when a fragment goes on the back stack and is no longer visible, its onDestroyView() method is called to completely remove its view hierarchy, greatly reducing its footprint. https://stackoverflow.com/questions/7536988/android-app-out-of-memory-issues-tried-everything-and-still-at-a-loss/7576275#7576275\" Activity itself is never killed by the system, system kills whole process (all activities) LIFECYCLE - you can extend from class LifecycleObserver - pass Lifecycle as paramter, later call: lifecycle.addObserver(this-LifecycleObserver) - add annotations to methods to be called @OnLifecycleEvent(Lifecycle.event.ON_XXX) LIVEDATA - always val, - backing field/property poniewz view powinien miec mozliwosc obserwowania livedata, to livedata nie moze byc private, ale jesli jest mutableLiveData wtedy view moze zmienic wartosc, a tak nie powinno byc! z tego wzgledu wprowadza sie backing property, ktora powoduje ze wartosc zmienna zaczyna sie z podkreslnikime i ustawia jako private np. private val _score, natomiast widoczna LiveData dla view bedzie val score: LiveData get() = _score tym samym view moze obserowowac wartosc, ale nie moze jeje zmieniac - EASY BUG TO DO - obserowanie state moze powodowac, ze po rotacji otrzymamy kolejny raz state, a powinnismy go dostac tylko raz JobScheduler create a class that extends JobService override: onStartJob -> if returns true then it will continue the the live of the job, false destroys the job. If you want to destroy it on your own call jobFinished(...) onStopJob -> if returns true, the job will be redone Room utworzenie entity: data klasa ktora ma adnotacje @Entity, jest obiektem ktory chcemy zapisac, musi miec @PrimaryKey utworzenie Data Access Object (DAO): klasa abstrakcyjna lub interface, w ktorej wykonujemy operacje na bazie danych -> tworzymy poleceniea poprzez utworzenie metody z adnotacja, jak: @Insert(onConflict = OnConflictStrategy.IGNORE) fun insert(person: Person) albo: @Query(\"SELECT * FROM Person ORDER BY surname ASC\") fun getAll(): LiveData > Utworzenie bazydanych Room 3.1. klasa dziedziczy po RoomDatabase, musi miec adnotacje @Database(entities = [tutajEntites], version = x, exportSchema = true/false) exportSchema - pozwala zachowac w pamiec jak wygladala tabela w danej wersji 3.2. klasa abstrakcyjna 3.3. nalezy utworzyc abstrakcyjne funkcje zwracajace kazde dao 3.4. obiekt ma byc singletonem, ktorego nalezy utworzyc przy wykorzystaniu synchronized, jak robi sie poprzez asyncTask nalezy dodac tez callback Utworzenie Repository, ktore zbiera wszystkie zrodla pozyskiwania tej samej iformacji (chmura, bazadanych) 4.1. tutaj inicjalizujemy RoomDatabase 4.2. bierzemy z rooma dao za pomoca ktorego komonikujemy z roomem 4.3. dodajemy obiekty do rooma za pomoca asyntaska Tworzymy viewmodel w ktorym tworzymy repo obiekt i z ktorego bierzemy dane Paging PageLibrary Full version 1. Stworz klase ktora dziedziczy po DataSource (Generalnie sa 3 popularne klasy po ktorych sie dziedziczy: 1. PageKeyedDataSource - dzielimy zrodlo na strony, np. kazda strona ma 10 elementow, strona jest umowna, chodzi o to by wiedziec ze 10 elemnotw tworzy 1 wiekszy element = strona) 2. ItemKeyDataSource - ladowanie po itemie tzn, jesli jest cos dla niego specyficznego, i sa uszeregowane to mozna wykorzystac to do ladowania 3. PositionalDataSource - kiedy wiadomo jaka jest wielkosc listy) W przypadku PageKeyedDataSource mozna uzyc do tworzenia listy, gdzie Int odpowiada numerowi stronie, a item to dane ktore nas interesuja, 3 metody do nadpisania: loadBefore - w przypadku requestu bezporesednio do internetu, nie potrzeba implementowac loadInitial - pierwsze ladowanie danych, request w repo(dobrze jest przekazac jako parametr params.requestedLoadSize ) ktory nastepnie przekazujemy do callback.onResult() loadAfter - nastepne ladowania danych jw. istotne jest utworzenie pol val currentPage = 1 val nextPage = currentPage + 1, ktore przekazujemy do callbacku i w loadAfter() przed kazdym requestem nadpisujemy( currentPage = params.key( bo key jest item== current page), nextpage = currentPage + 1) Utworzenie klasy ktora dziedziczy po DataSource.Factory utworzenie pola np. source ktory jest MutableLiveData () nadpisujemy onCreate tworzymy tam zmienna lokalna MyDataSource() a jej wartosc postujemy do source liveData, zwracamy zmienna lokalna Utworzenie metody w repo ktora zwraca LiveData > poprzez utworzenie LivePageDataBuilder.build() w aktywnosci zmieniamy z setowania listy do adaptera na uzywanie adapter.submitList(lista) w Adapterze zmieniamy z dziedziczenia na PagedListAdapter (DIFF_CALLBACK) (DIFF_CALLBACK) to DiffUtil.ItemCallback ktory ma 2 metody na sprawdzanie itemow (zazwyczaj po ID) i kontentu - porownanie obiektow do siebie (itemOld == itemNew) nie nadpisujemy getItemCount na onBindViewHolder uzywamy getItem() bo nie ma pola dla listy! PAGING Library in Room w dao object zwracamy DataSource.Factory zamiast livedata ta sama zmiana w repo w viewModel tworzymy livedata poprzez wywowalnie na obiekcie z repo .toLiveData(int pageSize) w aktywnosci zmieniamy z setowania listy do adaptera na uzywanie adapter.submitList(lista) w Adapterze zmieniamy z dziedziczenia na PagedListAdapter (DIFF_CALLBACK) (DIFF_CALLBACK) to DiffUtil.ItemCallback ktory ma 2 metody na sprawdzanie itemow (zazwyczaj po ID) i kontentu - porownanie obiektow do siebie (itemOld == itemNew) nie nadpisujemy getItemCount na onBindViewHolder uzywamy getItem() bo nie ma pola dla listy! Loaders Why not use loaders: https://medium.com/inloopx/its-time-to-ditch-loaders-in-android-6492616775f7 Dagger DAGGER2 Dependancy Injection - tworzenie obiektow poprzez dodatnie do konstrukora obiektow zaleznych, a nie tworzenie ich lokalnie Dagger2 sklada sie z nastepujacych elementow: - Module - klasa z adnotacja @Module, metody ktore dostarczaja obiekty z adnotacja @Provides i czesto @Singleton - jezeli obiekt jest ciezki w inicjializacji i moze byc uzyty ponownie, - Components - klej pomiedzy modulami a @Inject, to interfacae, ktory oznaczamy @Component(modules = {zaleznyModul1.class, zaleznyModul2.class}) metody interfacu maja za zadanie dostarczyc obiekty z modulow. Komponenty sa swiadome zakresu obiketow w module i jesli obiekty sa singletom mozna onaczyc kompent aby rowniez byc singletonem - @Inject - adnotacja ktora umozliwia dostarczenie przez Dagger2 potrzebnych obiektow, dodatkowo jezeli klasa X ktora sama jest tworzona w module i jej parameter Y jest tworzony w module, to ostatecznie nie musi byc tworzona w module :P Poniewaz dagger2 potrafi znalezc zaleznosci. W takim przypadku wystarczy oznaczyc konstrukor jako class X @Inject constructor(y: Y) , nalezy tez pamietac o tym by klasa wtedy byla @Singleton (jesli w module tak bylo) i nalezy usunac metody z modulu. na metodach @Inject uzywamy TYLKO aby zastapic this (tak powiedzial Jack Wharton) By dostac obiekty tworzymy jak najszybsciej Component w kodzie np. w klasie Aplikacji za pomoca DaggerNameOfComponent.builder()... .build() wtedy mamy dostep do metod z componentu Picasso mozna uzywac posredniego serwera (np. thumbor) do stwierdzania jakiej wielkosci ma byc obrazek, wtedy dostajemy gotowej wielkosci obraz -> nie trzeba go zmniejszac na telefonie -> oszczednoscc CPU i baterii THREADING AsyncTask nie moze byc inner class UIControllerze bo bedzie trzymal referencje StrickMode - pozwala na wykrycie operacji I/O na MainThread CPUProfiler - displays all there are ANR trace file that you can get from the device ANR - moze odbyc sie tez przez inne thready jak jest lockResource (Deadlock) - resource wykorzystywany przez inny watek, ktory jest potrzebny w glowny np. przez synchronized(resource) a ten tam resource jest przekazany do asynctaska slow rendering jest nazywany jank Main thread (Ui Thread) zadaniem jest wykonywanie blokow pracy z thread-safe kolejki do moementu zakonczenie pracy. W tym zawiera sie: callbacki od lifecycle, wydarzenia od uzytkownia, od innych aplikacji i procesow, zarzadzanie viewsow (dlatego tez, nie daje sie zadnych referencji viewsow do innych watkow!- updated tylko poprzez wlascicicela Activity/Fragment), animacji System probuje sie przerysowac co kazde 16 milisekund - jesli jest za duzo rzeczy do zrobienia na Main threadzie to nie zdazy - jank -> bedzie musial skipowac framey - co oznacze ze ich nie odsiweza. AsyncTask(90% use caseow) nie moze byc inner(w kotlinie wystarczy usunaca inner) class Activity/Fragment bo bedzie trzymam referencje -> leak + jank onPreExecution odbywa sie na MainThreadzie doInBackground - juz na workerThreadzie onPostExecution - MainThread onCancel - MainThread AasynTask ma 1 worker thread HandlerThread - sklada sie z: - loopera kiedy praca do wykonania jest naprawde duza - zwracamy do UI Threada za pomoaca runOnUiThread ThreadPoolExecutor - tworzy thready na ktorych moze byc wykonana pracy duzej ilosci malej, maks ilosc watkow mozna pobrac z sytemu. IntentService - w momencie kiedy chcesz odpowiedziec intentowi, ale wisz ze praca troche zajmie a UI aktualnie jest w backgroundzie, Handler zly bo by czekal godzinamy na to az intent przyjdzie (a w miedzyczasie zjada resources) wszystkei te klasy same ustawiaja thread priority, defaultowo thread priority bedzie takie samo jak maina - 0 (DEFAULT) Foreground Threads - 95% execution time background Threads - 5% Jak aplikacja jest odpalana Android tworzy linux proces dla tej aplikacji z main threadem Modularization androidx-dependency-tracker","title":"Notes"},{"location":"programming/android/notes/#activity-vs-fragment","text":"\"You may want to consider using the new Fragment APIs to replace this arbitrary stack of activities with a single activity that more tightly manages its memory. For example if you use the back stack facilities of fragments, when a fragment goes on the back stack and is no longer visible, its onDestroyView() method is called to completely remove its view hierarchy, greatly reducing its footprint. https://stackoverflow.com/questions/7536988/android-app-out-of-memory-issues-tried-everything-and-still-at-a-loss/7576275#7576275\" Activity itself is never killed by the system, system kills whole process (all activities) LIFECYCLE - you can extend from class LifecycleObserver - pass Lifecycle as paramter, later call: lifecycle.addObserver(this-LifecycleObserver) - add annotations to methods to be called @OnLifecycleEvent(Lifecycle.event.ON_XXX) LIVEDATA - always val, - backing field/property poniewz view powinien miec mozliwosc obserwowania livedata, to livedata nie moze byc private, ale jesli jest mutableLiveData wtedy view moze zmienic wartosc, a tak nie powinno byc! z tego wzgledu wprowadza sie backing property, ktora powoduje ze wartosc zmienna zaczyna sie z podkreslnikime i ustawia jako private np. private val _score, natomiast widoczna LiveData dla view bedzie val score: LiveData get() = _score tym samym view moze obserowowac wartosc, ale nie moze jeje zmieniac - EASY BUG TO DO - obserowanie state moze powodowac, ze po rotacji otrzymamy kolejny raz state, a powinnismy go dostac tylko raz","title":"Activity vs Fragment"},{"location":"programming/android/notes/#jobscheduler","text":"create a class that extends JobService override: onStartJob -> if returns true then it will continue the the live of the job, false destroys the job. If you want to destroy it on your own call jobFinished(...) onStopJob -> if returns true, the job will be redone","title":"JobScheduler"},{"location":"programming/android/notes/#room","text":"utworzenie entity: data klasa ktora ma adnotacje @Entity, jest obiektem ktory chcemy zapisac, musi miec @PrimaryKey utworzenie Data Access Object (DAO): klasa abstrakcyjna lub interface, w ktorej wykonujemy operacje na bazie danych -> tworzymy poleceniea poprzez utworzenie metody z adnotacja, jak: @Insert(onConflict = OnConflictStrategy.IGNORE) fun insert(person: Person) albo: @Query(\"SELECT * FROM Person ORDER BY surname ASC\") fun getAll(): LiveData > Utworzenie bazydanych Room 3.1. klasa dziedziczy po RoomDatabase, musi miec adnotacje @Database(entities = [tutajEntites], version = x, exportSchema = true/false) exportSchema - pozwala zachowac w pamiec jak wygladala tabela w danej wersji 3.2. klasa abstrakcyjna 3.3. nalezy utworzyc abstrakcyjne funkcje zwracajace kazde dao 3.4. obiekt ma byc singletonem, ktorego nalezy utworzyc przy wykorzystaniu synchronized, jak robi sie poprzez asyncTask nalezy dodac tez callback Utworzenie Repository, ktore zbiera wszystkie zrodla pozyskiwania tej samej iformacji (chmura, bazadanych) 4.1. tutaj inicjalizujemy RoomDatabase 4.2. bierzemy z rooma dao za pomoca ktorego komonikujemy z roomem 4.3. dodajemy obiekty do rooma za pomoca asyntaska Tworzymy viewmodel w ktorym tworzymy repo obiekt i z ktorego bierzemy dane","title":"Room"},{"location":"programming/android/notes/#paging","text":"PageLibrary Full version 1. Stworz klase ktora dziedziczy po DataSource (Generalnie sa 3 popularne klasy po ktorych sie dziedziczy: 1. PageKeyedDataSource - dzielimy zrodlo na strony, np. kazda strona ma 10 elementow, strona jest umowna, chodzi o to by wiedziec ze 10 elemnotw tworzy 1 wiekszy element = strona) 2. ItemKeyDataSource - ladowanie po itemie tzn, jesli jest cos dla niego specyficznego, i sa uszeregowane to mozna wykorzystac to do ladowania 3. PositionalDataSource - kiedy wiadomo jaka jest wielkosc listy) W przypadku PageKeyedDataSource mozna uzyc do tworzenia listy, gdzie Int odpowiada numerowi stronie, a item to dane ktore nas interesuja, 3 metody do nadpisania: loadBefore - w przypadku requestu bezporesednio do internetu, nie potrzeba implementowac loadInitial - pierwsze ladowanie danych, request w repo(dobrze jest przekazac jako parametr params.requestedLoadSize ) ktory nastepnie przekazujemy do callback.onResult() loadAfter - nastepne ladowania danych jw. istotne jest utworzenie pol val currentPage = 1 val nextPage = currentPage + 1, ktore przekazujemy do callbacku i w loadAfter() przed kazdym requestem nadpisujemy( currentPage = params.key( bo key jest item== current page), nextpage = currentPage + 1) Utworzenie klasy ktora dziedziczy po DataSource.Factory utworzenie pola np. source ktory jest MutableLiveData () nadpisujemy onCreate tworzymy tam zmienna lokalna MyDataSource() a jej wartosc postujemy do source liveData, zwracamy zmienna lokalna Utworzenie metody w repo ktora zwraca LiveData > poprzez utworzenie LivePageDataBuilder.build() w aktywnosci zmieniamy z setowania listy do adaptera na uzywanie adapter.submitList(lista) w Adapterze zmieniamy z dziedziczenia na PagedListAdapter (DIFF_CALLBACK) (DIFF_CALLBACK) to DiffUtil.ItemCallback ktory ma 2 metody na sprawdzanie itemow (zazwyczaj po ID) i kontentu - porownanie obiektow do siebie (itemOld == itemNew) nie nadpisujemy getItemCount na onBindViewHolder uzywamy getItem() bo nie ma pola dla listy! PAGING Library in Room w dao object zwracamy DataSource.Factory zamiast livedata ta sama zmiana w repo w viewModel tworzymy livedata poprzez wywowalnie na obiekcie z repo .toLiveData(int pageSize) w aktywnosci zmieniamy z setowania listy do adaptera na uzywanie adapter.submitList(lista) w Adapterze zmieniamy z dziedziczenia na PagedListAdapter (DIFF_CALLBACK) (DIFF_CALLBACK) to DiffUtil.ItemCallback ktory ma 2 metody na sprawdzanie itemow (zazwyczaj po ID) i kontentu - porownanie obiektow do siebie (itemOld == itemNew) nie nadpisujemy getItemCount na onBindViewHolder uzywamy getItem() bo nie ma pola dla listy!","title":"Paging"},{"location":"programming/android/notes/#loaders","text":"Why not use loaders: https://medium.com/inloopx/its-time-to-ditch-loaders-in-android-6492616775f7","title":"Loaders"},{"location":"programming/android/notes/#dagger","text":"DAGGER2 Dependancy Injection - tworzenie obiektow poprzez dodatnie do konstrukora obiektow zaleznych, a nie tworzenie ich lokalnie Dagger2 sklada sie z nastepujacych elementow: - Module - klasa z adnotacja @Module, metody ktore dostarczaja obiekty z adnotacja @Provides i czesto @Singleton - jezeli obiekt jest ciezki w inicjializacji i moze byc uzyty ponownie, - Components - klej pomiedzy modulami a @Inject, to interfacae, ktory oznaczamy @Component(modules = {zaleznyModul1.class, zaleznyModul2.class}) metody interfacu maja za zadanie dostarczyc obiekty z modulow. Komponenty sa swiadome zakresu obiketow w module i jesli obiekty sa singletom mozna onaczyc kompent aby rowniez byc singletonem - @Inject - adnotacja ktora umozliwia dostarczenie przez Dagger2 potrzebnych obiektow, dodatkowo jezeli klasa X ktora sama jest tworzona w module i jej parameter Y jest tworzony w module, to ostatecznie nie musi byc tworzona w module :P Poniewaz dagger2 potrafi znalezc zaleznosci. W takim przypadku wystarczy oznaczyc konstrukor jako class X @Inject constructor(y: Y) , nalezy tez pamietac o tym by klasa wtedy byla @Singleton (jesli w module tak bylo) i nalezy usunac metody z modulu. na metodach @Inject uzywamy TYLKO aby zastapic this (tak powiedzial Jack Wharton) By dostac obiekty tworzymy jak najszybsciej Component w kodzie np. w klasie Aplikacji za pomoca DaggerNameOfComponent.builder()... .build() wtedy mamy dostep do metod z componentu","title":"Dagger"},{"location":"programming/android/notes/#picasso","text":"mozna uzywac posredniego serwera (np. thumbor) do stwierdzania jakiej wielkosci ma byc obrazek, wtedy dostajemy gotowej wielkosci obraz -> nie trzeba go zmniejszac na telefonie -> oszczednoscc CPU i baterii","title":"Picasso"},{"location":"programming/android/notes/#threading","text":"AsyncTask nie moze byc inner class UIControllerze bo bedzie trzymal referencje StrickMode - pozwala na wykrycie operacji I/O na MainThread CPUProfiler - displays all there are ANR trace file that you can get from the device ANR - moze odbyc sie tez przez inne thready jak jest lockResource (Deadlock) - resource wykorzystywany przez inny watek, ktory jest potrzebny w glowny np. przez synchronized(resource) a ten tam resource jest przekazany do asynctaska slow rendering jest nazywany jank Main thread (Ui Thread) zadaniem jest wykonywanie blokow pracy z thread-safe kolejki do moementu zakonczenie pracy. W tym zawiera sie: callbacki od lifecycle, wydarzenia od uzytkownia, od innych aplikacji i procesow, zarzadzanie viewsow (dlatego tez, nie daje sie zadnych referencji viewsow do innych watkow!- updated tylko poprzez wlascicicela Activity/Fragment), animacji System probuje sie przerysowac co kazde 16 milisekund - jesli jest za duzo rzeczy do zrobienia na Main threadzie to nie zdazy - jank -> bedzie musial skipowac framey - co oznacze ze ich nie odsiweza. AsyncTask(90% use caseow) nie moze byc inner(w kotlinie wystarczy usunaca inner) class Activity/Fragment bo bedzie trzymam referencje -> leak + jank onPreExecution odbywa sie na MainThreadzie doInBackground - juz na workerThreadzie onPostExecution - MainThread onCancel - MainThread AasynTask ma 1 worker thread HandlerThread - sklada sie z: - loopera kiedy praca do wykonania jest naprawde duza - zwracamy do UI Threada za pomoaca runOnUiThread ThreadPoolExecutor - tworzy thready na ktorych moze byc wykonana pracy duzej ilosci malej, maks ilosc watkow mozna pobrac z sytemu. IntentService - w momencie kiedy chcesz odpowiedziec intentowi, ale wisz ze praca troche zajmie a UI aktualnie jest w backgroundzie, Handler zly bo by czekal godzinamy na to az intent przyjdzie (a w miedzyczasie zjada resources) wszystkei te klasy same ustawiaja thread priority, defaultowo thread priority bedzie takie samo jak maina - 0 (DEFAULT) Foreground Threads - 95% execution time background Threads - 5% Jak aplikacja jest odpalana Android tworzy linux proces dla tej aplikacji z main threadem","title":"THREADING"},{"location":"programming/android/notes/#modularization","text":"androidx-dependency-tracker","title":"Modularization"},{"location":"programming/android/storage/","text":"Storage Android 11 and above restrictions apps can't use any longer WRITE_EXTERNAL_STORAGE","title":"Storage"},{"location":"programming/android/storage/#storage","text":"","title":"Storage"},{"location":"programming/android/storage/#android-11-and-above-restrictions","text":"apps can't use any longer WRITE_EXTERNAL_STORAGE","title":"Android 11 and above restrictions"},{"location":"programming/android/threading/","text":"Threading Loci 12A bedroom open doors - Thread taking of shirt - Looper & Queue taking of trousers - CPU operations basics Single-Tasking System lift the duvet up - Preemptive multitasking system snakes on bedsheet - Multiprocessing system bedsheet is clean - Visibility problem laying head on pillow - Atomicity problem Domi 'give it to me'! - Atomic value DragonBall fusion - Synchronized picking up the fibres - Happens-Before bin - Happens-Garbage Collector oil leaking from bulb Memory Leak I am going sleep, and I am standing in open bedroom doors I spot the yarn laying on the floor that which fibre goes string to bed. Next I take of my t-shirt and the letters fall out from under the shirt, small creature starts collecting them, the letters are floating around the creature in circles. In the same moment, the letters one by one are flying out by the window. New machines fly in, and I'm telling it in binary to help me take of my trousers. The machine is analyzing the code and starts taking of the trousers in steps. After each step machine screams the count of instructions completed. I am starting to lifting the duvet and I notice that I have 4 hands that are lifting the duvet. Movements of all hands is very robotic - each hand is moving in short sequences with lagging. Only one hand is moving at a specie time, this hand is changing color to glowing green based on at which hand I am looking at. After lifting the duvet I can see the fabrics from the yarn on the bedsheet. They are in red color, and it's start forming and moving like snakes parallel into different directions. Suddenly 2nd me tells me that he doesn't see the snakes, while I can still see the snakes. He explains to me that it's become of the transparent screen between me and the bed, I move to a side to change the angle and I can see the screen with dollars floating on the screen which were not visible before, no sneaks either. I lay down on the pillow which suddenly becomes visible atoms flying above my head. I'm catching the atoms with my hands but when I'm opening hands I can see only one atom. Domi enters the bedroom and screams \"give it to me\"!, I am saying that I can't give it right now. and I will give it her once I will finish playing with atom. Then we are both doing like in dragonball fusion screaming \"synchronized!\" and I'm passing an atom to Domi. Domi is holding an atom, and she doesn't see snakes, problem solved! I stared to picking up the fibres from yarn and I remind myself that this happened before. The fibre leads me to the bucket. When I am standing I can feel drops falling on my head, it's looks like an oil. I look up and I see bulb that is covered in oil which is dripping with oil. Thread single in process task creation in Android: extend thread class creating runnable and passing to constructor of Thread(myRunnable) advantage of 2nd approach is using \"composition over inheritance\" Android UI thread lives as long as app flowchart LR A[PROCESS] <---> B[\"APPLICATION + SANDBOX\"] Each process can host one or more tasks. In Android these are Threads. Threads share the execution environment with the parent process. They can communicate and exchange data. In android each program (application) gets its own task. This task is associated with isolated execution environment (sandbox). for each Android component ( Activity , Service , BroadcastReceiver , Loader ) you can specify android process in AndroidManifest.xml you can share process with different app when using same Linux User ID and same certificate. Handler - simply wraps same thread which loops \"forever\" as long as it's not stopped. Lopper.getMainLooper() - abstraction over UI thread which loops over runnable The safe way is to not create Handler s and lookers and only use: Handler(Looper.getMainLooper()) as this is the only way to get UI thread View.post(Runnable) & Activity.runOnUiThread(runnable) - can be used to execute code on UI thread Difference between Looper.getMainLopper().post() and runOnUiThread() : post() is adding a block to execute to a queue which means the block will be executed in future runOnUiThread() - if current thread is Main it will immediately execute code, otherwise it will fall back to post() Looper & queue Threads are using message queue as \"inbox\" for messages. Threads are using Looper to manage message queue. flowchart LR subgraph Thread direction LR subgraph Queue direction TB m1 --> m2 m2 --> m3 m3 --> mn end Queue --> Looper end Handler.Thread has a build in Looper. Handler itself is a \"postman\" that delivers messages (each message is attached to handler). Message has to be posted and consumed inside the looper. CPU Operations basics graph LR A[\"send instruction from system\"]--\"1000 1001 1101 1000\"--> B[\"CPU\"] \"Move the content of register (CPU internal storage) BX into register AX\" graph LR A[\"Operating System\"]--\"Machine code\"--> B[\"CPU\"] B --> C[\"Memory\"] & D[\"I/O devices\"] System = CPU + Operating System Single-Tasking system execute the machine code of one single task until the task terminates. It's not used in most popular systems. graph LR i0 --- i1 --- i2 ---i3--... ---in subgraph PC i1 end i0 - instruction PC, program counter - moves from one instruction to another Preemptive multitasking system graph LR subgraph task 2 j0 --- j1 --- j2 ---j3--... ---jn end subgraph task 1 i0 --- i1 --- i2 ---i3--... ---in end subgraph Program Counter pc--1-->i0 pc--2-->i1 pc--3-->j0 pc--4-->j1 pc--5-->i2 pc--6-->j2 end flowchart LR OS -.yield.-> i1 OS -.yield.-> j1 OS -.yield.->i2 OS -.yield.-> j2 subgraph CPU instruction executing direction TB i0 --> i1 --> j0 -->j1--> i2 --> j2 -->... end yielding - releasing the CPU by the Operating System. It allows other task to start using the CPU Pros: allows concurrent tasks guarantees system responsiveness cons: very complex system in the terms of creation. Used by majority of general purpose Operating Systems e.g. Android Cooperative multitasking system Similar to preemptive multitasking system, but it's the that itself that is responsible for yielding. Pros: allows concurrent execution of multiple tasks as yieldingly can happen thousands of ime on one second. Cons: one misbehaving task can claim resources for long time thus making the entire system unresponsive Multiprocessing system System with more than one CPU graph LR A[\"Operating System\"]--\"Machine code\"--> B[\"CPU\"] B --> C[\"Memory\"] & D[\"I/O devices\"] A--\"Machine code\"--> F[\"CPU\"] F --> H[\"Memory\"] & I[\"I/O devices\"] Pros: Allows for parallelism graph LR subgraph Concurrency parallelism end Multithreading decomposition of app logic into multiple concurrent tasks concurrency - tasks appear to run at the same time parallelism - tasks to run at the same time e.g. by using different core in CPU Visibility problem Having 2 threads, system can decide that particular thread don't need to access filed from memory, rather it can use value from cache. System does it for performance improvements. This can lead to situation where another thread is updating the value of the filed but first thread is not reading updating value but reads value from cache. sequenceDiagram participant Thread 1 participant Thread 2 participant Thread 1 Cache participant Memory Thread 1->> Memory: getMyInt() Memory -->> Thread 1: myInt = 0 Thread 1->> Thread 1 Cache: cache MyInt* = 0 Thread 2->> Memory: myInt = setMyInt(1) Memory --> Memory: myInt = 1 Thread 1->> Thread 1 Cache: getMyInt() Thread 1 Cache -->> Thread 1: myInt = 0 volatile (kotlin @Volatile ) && final keywords in java makes sure that thread will read and write value from/to memory. (Though it doesn't solve the atomicity problem mentioned below) @Volatile var counter: int = 0 Atomicity problem Multiple threads read the same value from memory e.g. myInt = 3 , and increment it because each thread had the same value at the beginning the new value is 4 instead of 3 + n, (where n is the number of threads). sequenceDiagram participant Thread 3 participant Thread 2 participant Thread 1 participant Memory Thread 1->> Memory: getMyInt() Thread 2->> Memory: getMyInt() Memory -->> Thread 1: myInt = 0 Memory -->> Thread 2: myInt = 0 Thread 1->> Thread 1: myInt++ Thread 2->> Thread 2: myInt++ Thread 1->> Memory: setMyInt(1) Thread 2->> Memory: setMyInt(1) Thread 3->> Memory: getMyInt() Memory -->> Thread 3: myInt = 1 When thread is doing \"read, modify, write\" non-other thread can access the same instance otherwise we have race condition. In case of \"race condition\" you are not guarantee the order in which particular statements will be run. Atomic atomic values = guarantees that only one thread can \"read, modify, write\" at the given time, all others threads have to wait. It does not guarantee that thread will not cache the value (but the thread should never read the value from cache). Synchronized synchronized (kotlin @Synchronized ) - allows to handle \"race condition\". @Synchronized fun incrementCounter() { counter++ } When 2 threads are calling method which has synchronized keyword, you are guaranteed that once the thread no. 1 finishes execution on synchronised only then thread no. 2 will be able to execute the code. note: it does not guarantee who will be next holder of monitor (it can be same thread) Metaphor - taking stick only the one that is currently holding the stick is able to talk, all the others have to wait. This is exactly the Lock \"monitor\" object. Only one thread at a time can hold it: synchronized (Lock) Pros: Guarantees atomicity and visibility cons: it's very complex, and it's easy to make a mistake performance as it blocks other threads, though it's not always significant (depends on the environment not really important on Android) Happens Before It is lower level concept than \"visibility\". Visibility is a function of established (or not) happens-before relationships between actions. 2 actions can have happens-before relationships if: First action is ordered before second action. First action happens before second First action is visible to second action Why we need happens-before? Even though we write our code ordered. In reality there is no guarantee of sequence when we have multithreading. Compilers, JVM or CPU can reorder sequence, unless we define the constraints e.g. happens-before. Rules: if only 1 thread then order in code will be respected if action x synchronizes* with action y Everything before thread.start() is visible for thread. * - includes: synchronized keyword, read and write volatile s, java.util.concurrent If we have volatile filed (which guarantees that thread will read value from memory) and later call to thread.start() we have happens-before relation. Therefore, thread will always be checking for the value of the variable in the memory. As field was create before the thread. Garbage Collector GC - System process which automatically reclaims memory by discarding objects that are no longer in use (not reachable) Root - object which is always consider by GC as reachable thus never cleaned by GC. Roots in Android App: 1. object referenced from static fields 2. Instances of application class (it's almost always the case) 3. Live threads Object reachability flow: flowchart LR A{\"is root?\"} --yes--> B[reachable] C --yes--> D{\"is any parent reachable?\"} D --yes--> B A --no--> C{is referenced?} C --no--> E[not reachable] D --no--> E style B fill:#0F0 style E fill:#F00 Circular Reference flowchart LR MyObject1 <---> MyObject2 Garbage Collector is able to recognize circular reference and knows that both object are not reachable, hence it will release memory for myObject1 and myObjet2 Each application can ask the system about how much memory is available for it by calling: getMemoryClass() Foreground application are less likely to be killed by system If application is Least-Recently-Used (so it's not in foreground, but in recently used) and system is running out of memory then it's starts killing from bot-to-top but also checks which takes the most memory and might kill it Memory Leak object that is no longer used but can't be Garbage Collected Memory assignment class MyActivity : Activity { lateinit var myRepo: Repo override fun onCreate() { myRepo = Repo() } } Memory model of the above code flowchart TB MyActivity --Reference--> MyRepo Each anonymous (which is inner class) have implicit reference to enclosing class objects. So creating anonymous thread in onCreate of Activity then starting thread and closing Activity will cause memory leak as long as thread is running, because thread has reference to Activity. Each thread is Root for GC, hence GC can't clear the memory of Activity - memory leak. Thread termination in Android: Allow to complete successfully by return in run() Return from run() in response to an error return from run() in response to external flag return from run() in response to interruption lateinit var leakingObject: LeakingObject override fun onCreateView(inflater: LayoutInflater, container: ViewGroup?, savedInstanceState: Bundle?): View? { leakingObject = LeakingObject(view) } It's leaking because every time on new assignment to LeakingObject, the old one will be held in memory without assignment as Long as it's attached to the root","title":"Threading"},{"location":"programming/android/threading/#threading","text":"","title":"Threading"},{"location":"programming/android/threading/#loci-12a-bedroom","text":"open doors - Thread taking of shirt - Looper & Queue taking of trousers - CPU operations basics Single-Tasking System lift the duvet up - Preemptive multitasking system snakes on bedsheet - Multiprocessing system bedsheet is clean - Visibility problem laying head on pillow - Atomicity problem Domi 'give it to me'! - Atomic value DragonBall fusion - Synchronized picking up the fibres - Happens-Before bin - Happens-Garbage Collector oil leaking from bulb Memory Leak I am going sleep, and I am standing in open bedroom doors I spot the yarn laying on the floor that which fibre goes string to bed. Next I take of my t-shirt and the letters fall out from under the shirt, small creature starts collecting them, the letters are floating around the creature in circles. In the same moment, the letters one by one are flying out by the window. New machines fly in, and I'm telling it in binary to help me take of my trousers. The machine is analyzing the code and starts taking of the trousers in steps. After each step machine screams the count of instructions completed. I am starting to lifting the duvet and I notice that I have 4 hands that are lifting the duvet. Movements of all hands is very robotic - each hand is moving in short sequences with lagging. Only one hand is moving at a specie time, this hand is changing color to glowing green based on at which hand I am looking at. After lifting the duvet I can see the fabrics from the yarn on the bedsheet. They are in red color, and it's start forming and moving like snakes parallel into different directions. Suddenly 2nd me tells me that he doesn't see the snakes, while I can still see the snakes. He explains to me that it's become of the transparent screen between me and the bed, I move to a side to change the angle and I can see the screen with dollars floating on the screen which were not visible before, no sneaks either. I lay down on the pillow which suddenly becomes visible atoms flying above my head. I'm catching the atoms with my hands but when I'm opening hands I can see only one atom. Domi enters the bedroom and screams \"give it to me\"!, I am saying that I can't give it right now. and I will give it her once I will finish playing with atom. Then we are both doing like in dragonball fusion screaming \"synchronized!\" and I'm passing an atom to Domi. Domi is holding an atom, and she doesn't see snakes, problem solved! I stared to picking up the fibres from yarn and I remind myself that this happened before. The fibre leads me to the bucket. When I am standing I can feel drops falling on my head, it's looks like an oil. I look up and I see bulb that is covered in oil which is dripping with oil.","title":"Loci 12A bedroom"},{"location":"programming/android/threading/#thread","text":"single in process task creation in Android: extend thread class creating runnable and passing to constructor of Thread(myRunnable) advantage of 2nd approach is using \"composition over inheritance\" Android UI thread lives as long as app flowchart LR A[PROCESS] <---> B[\"APPLICATION + SANDBOX\"] Each process can host one or more tasks. In Android these are Threads. Threads share the execution environment with the parent process. They can communicate and exchange data. In android each program (application) gets its own task. This task is associated with isolated execution environment (sandbox). for each Android component ( Activity , Service , BroadcastReceiver , Loader ) you can specify android process in AndroidManifest.xml you can share process with different app when using same Linux User ID and same certificate. Handler - simply wraps same thread which loops \"forever\" as long as it's not stopped. Lopper.getMainLooper() - abstraction over UI thread which loops over runnable The safe way is to not create Handler s and lookers and only use: Handler(Looper.getMainLooper()) as this is the only way to get UI thread View.post(Runnable) & Activity.runOnUiThread(runnable) - can be used to execute code on UI thread Difference between Looper.getMainLopper().post() and runOnUiThread() : post() is adding a block to execute to a queue which means the block will be executed in future runOnUiThread() - if current thread is Main it will immediately execute code, otherwise it will fall back to post()","title":"Thread"},{"location":"programming/android/threading/#looper-queue","text":"Threads are using message queue as \"inbox\" for messages. Threads are using Looper to manage message queue. flowchart LR subgraph Thread direction LR subgraph Queue direction TB m1 --> m2 m2 --> m3 m3 --> mn end Queue --> Looper end Handler.Thread has a build in Looper. Handler itself is a \"postman\" that delivers messages (each message is attached to handler). Message has to be posted and consumed inside the looper.","title":"Looper &amp; queue"},{"location":"programming/android/threading/#cpu-operations-basics","text":"graph LR A[\"send instruction from system\"]--\"1000 1001 1101 1000\"--> B[\"CPU\"] \"Move the content of register (CPU internal storage) BX into register AX\" graph LR A[\"Operating System\"]--\"Machine code\"--> B[\"CPU\"] B --> C[\"Memory\"] & D[\"I/O devices\"] System = CPU + Operating System","title":"CPU Operations basics"},{"location":"programming/android/threading/#single-tasking-system","text":"execute the machine code of one single task until the task terminates. It's not used in most popular systems. graph LR i0 --- i1 --- i2 ---i3--... ---in subgraph PC i1 end i0 - instruction PC, program counter - moves from one instruction to another","title":"Single-Tasking system"},{"location":"programming/android/threading/#preemptive-multitasking-system","text":"graph LR subgraph task 2 j0 --- j1 --- j2 ---j3--... ---jn end subgraph task 1 i0 --- i1 --- i2 ---i3--... ---in end subgraph Program Counter pc--1-->i0 pc--2-->i1 pc--3-->j0 pc--4-->j1 pc--5-->i2 pc--6-->j2 end flowchart LR OS -.yield.-> i1 OS -.yield.-> j1 OS -.yield.->i2 OS -.yield.-> j2 subgraph CPU instruction executing direction TB i0 --> i1 --> j0 -->j1--> i2 --> j2 -->... end yielding - releasing the CPU by the Operating System. It allows other task to start using the CPU Pros: allows concurrent tasks guarantees system responsiveness cons: very complex system in the terms of creation. Used by majority of general purpose Operating Systems e.g. Android","title":"Preemptive multitasking system"},{"location":"programming/android/threading/#cooperative-multitasking-system","text":"Similar to preemptive multitasking system, but it's the that itself that is responsible for yielding. Pros: allows concurrent execution of multiple tasks as yieldingly can happen thousands of ime on one second. Cons: one misbehaving task can claim resources for long time thus making the entire system unresponsive","title":"Cooperative multitasking system"},{"location":"programming/android/threading/#multiprocessing-system","text":"System with more than one CPU graph LR A[\"Operating System\"]--\"Machine code\"--> B[\"CPU\"] B --> C[\"Memory\"] & D[\"I/O devices\"] A--\"Machine code\"--> F[\"CPU\"] F --> H[\"Memory\"] & I[\"I/O devices\"] Pros: Allows for parallelism graph LR subgraph Concurrency parallelism end","title":"Multiprocessing system"},{"location":"programming/android/threading/#multithreading","text":"decomposition of app logic into multiple concurrent tasks concurrency - tasks appear to run at the same time parallelism - tasks to run at the same time e.g. by using different core in CPU","title":"Multithreading"},{"location":"programming/android/threading/#visibility-problem","text":"Having 2 threads, system can decide that particular thread don't need to access filed from memory, rather it can use value from cache. System does it for performance improvements. This can lead to situation where another thread is updating the value of the filed but first thread is not reading updating value but reads value from cache. sequenceDiagram participant Thread 1 participant Thread 2 participant Thread 1 Cache participant Memory Thread 1->> Memory: getMyInt() Memory -->> Thread 1: myInt = 0 Thread 1->> Thread 1 Cache: cache MyInt* = 0 Thread 2->> Memory: myInt = setMyInt(1) Memory --> Memory: myInt = 1 Thread 1->> Thread 1 Cache: getMyInt() Thread 1 Cache -->> Thread 1: myInt = 0 volatile (kotlin @Volatile ) && final keywords in java makes sure that thread will read and write value from/to memory. (Though it doesn't solve the atomicity problem mentioned below) @Volatile var counter: int = 0","title":"Visibility problem"},{"location":"programming/android/threading/#atomicity-problem","text":"Multiple threads read the same value from memory e.g. myInt = 3 , and increment it because each thread had the same value at the beginning the new value is 4 instead of 3 + n, (where n is the number of threads). sequenceDiagram participant Thread 3 participant Thread 2 participant Thread 1 participant Memory Thread 1->> Memory: getMyInt() Thread 2->> Memory: getMyInt() Memory -->> Thread 1: myInt = 0 Memory -->> Thread 2: myInt = 0 Thread 1->> Thread 1: myInt++ Thread 2->> Thread 2: myInt++ Thread 1->> Memory: setMyInt(1) Thread 2->> Memory: setMyInt(1) Thread 3->> Memory: getMyInt() Memory -->> Thread 3: myInt = 1 When thread is doing \"read, modify, write\" non-other thread can access the same instance otherwise we have race condition. In case of \"race condition\" you are not guarantee the order in which particular statements will be run.","title":"Atomicity problem"},{"location":"programming/android/threading/#atomic","text":"atomic values = guarantees that only one thread can \"read, modify, write\" at the given time, all others threads have to wait. It does not guarantee that thread will not cache the value (but the thread should never read the value from cache).","title":"Atomic"},{"location":"programming/android/threading/#synchronized","text":"synchronized (kotlin @Synchronized ) - allows to handle \"race condition\". @Synchronized fun incrementCounter() { counter++ } When 2 threads are calling method which has synchronized keyword, you are guaranteed that once the thread no. 1 finishes execution on synchronised only then thread no. 2 will be able to execute the code. note: it does not guarantee who will be next holder of monitor (it can be same thread) Metaphor - taking stick only the one that is currently holding the stick is able to talk, all the others have to wait. This is exactly the Lock \"monitor\" object. Only one thread at a time can hold it: synchronized (Lock) Pros: Guarantees atomicity and visibility cons: it's very complex, and it's easy to make a mistake performance as it blocks other threads, though it's not always significant (depends on the environment not really important on Android)","title":"Synchronized"},{"location":"programming/android/threading/#happens-before","text":"It is lower level concept than \"visibility\". Visibility is a function of established (or not) happens-before relationships between actions. 2 actions can have happens-before relationships if: First action is ordered before second action. First action happens before second First action is visible to second action Why we need happens-before? Even though we write our code ordered. In reality there is no guarantee of sequence when we have multithreading. Compilers, JVM or CPU can reorder sequence, unless we define the constraints e.g. happens-before. Rules: if only 1 thread then order in code will be respected if action x synchronizes* with action y Everything before thread.start() is visible for thread. * - includes: synchronized keyword, read and write volatile s, java.util.concurrent If we have volatile filed (which guarantees that thread will read value from memory) and later call to thread.start() we have happens-before relation. Therefore, thread will always be checking for the value of the variable in the memory. As field was create before the thread.","title":"Happens Before"},{"location":"programming/android/threading/#garbage-collector","text":"GC - System process which automatically reclaims memory by discarding objects that are no longer in use (not reachable) Root - object which is always consider by GC as reachable thus never cleaned by GC. Roots in Android App: 1. object referenced from static fields 2. Instances of application class (it's almost always the case) 3. Live threads Object reachability flow: flowchart LR A{\"is root?\"} --yes--> B[reachable] C --yes--> D{\"is any parent reachable?\"} D --yes--> B A --no--> C{is referenced?} C --no--> E[not reachable] D --no--> E style B fill:#0F0 style E fill:#F00 Circular Reference flowchart LR MyObject1 <---> MyObject2 Garbage Collector is able to recognize circular reference and knows that both object are not reachable, hence it will release memory for myObject1 and myObjet2 Each application can ask the system about how much memory is available for it by calling: getMemoryClass() Foreground application are less likely to be killed by system If application is Least-Recently-Used (so it's not in foreground, but in recently used) and system is running out of memory then it's starts killing from bot-to-top but also checks which takes the most memory and might kill it","title":"Garbage Collector"},{"location":"programming/android/threading/#memory-leak","text":"object that is no longer used but can't be Garbage Collected Memory assignment class MyActivity : Activity { lateinit var myRepo: Repo override fun onCreate() { myRepo = Repo() } } Memory model of the above code flowchart TB MyActivity --Reference--> MyRepo Each anonymous (which is inner class) have implicit reference to enclosing class objects. So creating anonymous thread in onCreate of Activity then starting thread and closing Activity will cause memory leak as long as thread is running, because thread has reference to Activity. Each thread is Root for GC, hence GC can't clear the memory of Activity - memory leak. Thread termination in Android: Allow to complete successfully by return in run() Return from run() in response to an error return from run() in response to external flag return from run() in response to interruption lateinit var leakingObject: LeakingObject override fun onCreateView(inflater: LayoutInflater, container: ViewGroup?, savedInstanceState: Bundle?): View? { leakingObject = LeakingObject(view) } It's leaking because every time on new assignment to LeakingObject, the old one will be held in memory without assignment as Long as it's attached to the root","title":"Memory Leak"},{"location":"programming/android/views/","text":"constrain layout - wrap_content will always allow all items to be displayed, while 0dp will take available space If you have some view+ recycler view, and both have to be scrollable then view needs to be a header/footer of recycler view recycler view can have cache for viewHolder before they are needed to use to provide smooth experience RecyclerViewyou can setup layoutManager inside xml wszystko powinno byc enkapsulowane - viewHolder nie ma referencji bezposrednio do ViewHoldera StackView allows displaying view as stacked with animation to remove them View has a fun animate() which allows to animate it You can pass ResId directly to view.text Androix Webkit suppors dark mode ViewPager2 allows vertical scroll, and is easier to use NAVIGATION: Navigation listeners - allows to control locking navigation view ANIMATIONS: Exit Transition - played for UIcontroller that will be taken off from the screen Enter Transition - played for UIController that will be displayed on the screen pop Exit Transition - played for UiController that will be takaen off from the screen because of back button click pop Enter Transition - played for UIController that will be displayd on the screen because of back button click","title":"Views"},{"location":"programming/courses/algorithms/algorithms/","text":"Princeton university algorithms part 1 1.5 Union Find Dynamic connectivity Given a set of N objects: Union command: connect two objects (commonly known as p and q) Find/connected query: is there a patch connecting the two objects? e.g. is there a connectivity between 0 and 6? union(1, 2) union(3, 4) union(5, 6) connected(0,6) - NO union(7, 8) union(7, 9) union(2, 8) union(0, 5) connected(0,6) - YES union(1, 9) flowchart LR subgraph connected component direction LR 5 --> 6 0 --> 5 end 3 --> 4 1 --> 2 7 --> 8 7 --> 9 2 --> 8 1 --> 9 Connected components - maximal set of object that are mutually connected it the above examples we have 3 components: { 0 } { 1 4 5 } { 2 3 6 7 } Implementations Quick Find (eager algorithm) Data structure. \u30fbInteger array id[] of length N. \u30fbInterpretation: p and q are connected iff they have the same id given an array: [0,1,1,8,8,0,0,1,8,8] - known as id[] we connect pairs by using: index as p value as q in the above example it gives as below connected components flowchart LR 0 --> 0 1 --> 1 2 --> 1 3 --> 8 4 --> 8 5 --> 0 6 --> 0 7 --> 1 8 --> 8 9 --> 8 To merge components containing p and q change all entire whose id equals id[p to id[q]] In above case, if we are doing a union of 6 and 1 then all values for component {0, 5, 6 } needs to change id to used in the second component - which is 1. array after change [ 1 ,1,1,8,8, 1 , 1 ,1,8,8] - known as id[] The change is always based on order of the IDs - we change the first one to the second one Union is too expensive. It takes N 2 array accesses to process a sequence of N union commands on N objects. Quick-find defect. \u30fbUnion too expensive (N array accesses). \u30fbTrees are flat, but too expensive to keep them fla Quick-union - lazy approach Integer array id[] of size N interpretation: id[i] is parent of i (so we have set of trees) Root of i is id[id[...id[id[i]...]]] id[] = [0,9,6,5,4,2,6,1,0,5] id[i] --- i flowchart TB 0 --- 0 9 --- 1 6 --- 2 5 --- 3 4 --- 4 2 --- 5 6 --- 6 1 --- 7 0 --- 8 5 --- 9 6 is a root of the tree containing {2,5,3,9,1,7} Find - check if p and q have the same root. Union - to merge components containing p and q set the id of p's root to the id of the q's root. We need to change only 1 value (root of 'p') in the array to Union components together. So the new component is always pointing to the root even if the union was: child --- child or child --- root Quick-union defect. \u30fbTrees can get tall. \u30fbFind too expensive (could be N array accesses) Improvement 1: weighting Weighted quick-union. \u30fbModify quick-union to avoid tall trees. \u30fbKeep track of size of each tree (number of objects). \u30fbBalance by linking root of smaller tree to root of larger tree. having an array n = 4 with bellow operations union(0,3) flowchart TB 3 --- 0 1 2 and next operation is: union(1, 0) instead of attaching {3, 0} to {1} we attach {1} to {3,0} as those are the rules in weighting (attach smaller tree root to larger tree root) flowchart TB 3 --- 0 3 --- 1 2 Proposition. Depth of any node x is at most lg N. Pf. When does depth of x increase? Increases by 1 when tree T 1 containing x is merged into another tree T 2. \u30fbThe size of the tree containing x at least doubles since | T 2 | \u2265 | T 1 |. \u30fbSize of tree containing x can double at most lg N times. Why? If you start with 1 and double log N times, you get N and there's only N nodes in the tree. So, that's a sketch of a proof that the depth of any node x is at most log base two of N. improvement 2: path compression Quick union with path compression. Just after computing the root of p, set the id of each examined node to point to that root. example: having: flowchart TB 0 --- 1 1 --- 2 1 --- 3 1 --- 8 4 --- 5 4 --- 6 6 --- 7 when union(0, 6) THEN 1st step is adding as in weighted flowchart TB 0 --- 1 1 --- 2 1 --- 3 1 --- 8 0 --- 4 4 --- 5 4 --- 6 6 --- 7 after path compression flowchart TB 0 --- 1 1 --- 2 1 --- 3 1 --- 8 0 --- 4 4 --- 5 0 --- 6 6 --- 7 Bottom line. Weighted quick union (with path compression) makes it possible to solve problems that could not otherwise be addressed. \u30fbWQUPC (Weighted quick union (with path compression))reduces time from 30 years to 6 seconds. \u30fbSupercomputer won't help much; good algorithm enables solution. Union-Find applications Percolation a model for many physical systems: N-by-N grid of sites Each site is open with probability p (or blocked with probability 1-p) System percolates iff (if and only f) top and bottom are connected by open sites How to check whether an N-by-N system percolates? \u30fbCreate an object for each site and name them 0 to N 2 \u2013 1. \u30fbSites are in same component if connected by open sites. \u30fbPercolates iff any site on bottom row is connected to site on top row. When opening one new site in the percolation simulation, how many times is union() called? It is called for each neighboring site that is already open. There are 4 possible neighbors, but some of them may not already be open. Analysing algorithms Running time (performance) of algorithm reasons: - avoid performance bugs - predict performance compare algorithms provide guarantees understand theoretical basis Use scientific method to understand performance Observe some feature of the natural world Hypothesize a model that is consistent with the observations Predict events using the hypothesis Verify the predictions by making further observations Validate by repeating until the hypothesis and observations agree Principles: Experiments must be reproducible Hypotheses must be falsifiable Question: Suppose that n equals 1 million. Approximately how much faster is an algorithm that performs n lg n operations versus one that performs n^2 operations? Recall that lg is the base-2 logarithm function. n^2 / nlgn // /n n / lgn // 10^6 / lg 10^6 2^x = 10^6 x~20 10^6 / 20 = 50 000 Approximately 50 000x faster 3-SUM Given N distinct integers, how many triples sum to exactly zero? Log-log plot - allows you to receive straight line which help you to understand what is the slope of the line. Power low - each point on the straight line is equal to aN^b lg(T(N)) = b Lg N + c // to power? T(N) = fa N^b (where a = 2^c) system independent effects: algorithm Input data system dependent effects: Hardware Software System Type of analyses best case worst case average case Theory of algorithms establish difficulty of a problem develop optimal approach e.g. 1-SUM \"Is there a 0 in the array?\" Upper Bound - A specific algorithm Ex. Brute-force algorithm for 1-sum: look at every array entry Running time of the optimal algorithm for 1-Sum is O(N) Lower bound - Proof that no algorithm can do better Ex. have to examine all N entries (any unexamined one might be 0) Running time of optimal algorithm for 1-sum is M(N) Recall that big-Oh notation provides only an upper bound on the growth rate of a function as nn gets large. In this course, we primarily use tilde notation because it more accurately describes the function\u2014it provides both an upper and lower bound on the function as well as the coefficient of the leading term. stacks stack - LIFO principle queue - FIFO principle stack often is implemented either: with usage of linked list by creating a class called Node. class LinkedStackOfStrings { private Node first = null; private class Node { String item; Node next; } public boolean isEmpty() { return first == null; } public void push(String name) { Node oldFirst = first; first = new Node(); first.item = name; first.next = oldFirst; } public String pop() { String item = first.item; first = oldFirst.next; return item; } } with usage of Array - with fixed capacity public class FixedCapacityStackOfStrings { private String[] s; private int N = 0; /*a cheat because often it's required that client doesn't know the capacity, how to solve? resizing */ public FixedCapacityStackOfStrings(int capacity) { s = new String[capacity]; } public boolean isEmpty() { return N == 0; } public void push(String name) { s[N++] = name; } public String pop() { String name = S[--N]; s[N] == null; // remove reference to allow GC for recollection of memory return name; } } with usage of resizing Array public class FixedCapacityStackOfStrings { private String[] s = new String[10]; private int N = 0; /*a cheat because often it's required that client doesn't know the capacity, how to solve? resizing */ public FixedCapacityStackOfStrings() { } public boolean isEmpty() { return N == 0; } public void push(String name) { if (s.length == N) { resize(2 * s.length); } s[N++] = name; } public String pop() { String name = S[--N]; s[N] == null; // remove reference to allow GC for recollection of memory return name; } /** @noinspection RedundantSuppression*/ private void resize(int size) { String[] copy = new String[size]; //noinspection ManualArrayCopy for (int i = 0; i < s.length; i++) { copy[i] = s[i]; } s = copy; } } queue class LinkedQueueOfStrings { private Node first = null; private Node last = null; private class Node { String item; Node next; } public boolean isEmpty() { return first == null; } public void enqueue(String name) { Node oldLast = last; last = new Node(); last.item = name; last.next = null; if (first == null) first = last; else oldLast.next = last; } public String dequeue() { String item = first.item; first = first.next; if (isEmpty()) last = null; return item; } } Iteration Q:What is Java Iterable ? A: has a method that returns an Iterator . Q: What is an Iterator ? A: Has methods hasNext() and next() also remove() (but using it is risky) Be carefully with using libraries if you don't understand what is the performance of these. e.g. java.util.Stack returns items in FIFO order","title":"Princeton university algorithms part 1"},{"location":"programming/courses/algorithms/algorithms/#princeton-university-algorithms-part-1","text":"","title":"Princeton university algorithms part 1"},{"location":"programming/courses/algorithms/algorithms/#15-union-find","text":"Dynamic connectivity Given a set of N objects: Union command: connect two objects (commonly known as p and q) Find/connected query: is there a patch connecting the two objects? e.g. is there a connectivity between 0 and 6? union(1, 2) union(3, 4) union(5, 6) connected(0,6) - NO union(7, 8) union(7, 9) union(2, 8) union(0, 5) connected(0,6) - YES union(1, 9) flowchart LR subgraph connected component direction LR 5 --> 6 0 --> 5 end 3 --> 4 1 --> 2 7 --> 8 7 --> 9 2 --> 8 1 --> 9 Connected components - maximal set of object that are mutually connected it the above examples we have 3 components: { 0 } { 1 4 5 } { 2 3 6 7 }","title":"1.5 Union Find"},{"location":"programming/courses/algorithms/algorithms/#implementations","text":"","title":"Implementations"},{"location":"programming/courses/algorithms/algorithms/#quick-find-eager-algorithm","text":"Data structure. \u30fbInteger array id[] of length N. \u30fbInterpretation: p and q are connected iff they have the same id given an array: [0,1,1,8,8,0,0,1,8,8] - known as id[] we connect pairs by using: index as p value as q in the above example it gives as below connected components flowchart LR 0 --> 0 1 --> 1 2 --> 1 3 --> 8 4 --> 8 5 --> 0 6 --> 0 7 --> 1 8 --> 8 9 --> 8 To merge components containing p and q change all entire whose id equals id[p to id[q]] In above case, if we are doing a union of 6 and 1 then all values for component {0, 5, 6 } needs to change id to used in the second component - which is 1. array after change [ 1 ,1,1,8,8, 1 , 1 ,1,8,8] - known as id[] The change is always based on order of the IDs - we change the first one to the second one Union is too expensive. It takes N 2 array accesses to process a sequence of N union commands on N objects. Quick-find defect. \u30fbUnion too expensive (N array accesses). \u30fbTrees are flat, but too expensive to keep them fla","title":"Quick Find (eager algorithm)"},{"location":"programming/courses/algorithms/algorithms/#quick-union-lazy-approach","text":"Integer array id[] of size N interpretation: id[i] is parent of i (so we have set of trees) Root of i is id[id[...id[id[i]...]]] id[] = [0,9,6,5,4,2,6,1,0,5] id[i] --- i flowchart TB 0 --- 0 9 --- 1 6 --- 2 5 --- 3 4 --- 4 2 --- 5 6 --- 6 1 --- 7 0 --- 8 5 --- 9 6 is a root of the tree containing {2,5,3,9,1,7} Find - check if p and q have the same root. Union - to merge components containing p and q set the id of p's root to the id of the q's root. We need to change only 1 value (root of 'p') in the array to Union components together. So the new component is always pointing to the root even if the union was: child --- child or child --- root Quick-union defect. \u30fbTrees can get tall. \u30fbFind too expensive (could be N array accesses)","title":"Quick-union - lazy approach"},{"location":"programming/courses/algorithms/algorithms/#improvement-1-weighting","text":"Weighted quick-union. \u30fbModify quick-union to avoid tall trees. \u30fbKeep track of size of each tree (number of objects). \u30fbBalance by linking root of smaller tree to root of larger tree. having an array n = 4 with bellow operations union(0,3) flowchart TB 3 --- 0 1 2 and next operation is: union(1, 0) instead of attaching {3, 0} to {1} we attach {1} to {3,0} as those are the rules in weighting (attach smaller tree root to larger tree root) flowchart TB 3 --- 0 3 --- 1 2 Proposition. Depth of any node x is at most lg N. Pf. When does depth of x increase? Increases by 1 when tree T 1 containing x is merged into another tree T 2. \u30fbThe size of the tree containing x at least doubles since | T 2 | \u2265 | T 1 |. \u30fbSize of tree containing x can double at most lg N times. Why? If you start with 1 and double log N times, you get N and there's only N nodes in the tree. So, that's a sketch of a proof that the depth of any node x is at most log base two of N.","title":"Improvement 1: weighting"},{"location":"programming/courses/algorithms/algorithms/#improvement-2-path-compression","text":"Quick union with path compression. Just after computing the root of p, set the id of each examined node to point to that root. example: having: flowchart TB 0 --- 1 1 --- 2 1 --- 3 1 --- 8 4 --- 5 4 --- 6 6 --- 7 when union(0, 6) THEN 1st step is adding as in weighted flowchart TB 0 --- 1 1 --- 2 1 --- 3 1 --- 8 0 --- 4 4 --- 5 4 --- 6 6 --- 7 after path compression flowchart TB 0 --- 1 1 --- 2 1 --- 3 1 --- 8 0 --- 4 4 --- 5 0 --- 6 6 --- 7 Bottom line. Weighted quick union (with path compression) makes it possible to solve problems that could not otherwise be addressed. \u30fbWQUPC (Weighted quick union (with path compression))reduces time from 30 years to 6 seconds. \u30fbSupercomputer won't help much; good algorithm enables solution.","title":"improvement 2: path compression"},{"location":"programming/courses/algorithms/algorithms/#union-find-applications","text":"","title":"Union-Find applications"},{"location":"programming/courses/algorithms/algorithms/#percolation","text":"a model for many physical systems: N-by-N grid of sites Each site is open with probability p (or blocked with probability 1-p) System percolates iff (if and only f) top and bottom are connected by open sites How to check whether an N-by-N system percolates? \u30fbCreate an object for each site and name them 0 to N 2 \u2013 1. \u30fbSites are in same component if connected by open sites. \u30fbPercolates iff any site on bottom row is connected to site on top row. When opening one new site in the percolation simulation, how many times is union() called? It is called for each neighboring site that is already open. There are 4 possible neighbors, but some of them may not already be open.","title":"Percolation"},{"location":"programming/courses/algorithms/algorithms/#analysing-algorithms","text":"Running time (performance) of algorithm reasons:","title":"Analysing algorithms"},{"location":"programming/courses/algorithms/algorithms/#-avoid-performance-bugs","text":"- predict performance compare algorithms provide guarantees understand theoretical basis Use scientific method to understand performance Observe some feature of the natural world Hypothesize a model that is consistent with the observations Predict events using the hypothesis Verify the predictions by making further observations Validate by repeating until the hypothesis and observations agree Principles: Experiments must be reproducible Hypotheses must be falsifiable Question: Suppose that n equals 1 million. Approximately how much faster is an algorithm that performs n lg n operations versus one that performs n^2 operations? Recall that lg is the base-2 logarithm function. n^2 / nlgn // /n n / lgn // 10^6 / lg 10^6 2^x = 10^6 x~20 10^6 / 20 = 50 000 Approximately 50 000x faster","title":"- avoid performance bugs"},{"location":"programming/courses/algorithms/algorithms/#3-sum","text":"Given N distinct integers, how many triples sum to exactly zero? Log-log plot - allows you to receive straight line which help you to understand what is the slope of the line. Power low - each point on the straight line is equal to aN^b lg(T(N)) = b Lg N + c // to power? T(N) = fa N^b (where a = 2^c) system independent effects: algorithm Input data system dependent effects: Hardware Software System","title":"3-SUM"},{"location":"programming/courses/algorithms/algorithms/#type-of-analyses","text":"best case worst case average case Theory of algorithms establish difficulty of a problem develop optimal approach e.g. 1-SUM \"Is there a 0 in the array?\" Upper Bound - A specific algorithm Ex. Brute-force algorithm for 1-sum: look at every array entry Running time of the optimal algorithm for 1-Sum is O(N) Lower bound - Proof that no algorithm can do better Ex. have to examine all N entries (any unexamined one might be 0) Running time of optimal algorithm for 1-sum is M(N) Recall that big-Oh notation provides only an upper bound on the growth rate of a function as nn gets large. In this course, we primarily use tilde notation because it more accurately describes the function\u2014it provides both an upper and lower bound on the function as well as the coefficient of the leading term.","title":"Type of analyses"},{"location":"programming/courses/algorithms/algorithms/#stacks","text":"stack - LIFO principle queue - FIFO principle stack often is implemented either: with usage of linked list by creating a class called Node. class LinkedStackOfStrings { private Node first = null; private class Node { String item; Node next; } public boolean isEmpty() { return first == null; } public void push(String name) { Node oldFirst = first; first = new Node(); first.item = name; first.next = oldFirst; } public String pop() { String item = first.item; first = oldFirst.next; return item; } } with usage of Array - with fixed capacity public class FixedCapacityStackOfStrings { private String[] s; private int N = 0; /*a cheat because often it's required that client doesn't know the capacity, how to solve? resizing */ public FixedCapacityStackOfStrings(int capacity) { s = new String[capacity]; } public boolean isEmpty() { return N == 0; } public void push(String name) { s[N++] = name; } public String pop() { String name = S[--N]; s[N] == null; // remove reference to allow GC for recollection of memory return name; } } with usage of resizing Array public class FixedCapacityStackOfStrings { private String[] s = new String[10]; private int N = 0; /*a cheat because often it's required that client doesn't know the capacity, how to solve? resizing */ public FixedCapacityStackOfStrings() { } public boolean isEmpty() { return N == 0; } public void push(String name) { if (s.length == N) { resize(2 * s.length); } s[N++] = name; } public String pop() { String name = S[--N]; s[N] == null; // remove reference to allow GC for recollection of memory return name; } /** @noinspection RedundantSuppression*/ private void resize(int size) { String[] copy = new String[size]; //noinspection ManualArrayCopy for (int i = 0; i < s.length; i++) { copy[i] = s[i]; } s = copy; } }","title":"stacks"},{"location":"programming/courses/algorithms/algorithms/#queue","text":"class LinkedQueueOfStrings { private Node first = null; private Node last = null; private class Node { String item; Node next; } public boolean isEmpty() { return first == null; } public void enqueue(String name) { Node oldLast = last; last = new Node(); last.item = name; last.next = null; if (first == null) first = last; else oldLast.next = last; } public String dequeue() { String item = first.item; first = first.next; if (isEmpty()) last = null; return item; } }","title":"queue"},{"location":"programming/courses/algorithms/algorithms/#iteration","text":"Q:What is Java Iterable ? A: has a method that returns an Iterator . Q: What is an Iterator ? A: Has methods hasNext() and next() also remove() (but using it is risky) Be carefully with using libraries if you don't understand what is the performance of these. e.g. java.util.Stack returns items in FIFO order","title":"Iteration"},{"location":"programming/kotlin/coroutines/","text":"Coroutines are: asynchronous - you have to wait for result non-blocking - it doesn't block the thread sequential code - no callback are required suspend - key word for coroutines - waits until job will return, though different work can be processed on same thread Coroutine needs: - Job - cancellable object with lifecycle that completes - Dispatcher - sends coroutines to different threads (like rx java) scheduleOn() - Scope - combines information including Job and Dispatcher. Creation: CoroutineScope(dispatcher + job) Job is just a representation of coroutine. There is no coroutine without job. Coroutine scopes are just boxes in which coroutines run (wrapper around CoroutineContext ). It needs to have a root Job! CoroutineContext is a Set of elements. \"most of the time coroutine scope and context are the same thing\" Dispatchers: Main - is adding a block to execute to a queue which means the block will be executed in future Main.immediate - if current thread is Main it will immediately execute code, otherwise it will fall back to Main Default - is using 2 or more threads I.O. is using 64 or more threads Unconfinead - is using the same thread as one which is started from If dispatcher is not specify in scope nor as argument then Dispatchers.Default wil be used. Dispatchers are using threads under the hood. withContext(Dispatchers.Default + NonCancellable) {...} adding NonCancellable guarantees that code inside will not be cancelled when parent coroutine will throw the exception CoroutineContext.ensureActive() is checking if hob is Active otherwise throws cancellation exception CoroutineScope.coroutineContext.cancel(children) allows to cancel all jobs inside coroutine scope","title":"Coroutines"},{"location":"programming/kotlin/coroutines/#coroutines","text":"are: asynchronous - you have to wait for result non-blocking - it doesn't block the thread sequential code - no callback are required suspend - key word for coroutines - waits until job will return, though different work can be processed on same thread Coroutine needs: - Job - cancellable object with lifecycle that completes - Dispatcher - sends coroutines to different threads (like rx java) scheduleOn() - Scope - combines information including Job and Dispatcher. Creation: CoroutineScope(dispatcher + job) Job is just a representation of coroutine. There is no coroutine without job. Coroutine scopes are just boxes in which coroutines run (wrapper around CoroutineContext ). It needs to have a root Job! CoroutineContext is a Set of elements. \"most of the time coroutine scope and context are the same thing\" Dispatchers: Main - is adding a block to execute to a queue which means the block will be executed in future Main.immediate - if current thread is Main it will immediately execute code, otherwise it will fall back to Main Default - is using 2 or more threads I.O. is using 64 or more threads Unconfinead - is using the same thread as one which is started from If dispatcher is not specify in scope nor as argument then Dispatchers.Default wil be used. Dispatchers are using threads under the hood. withContext(Dispatchers.Default + NonCancellable) {...} adding NonCancellable guarantees that code inside will not be cancelled when parent coroutine will throw the exception CoroutineContext.ensureActive() is checking if hob is Active otherwise throws cancellation exception CoroutineScope.coroutineContext.cancel(children) allows to cancel all jobs inside coroutine scope","title":"Coroutines"},{"location":"programming/kotlin/kotlin/","text":"Kotlin kotlin has property: List.indices which returns index of last element <out MutableList<X>> // means that we can't add anything to this list, we can only read valuse from it delegates properties: by Lazy<T> by Delegates.observable(){} // will call specific block of function when the observed value has changed by Delagates.vetoable() // will call specific block which returns boolean -> true assing new value by Delegates.notNull() // will throw IllegalStateException if not initilized\" by Lazy allows also to initialize values, which can allow to omit NPE in case when fe. object is inside sealed class that takes value like: object: Tree: Plant(\"green\")","title":"Kotlin"},{"location":"programming/kotlin/kotlin/#kotlin","text":"kotlin has property: List.indices which returns index of last element <out MutableList<X>> // means that we can't add anything to this list, we can only read valuse from it","title":"Kotlin"},{"location":"programming/kotlin/kotlin/#delegates-properties","text":"by Lazy<T> by Delegates.observable(){} // will call specific block of function when the observed value has changed by Delagates.vetoable() // will call specific block which returns boolean -> true assing new value by Delegates.notNull() // will throw IllegalStateException if not initilized\" by Lazy allows also to initialize values, which can allow to omit NPE in case when fe. object is inside sealed class that takes value like: object: Tree: Plant(\"green\")","title":"delegates properties:"},{"location":"programming/tools/bugsnag/","text":"Bugsnag tips Make use of the Timeline view as our default maybe. This has all the same information as Inbox but allows us to more easily see when certain issues are arising, or notice visual patterns like we do in Grafana Make use of isLaunching and other flags which give us more detail about app state during a crash. See if we spot any trends, and if we do then bugsnag has hooks for making use of these at runtime Make more use of custom filters as these are exposed in the \"pivot table\" (device / app state info in bottom left of issue view) which gives us more information about which devices are having these issues at a glance We can make use of the \"Features\" tab and link this to JETFM config via OP so that we can detect bugs in particular experiments more easily We can all make use of the \"New error view\" button to create custom widgets for ourselves to track issues arising in certain app areas / situations (e.g. when navigating to a given destination) and these work on a per-user basis so we're not impacting eachother so can use this liberally We could make use of assignement rules so that issues that arise in a particular package or class can notify a particular engineer, e.g. if one of us makes a refactor, we could assign that code area to that engineer and then they'd be notified more quickly of any introduced issues","title":"Bugsnag"},{"location":"programming/tools/bugsnag/#bugsnag","text":"","title":"Bugsnag"},{"location":"programming/tools/bugsnag/#tips","text":"Make use of the Timeline view as our default maybe. This has all the same information as Inbox but allows us to more easily see when certain issues are arising, or notice visual patterns like we do in Grafana Make use of isLaunching and other flags which give us more detail about app state during a crash. See if we spot any trends, and if we do then bugsnag has hooks for making use of these at runtime Make more use of custom filters as these are exposed in the \"pivot table\" (device / app state info in bottom left of issue view) which gives us more information about which devices are having these issues at a glance We can make use of the \"Features\" tab and link this to JETFM config via OP so that we can detect bugs in particular experiments more easily We can all make use of the \"New error view\" button to create custom widgets for ourselves to track issues arising in certain app areas / situations (e.g. when navigating to a given destination) and these work on a per-user basis so we're not impacting eachother so can use this liberally We could make use of assignement rules so that issues that arise in a particular package or class can notify a particular engineer, e.g. if one of us makes a refactor, we could assign that code area to that engineer and then they'd be notified more quickly of any introduced issues","title":"tips"},{"location":"programming/tools/git/","text":"GIT setting up ssh per repository: git config core.sshCommand 'ssh -i ~/.ssh/id_rsa_anotheraccount'","title":"Git"},{"location":"programming/tools/terminal/","text":"Terminal comments Display running tasks (stacks of activities) adb shell dumpsys activity activities | sed -En -e '/Stack #/p' -e '/Running activities/,/Run #0/p' returns: Stack #124: type=standard mode=fullscreen Running activities (most recent first): TaskRecord{111dd6e #577 A=com.lyst.lystapp.debug U=0 StackId=124 sz=2} Run #1: ActivityRecord{40d22c8 u0 com.lyst.lystapp.debug/com.lyst.account.activity.AccountActivity t577} Run #0: ActivityRecord{7b11a74 u0 com.lyst.lystapp.debug/com.lyst.home.view.HomeActivity t577} Stack #0: type=home mode=fullscreen Running activities (most recent first): TaskRecord{e4998d #2 I=com.android.launcher3/com.android.a1launcher.AndroidOneLauncher U=0 StackId=0 sz=1} Run #0: ActivityRecord{755e254 u0 com.android.launcher3/com.android.a1launcher.AndroidOneLauncher t2} adb shell dumpsys activity activities | grep 'Hist #' | grep 'YOUR_PACKAGE_NAME' returns: * Hist #1: ActivityRecord{b9b3bd3 u0 nimdokai.androidplayground/.MainActivity t73} * Hist #0: ActivityRecord{586b9e4 u0 nimdokai.androidplayground/.MainActivity t73} Clear data storage && remove file (used in orderpad to change the partner/ login to different restaurant) adb -s emulator-5554 shell \"pm clear com.justeat.orderpad & rm -f /sdcard/preferencesV3.json\"","title":"Terminal comments"},{"location":"programming/tools/terminal/#terminal-comments","text":"Display running tasks (stacks of activities) adb shell dumpsys activity activities | sed -En -e '/Stack #/p' -e '/Running activities/,/Run #0/p' returns: Stack #124: type=standard mode=fullscreen Running activities (most recent first): TaskRecord{111dd6e #577 A=com.lyst.lystapp.debug U=0 StackId=124 sz=2} Run #1: ActivityRecord{40d22c8 u0 com.lyst.lystapp.debug/com.lyst.account.activity.AccountActivity t577} Run #0: ActivityRecord{7b11a74 u0 com.lyst.lystapp.debug/com.lyst.home.view.HomeActivity t577} Stack #0: type=home mode=fullscreen Running activities (most recent first): TaskRecord{e4998d #2 I=com.android.launcher3/com.android.a1launcher.AndroidOneLauncher U=0 StackId=0 sz=1} Run #0: ActivityRecord{755e254 u0 com.android.launcher3/com.android.a1launcher.AndroidOneLauncher t2} adb shell dumpsys activity activities | grep 'Hist #' | grep 'YOUR_PACKAGE_NAME' returns: * Hist #1: ActivityRecord{b9b3bd3 u0 nimdokai.androidplayground/.MainActivity t73} * Hist #0: ActivityRecord{586b9e4 u0 nimdokai.androidplayground/.MainActivity t73} Clear data storage && remove file (used in orderpad to change the partner/ login to different restaurant) adb -s emulator-5554 shell \"pm clear com.justeat.orderpad & rm -f /sdcard/preferencesV3.json\"","title":"Terminal comments"},{"location":"programming/tools/vim/","text":"","title":"Vim"},{"location":"programming/tools/SotiMobiControl/SotiMobiControl/","text":"Soti MobiControl Modes Dev Mode [AE]-[All]-[Orderpad]-[UK]-[All]-[CFG]-[All]-Security_WorkManaged - remove [AE]-[Live]-[Orderpad]-[All]-[All]-[CFG]-[All]-Restrictions - remove Android 11 access external storage solutions With Android 11 apps can't access easily external storage (sd card). This change was introduce to increase protection of the user. Problem - all files that are used by JET e.g. deviceInfo.ini (this one is used to get IMEI), OrderPad.log.0 are stored on sd card. Which means devices that are running on Android 11 and above can't access those files by default. 1. Force the permission via SOTI mobicontrol: note: All cases described below where completed with permission added to the AndroidManifest.xml : <uses-permission android:name=\"android.permission.MANAGE_EXTERNAL_STORAGE\" /> 1.1. Josh from The SOTI team gave as below instruction how can we achieve it: afw_set_permission_grant_state com.justeat.orderpad android.permission.MANAGE_EXTERNAL_STORAGE allow unfortunately it didn't resolve the problem as permission wasn't granted: 1.2. Second solution from Josh was to try the below one: request_appops_permission android.permission.MANAGE_EXTERNAL_STORAGE allow com.justeat.orderpad Same result, it didn't work. 1.3. below works locally via terminal: adb shell appops set com.justeat.orderpad MANAGE_EXTERNAL_STORAGE allow so I tried to adjust the package from 1.2 and also tried: request_appops_permission MANAGE_EXTERNAL_STORAGE allow com.justeat.orderpad though it didn't work either. summary Explanation from Josh why it's not working: In order for MobiControl to have the ability to grant other apps any kind of special permissions, we need access to API\u2019s which Samsung do not offer. For other manufacturers we often work around this with the MobiControl agent plugin, but for Samsung this doesn\u2019t exist. I was hoping that one of the two scripts may have still worked but given the information I\u2019ve found since Nic\u2019s first email, these would never have worked on a Samsung device running Android 11. Having further researched, it seems other customers have made the same request and have been unable to come to a workable solution. It seems the only way which might be possible to get Orderpad to have the permission, is to embed the permission request into the app installation. to check: I asked Josh for clarification what he mean by embed the permission request into the app installation 2. Using app specific external storage This approach rather than trying to get the required permission is taking advantage of the available solution that was introduced in Android 11. Each application has access to its own storage (path) inside sd card if required. This doesn't require any permission to be acquired from the user. This solution does work in terms of creating logs on sd card under the directory: /sdcard/Android/data/com.justeat.orderpad/files/OrderPad.log.0 which is accessible by app. The downside is that files in this directory aren't accessible by SOTI MobiControl. Which means: we can't download the logs file via SOTI MobiControl (TO CONFIRM WITH JOSH) To check: can we put files there via SOTI (when app is added to distribution) instead of putting them in the root of SD card? - Nic asked question to Josh is there a different way for us to get the logs instead of via SOTI? like pushing it to some server/tool 3. Getting permission from the user We can request a permission from the user in runtime, though because it's not standard permission but special permission thus it can't grant directly in the app, but rather through system settings, as described in documentation Once requested the permission (we can define when it's going to happen), we are going to show below screen: Once user grands permission we have access to external storage. to check: is there a way for us to show and switch the toggle via SOTI MobiControl? 4. Shared Media Storage It would be probably achieve it via Shared Media Storage, but it requires user interaction for selecting the proper destination (granting permission for it) - per documentation . So similarly to 3. but more prone to error as user needs to select the proper directory.","title":"Soti MobiControl"},{"location":"programming/tools/SotiMobiControl/SotiMobiControl/#soti-mobicontrol","text":"","title":"Soti MobiControl"},{"location":"programming/tools/SotiMobiControl/SotiMobiControl/#modes","text":"","title":"Modes"},{"location":"programming/tools/SotiMobiControl/SotiMobiControl/#dev-mode","text":"[AE]-[All]-[Orderpad]-[UK]-[All]-[CFG]-[All]-Security_WorkManaged - remove [AE]-[Live]-[Orderpad]-[All]-[All]-[CFG]-[All]-Restrictions - remove","title":"Dev Mode"},{"location":"programming/tools/SotiMobiControl/SotiMobiControl/#android-11-access-external-storage-solutions","text":"With Android 11 apps can't access easily external storage (sd card). This change was introduce to increase protection of the user. Problem - all files that are used by JET e.g. deviceInfo.ini (this one is used to get IMEI), OrderPad.log.0 are stored on sd card. Which means devices that are running on Android 11 and above can't access those files by default.","title":"Android 11 access external storage solutions"},{"location":"programming/tools/SotiMobiControl/SotiMobiControl/#1-force-the-permission-via-soti-mobicontrol","text":"note: All cases described below where completed with permission added to the AndroidManifest.xml : <uses-permission android:name=\"android.permission.MANAGE_EXTERNAL_STORAGE\" /> 1.1. Josh from The SOTI team gave as below instruction how can we achieve it: afw_set_permission_grant_state com.justeat.orderpad android.permission.MANAGE_EXTERNAL_STORAGE allow unfortunately it didn't resolve the problem as permission wasn't granted: 1.2. Second solution from Josh was to try the below one: request_appops_permission android.permission.MANAGE_EXTERNAL_STORAGE allow com.justeat.orderpad Same result, it didn't work. 1.3. below works locally via terminal: adb shell appops set com.justeat.orderpad MANAGE_EXTERNAL_STORAGE allow so I tried to adjust the package from 1.2 and also tried: request_appops_permission MANAGE_EXTERNAL_STORAGE allow com.justeat.orderpad though it didn't work either.","title":"1. Force the permission via SOTI mobicontrol:"},{"location":"programming/tools/SotiMobiControl/SotiMobiControl/#summary","text":"Explanation from Josh why it's not working: In order for MobiControl to have the ability to grant other apps any kind of special permissions, we need access to API\u2019s which Samsung do not offer. For other manufacturers we often work around this with the MobiControl agent plugin, but for Samsung this doesn\u2019t exist. I was hoping that one of the two scripts may have still worked but given the information I\u2019ve found since Nic\u2019s first email, these would never have worked on a Samsung device running Android 11. Having further researched, it seems other customers have made the same request and have been unable to come to a workable solution. It seems the only way which might be possible to get Orderpad to have the permission, is to embed the permission request into the app installation. to check: I asked Josh for clarification what he mean by embed the permission request into the app installation","title":"summary"},{"location":"programming/tools/SotiMobiControl/SotiMobiControl/#2-using-app-specific-external-storage","text":"This approach rather than trying to get the required permission is taking advantage of the available solution that was introduced in Android 11. Each application has access to its own storage (path) inside sd card if required. This doesn't require any permission to be acquired from the user. This solution does work in terms of creating logs on sd card under the directory: /sdcard/Android/data/com.justeat.orderpad/files/OrderPad.log.0 which is accessible by app. The downside is that files in this directory aren't accessible by SOTI MobiControl. Which means: we can't download the logs file via SOTI MobiControl (TO CONFIRM WITH JOSH) To check: can we put files there via SOTI (when app is added to distribution) instead of putting them in the root of SD card? - Nic asked question to Josh is there a different way for us to get the logs instead of via SOTI? like pushing it to some server/tool","title":"2. Using app specific external storage"},{"location":"programming/tools/SotiMobiControl/SotiMobiControl/#3-getting-permission-from-the-user","text":"We can request a permission from the user in runtime, though because it's not standard permission but special permission thus it can't grant directly in the app, but rather through system settings, as described in documentation Once requested the permission (we can define when it's going to happen), we are going to show below screen: Once user grands permission we have access to external storage. to check: is there a way for us to show and switch the toggle via SOTI MobiControl?","title":"3. Getting permission from the user"},{"location":"programming/tools/SotiMobiControl/SotiMobiControl/#4-shared-media-storage","text":"It would be probably achieve it via Shared Media Storage, but it requires user interaction for selecting the proper destination (granting permission for it) - per documentation . So similarly to 3. but more prone to error as user needs to select the proper directory.","title":"4. Shared Media Storage"},{"location":"work/JustEatIdeas/","text":"JustEatTakeaway Ideas Team/Project daily stability meeting, why it's needed, do we have any hooks that check for anomaly? ways of working: tools (communication), confluence, definition of ready, definition of done JIRA no preview/code available when typing a comment change log for each release? - it is in confluence Android To Propose on next Sharing Session ideas optimize the startup processes by using Handlers linking JIRA ticket in github moving away from DataBinding and using ViewBinding SavedStateHandle injections https://insert-koin.io/docs/reference/koin-android/viewmodel/#savedstatehandle-injection-330 why we need firebase, snagbug && kibana. Can we remove any of this, why one is better than another? storing amounts as float's build time on CI + cost? adding strict mode on debug Explicit API mode github actions remove tagging for every pipeline run, instead tag only release builds. https://github.blog/2023-07-19-metrics-for-issues-pull-requests-and-discussions/ https://justeattakeaway.atlassian.net/wiki/spaces/techcomms/blog/2023/03/29/6309511581/Support+For+Gradle+Projects+In+RunSonarQubeScan+Github+Action proposed already @AllowFlaky annotation, should we use it at all - proposed ticket created assigning reviewers instead of \"FFA\". proposed: mixed feeling across developers - Anfan & Anna were happy about it, rest mixed feelings. project structure guides & rules (architecture, naming convention, tooling) - proposed & agreed we can check if lint rules are going to help us we are going to keep it in the repository squash commits when merging to main for simpler commit history - flexibility - do it if you want proposed auto-deleting branches after merging - proposed and done review our stale branches on github - proposed and agreed. remove/comment flaky tests - Anfan will take care of it Issue with multiple activities because of EnsureForegroundService - resolved and committed the change. fixing the failing tests/jobs. TODOs check the flows from Des: \"You can find everything from the link here in this screen, whilst the subsequent screens demonstrate everything.\" https://docs.google.com/presentation/d/1x3qY6LIsr13hiLbWH63MCDpAPnxlriD8d9NpdbeN0g0/edit#slide=id.g1b6296ba63d_1_0","title":"JustEatTakeaway Ideas"},{"location":"work/JustEatIdeas/#justeattakeaway-ideas","text":"","title":"JustEatTakeaway Ideas"},{"location":"work/JustEatIdeas/#teamproject","text":"daily stability meeting, why it's needed, do we have any hooks that check for anomaly? ways of working: tools (communication), confluence, definition of ready, definition of done JIRA no preview/code available when typing a comment change log for each release? - it is in confluence","title":"Team/Project"},{"location":"work/JustEatIdeas/#android","text":"","title":"Android"},{"location":"work/JustEatIdeas/#to-propose-on-next-sharing-session","text":"","title":"To Propose on next Sharing Session"},{"location":"work/JustEatIdeas/#ideas","text":"optimize the startup processes by using Handlers linking JIRA ticket in github moving away from DataBinding and using ViewBinding SavedStateHandle injections https://insert-koin.io/docs/reference/koin-android/viewmodel/#savedstatehandle-injection-330 why we need firebase, snagbug && kibana. Can we remove any of this, why one is better than another? storing amounts as float's build time on CI + cost? adding strict mode on debug Explicit API mode","title":"ideas"},{"location":"work/JustEatIdeas/#github-actions","text":"remove tagging for every pipeline run, instead tag only release builds. https://github.blog/2023-07-19-metrics-for-issues-pull-requests-and-discussions/ https://justeattakeaway.atlassian.net/wiki/spaces/techcomms/blog/2023/03/29/6309511581/Support+For+Gradle+Projects+In+RunSonarQubeScan+Github+Action","title":"github actions"},{"location":"work/JustEatIdeas/#proposed-already","text":"@AllowFlaky annotation, should we use it at all - proposed ticket created assigning reviewers instead of \"FFA\". proposed: mixed feeling across developers - Anfan & Anna were happy about it, rest mixed feelings. project structure guides & rules (architecture, naming convention, tooling) - proposed & agreed we can check if lint rules are going to help us we are going to keep it in the repository squash commits when merging to main for simpler commit history - flexibility - do it if you want proposed auto-deleting branches after merging - proposed and done review our stale branches on github - proposed and agreed. remove/comment flaky tests - Anfan will take care of it Issue with multiple activities because of EnsureForegroundService - resolved and committed the change. fixing the failing tests/jobs.","title":"proposed already"},{"location":"work/JustEatIdeas/#todos","text":"check the flows from Des: \"You can find everything from the link here in this screen, whilst the subsequent screens demonstrate everything.\" https://docs.google.com/presentation/d/1x3qY6LIsr13hiLbWH63MCDpAPnxlriD8d9NpdbeN0g0/edit#slide=id.g1b6296ba63d_1_0","title":"TODOs"},{"location":"work/ReceiveOrderStructureRefactor/","text":"Receive Order Structure Current structure classDiagram class Square~Shape~{ int id List~int~ position setPoints(List~int~ points) getPoints() List~int~ } Square : -List~string~ messages Square : +setMessages(List~string~ messages) Square : +getMessages() List~string~ Square : +getDistanceMatrix() List~List~int~~ class Zebra{ +bool is_wild +run() }","title":"Receive Order Structure"},{"location":"work/ReceiveOrderStructureRefactor/#receive-order-structure","text":"","title":"Receive Order Structure"},{"location":"work/ReceiveOrderStructureRefactor/#current-structure","text":"classDiagram class Square~Shape~{ int id List~int~ position setPoints(List~int~ points) getPoints() List~int~ } Square : -List~string~ messages Square : +setMessages(List~string~ messages) Square : +getMessages() List~string~ Square : +getDistanceMatrix() List~List~int~~ class Zebra{ +bool is_wild +run() }","title":"Current structure"},{"location":"work/goals/","text":"Goals JET probation learn koin learn about UI testing learn Screenshoot testing Propose improvement in the codebase Propose improvement in the work process (e.g. by creating a documentation, ways of working) Tech-Stack","title":"Goals"},{"location":"work/goals/#goals","text":"","title":"Goals"},{"location":"work/goals/#jet-probation","text":"learn koin learn about UI testing learn Screenshoot testing Propose improvement in the codebase Propose improvement in the work process (e.g. by creating a documentation, ways of working) Tech-Stack","title":"JET probation"},{"location":"work/interviewQuestions/","text":"Candidate questions tech stack what is the tech stack? what are future plans for tech stack? architecture what is the architecture of the app? do you have business process model? testing what kind of tests do you use? what is the coverage of particular tests? process How the process of developing the feature looks like? Are you using data behind? what are future plans for features? team what is the structure of the team? how many squads are in? how many android developers work on the app? role what are the main area that I will be involved as developer? onboarding how will my onboarding will look like? dedicated person? onboarding document?","title":"Candidate questions"},{"location":"work/interviewQuestions/#candidate-questions","text":"","title":"Candidate questions"},{"location":"work/interviewQuestions/#tech-stack","text":"what is the tech stack? what are future plans for tech stack?","title":"tech stack"},{"location":"work/interviewQuestions/#architecture","text":"what is the architecture of the app? do you have business process model?","title":"architecture"},{"location":"work/interviewQuestions/#testing","text":"what kind of tests do you use? what is the coverage of particular tests?","title":"testing"},{"location":"work/interviewQuestions/#process","text":"How the process of developing the feature looks like? Are you using data behind? what are future plans for features?","title":"process"},{"location":"work/interviewQuestions/#team","text":"what is the structure of the team? how many squads are in? how many android developers work on the app?","title":"team"},{"location":"work/interviewQuestions/#role","text":"what are the main area that I will be involved as developer?","title":"role"},{"location":"work/interviewQuestions/#onboarding","text":"how will my onboarding will look like? dedicated person? onboarding document?","title":"onboarding"}]}